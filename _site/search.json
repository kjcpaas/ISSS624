[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "Welcome to ISSS624 Geospatial Analytics Applications!\nI am Kristine Joy Paas, or Joy for short.\nIn this webpage, I am going to share with you my learning journey of geospatial analytics.\nNetlify link: https://isss624-kjcpaas.netlify.app/\nGithub repo: https://github.com/kjcpaas/ISSS624"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex1.html",
    "href": "Hands-on_Ex1.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "Hands-on_Ex1.html#overview",
    "href": "Hands-on_Ex1.html#overview",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Exercise 1",
    "section": "Getting Started",
    "text": "Getting Started\nThis is the getting started paragraph."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "This hands-on exercise covers Chapter 1: Data Wrangling with R.\nI learned about the following:\n\nPublic Data Sets like the ones on data.gov.sg, LTADataMall, and InsideAirbnb.\nHow to import data sets into RStudio\nWrangling geospatial data in using different R packages like sf, tidyverse, etc.\nCreating thematic/choropleth maps with tmap"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#overview",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learned about the following:\n\nPublic Data Sets like the ones on data.gov.sg, LTADataMall, and InsideAirbnb.\nHow to import data sets into RStudio\nWrangling geospatial data in using different R packages like sf, tidyverse, etc."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Getting Started",
    "text": "Getting Started\n\nPreparing the data sets\nFirst, I downloaded the different data sets from data.gov.sg, LTADataMall, and InsideAirbnb.\nNext, I put them under the Hands-on_Ex1 directory, with the following file structure:\nHands-on_Ex1\n├── Hands-on_Ex1.qmd\n└── data\n    ├── aspatial\n    │   └── listings.csv\n    └── geospatial\n        ├── CyclingPathGazette.cpg\n        ├── CyclingPathGazette.dbf\n        ├── CyclingPathGazette.lyr\n        ├── CyclingPathGazette.prj\n        ├── CyclingPathGazette.sbn\n        ├── CyclingPathGazette.sbx\n        ├── CyclingPathGazette.shp\n        ├── CyclingPathGazette.shp.xml\n        ├── CyclingPathGazette.shx\n        ├── MP14_SUBZONE_WEB_PL.dbf\n        ├── MP14_SUBZONE_WEB_PL.prj\n        ├── MP14_SUBZONE_WEB_PL.sbn\n        ├── MP14_SUBZONE_WEB_PL.sbx\n        ├── MP14_SUBZONE_WEB_PL.shp\n        ├── MP14_SUBZONE_WEB_PL.shp.xml\n        ├── MP14_SUBZONE_WEB_PL.shx\n        └── PreSchoolsLocation.kml\n\n\nInstalling R packages\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\nAfter setting up the data sets and the R packages, we can proceed with importing the geospatial data.\n\nMaster Plan 2014 Subzone Boundary (Web)\nTo import the data set to RStudio, I used st_read() :\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nI encountered the error below along the way:\nCannot open layer MasterPlan2014SubzoneBoundaryWebKML\nThis is because I originally downloaded the kml file instead of the shp file. After using the shp file, the st_read() succeeded.\n\nℹ️ My biggest take-away for this is that st_read reads shp data set by default. (this would be debunked later)\n\nAfter running the code, we should see the mpsz data in the environment.\n\n\n\nCycling Path Data\nEquipped with my learning from the previous step, I was able to quickly figure out that importing this data set can be done by simply changing the layer parameter from the previous code:\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nHowever, the difference is that this geometry has polyline features, while the previous has polygon features.\n\n\nPre-Schools Location Data\nUnlike the others, this data set is in kml format instead of shp format. I used the following code to import:\n\npreschool &lt;- st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nℹ️ Contrary to my previous take-away, st_read() can read kml files by default. In fact, reading shp files require more parameters like dsn and layer."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#others",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#others",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "Others",
    "text": "Others\n\nChanging the website theme\nAfter exploring Quarto docs, I found that we can change the theme. I decided on the zephyr theme as it looks most readable and aesthetic for me.\n\n\nIssues with using Github on Rstudio\nIt was recommended to name the project with the convention &lt;github_username&gt;/ISSS624. However, due to restrictions on my machine, I had to deviate from this and create my project elsewhere.\nHence, I couldn’t use usethis::use_github() to setup my Github repository. However, as I use Github intensively in my job, I did the setup manually myself to use the git functions on RStudio.\n\nCreate the repo manually on Github on https://github.com/kjcpaas/ISSS624\nAdd the Github remote on RStudio project\n&gt; git remote add origin git@github.com:kjcpaas/ISSS624.git\n&gt; git remote -v\norigin  git@github.com:kjcpaas/ISSS624.git (fetch)\norigin  git@github.com:kjcpaas/ISSS624.git (push)\nSet remote for head\n&gt; git remote set-head origin --auto\n&gt; git gc\n\nAfter all these, I was able to use the git functions on RStudio."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#checking-contents-of-data-frames",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#checking-contents-of-data-frames",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Checking Contents of Data Frames",
    "text": "Checking Contents of Data Frames\n\nChecking the geometry of data frames\nUsing st_geometry() returns information about the geometry of the data frame.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nIt gave the same geometric information as when importing the shape data but with additional details like the first 5 geometries.\n\n\nGetting overview of geospatial data\nUsing glimpse() gives useful information about the columns, data types, values. For example:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThis will be very useful to scan for the available data and which columns are useful for analysis.\n\n\nRevealing complete information of feature objects\nUsing head() can give full information about objects in the data set. For example:\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThis will return the first 5 objects, and the number of objects can be set by specifying a value for n.\nAnother function that is useful for this purpose is tail(), which returns items from the end of the data set. For example:\n\ntail(mpsz, n=2)\n\nSimple feature collection with 2 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 23378.74 ymin: 48569.62 xmax: 28343.2 ymax: 50256.33\nProjected CRS: SVY21\n    OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n322      322          7  THE WHARVES    SBSZ07      N  SEMBAWANG         SB\n323      323          8 SENOKO NORTH    SBSZ08      N  SEMBAWANG         SB\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n322 NORTH REGION       NR 6D89875A351CF51C 2014-12-05 26945.07 49552.79\n323 NORTH REGION       NR A800CBEE879C1BF9 2014-12-05 24665.79 49482.60\n    SHAPE_Leng SHAPE_Area                       geometry\n322  11828.878    1635808 MULTIPOLYGON (((26219.89 50...\n323   7392.129    2241387 MULTIPOLYGON (((26047.11 50...\n\n\nThis returned the items on rows 322 and 323 instead of 1 and 2 if we were to use head().\nHowever, I wonder which use cases these functions would be useful as we can easily inspect the full data when looking at all the Environment Data in RStudio. 🤔"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#plotting-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Plotting Geospatial Data",
    "text": "Plotting Geospatial Data\n\nplot(mpsz, max.plot = 15)\n\n\n\n\nI was pleasantly surprised to find that the rendering of the plots was so fast! It only took 1 second or so on my machine for 300+ features and 15 fields. This is really useful for quick look of the data.\nTrying it on the cycling path data was also very fast though the result was not so useful for me as it needs to be overlayed with a map like above.\n\nplot(cyclingpath)\n\n\n\n\nI wonder how long it would take once we have larger data sets. 🤔\nAs someone not originally from Singapore, I am still familiarizing myself with the countries geography so I’ll plot the regions first.\n\nplot(mpsz['REGION_N'])\n\n\n\n\nThis can still be visualized better, especially the names in the legend got cut off. From the Help pages on RStudio, this function has a lot more parameters and I’ll explore it once I have more time."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#projections",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#projections",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Projections",
    "text": "Projections\n\nCorrecting the EPSG code\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nI am not familiar with what the st_crs() returns and I wouldn’t have thought that EPSG needs correcting since I don’t have the domain knowledge. This is one of my biggest take away for this exercise.\n\n\nProjection Transformation\nWhen using st_set_crs(), I got the warning below:\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for that\nAs such, the mpsz3414 data before may not be projected properly despite having the correct EPSG value.\nNext, I will transform the pre-school data:\n\npreschool3414 &lt;- st_transform(preschool, crs=3414)\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#reflections",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#reflections",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "Reflections",
    "text": "Reflections\n\nI thought it would be difficult to setup R and RStudio especially as the Cran Project site was down when I first attempted to set up. Good thing it was up the next day.\nThis course is looking to be very demanding indeed with a lot of time spent on pre-class assignments. However, I have enjoyed the hands-on exercise so far and I am eager to learn more!"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Importing and Converting Aspatial Data",
    "text": "Importing and Converting Aspatial Data\nFor aspatial data, I used read_csv() to import the data.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nFrom this, we have candidate geospatial fields that we can use, longitude and latitude.\nChecking the data contents of these field can confirm if we can really use the data.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nAfter confirming that longitude and latitude can be used as geospatial data, I transformed this data to geospatial data.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nChecking the new data frame, it was confirmed that it was transformed to a geospatial data.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#geoprocessing",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#geoprocessing",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Geoprocessing",
    "text": "Geoprocessing\n\nBuffering\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\nAfter seeing my classmate’s question on Piazza, I was also curious about the effect of nQuadSegs to the area. From the documentation, this is the number of segments created per quadrant.\nMy understanding of this is since each quadrant has 90 degrees, having nQuadSegs = 30 means 1 segment per 3 degrees. If this correct, my hypothesis is that the higher nQuadSegs is, the more accurate it is. This is because nQuadSegs=1 would be a square, and it becomes a polygon with more sides the higher nQuadSegs is. The higher nQuadSegs, the smoother the polygon becomes and it gets closer to being a circle.\nI’m testing the theory below and if my hypothesis is correct, the area should not differ much past nQuadSegs=180\n\nbuffer_cycling0 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 0)\nbuffer_cycling0$AREA &lt;- st_area(buffer_cycling0)\nsum(buffer_cycling0$AREA)\n\n1700331 [m^2]\n\n\n\nbuffer_cycling10 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 10)\nbuffer_cycling10$AREA &lt;- st_area(buffer_cycling10)\nsum(buffer_cycling10$AREA)\n\n1773584 [m^2]\n\n\n\nbuffer_cycling45 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 45)\nbuffer_cycling45$AREA &lt;- st_area(buffer_cycling45)\nsum(buffer_cycling45$AREA)\n\n1774421 [m^2]\n\n\n\nbuffer_cycling90 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 90)\nbuffer_cycling90$AREA &lt;- st_area(buffer_cycling90)\nsum(buffer_cycling90$AREA)\n\n1774454 [m^2]\n\n\n\nbuffer_cycling180 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 180)\nbuffer_cycling180$AREA &lt;- st_area(buffer_cycling180)\nsum(buffer_cycling180$AREA)\n\n1774462 [m^2]\n\n\n\nbuffer_cycling1800 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 1800)\nbuffer_cycling1800$AREA &lt;- st_area(buffer_cycling1800)\nsum(buffer_cycling1800$AREA)\n\n1774465 [m^2]\n\n\nAs we can see, from 180 to 1800 the area only changed by 3m2 but the differences are larger in lower values. My conclusion is that the higher nQuadSegs, the more accurate the value we will get. However, the calculation took much longer. The extremely small accuracy benefit may not be worth the trade-off in most cases.\nThe result when using nQuadSegs of 30 is already very close to the result when it is 1800.\n\\[\n1774367/1774465 = 99.99\\%\n\\]\n\n\nPoint-in-polygon count\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nThis means that there are subzones without pre-school while some have as many as 72.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe subzone with the most pre-schools is Tampines East.\nTo calculate the density of pre-schools:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nLet’s see the top 3 subzones with the highest pre-school density.\n\ntop_n(mpsz3414, 3, `PreSch Density`)\n\nSimple feature collection with 3 features and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25594.22 ymin: 28623.75 xmax: 29976.93 ymax: 48182.13\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO         SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N\n1       27          8             CECIL    DTSZ08      Y DOWNTOWN CORE\n2      278          3     MANDAI ESTATE    MDSZ03      N        MANDAI\n3      291          3 SEMBAWANG CENTRAL    SBSZ03      N     SEMBAWANG\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         DT CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.20\n2         MD   NORTH REGION       NR F6266F7368DBB9AB 2014-12-05 27082.70\n3         SB   NORTH REGION       NR 772A64AB9A93FC3A 2014-12-05 26268.73\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1 29011.33   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n2 45367.46   1633.708   143137.9 MULTIPOLYGON (((27119.56 45...            5\n3 47558.08   3955.118   962437.4 MULTIPOLYGON (((26311.14 46...           27\n            Area   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]\n2 143137.9 [m^2] 34.93134 [1/m^2]\n3 962437.4 [m^2] 28.05377 [1/m^2]\n\n\nDespite Tampines East having the most pre-schools, Cecil has the highest pre-school density. Tampines East might be much bigger than Cecil so its Pre-school Density is lower."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\nBelow is the histogram for Pre-school Density:\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nWe improvef this graph by using ggplot.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are a few sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\nWe can also create a scatter plot.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html",
    "title": "Hands-on Exercise 2: Work in Progress",
    "section": "",
    "text": "In this hands-on exercise, I learned about the following:\n\nPut summarry of learnings here"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#overview",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#overview",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, I learned about the following:\n\nData preparation\nChoropleth Mapping\nJoining geospatial data"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#getting-started",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#getting-started",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Getting Started",
    "text": "Getting Started\n\nPreparing the data sets\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#importing-the-data",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#importing-the-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Importing the data",
    "text": "Importing the data\nI prepared the datasets as with Chapter 1, resulting in the following directory structure:\nHands-on_Ex2\n├── Hands-on_Ex2.qmd\n└── data\n    ├── aspatial\n    │   └── respopagesextod2011to2020.csv\n    └── geospatial\n        ├── MP14_SUBZONE_WEB_PL.dbf\n        ├── MP14_SUBZONE_WEB_PL.prj\n        ├── MP14_SUBZONE_WEB_PL.sbn\n        ├── MP14_SUBZONE_WEB_PL.sbx\n        ├── MP14_SUBZONE_WEB_PL.shp\n        ├── MP14_SUBZONE_WEB_PL.shp.xml\n        └── MP14_SUBZONE_WEB_PL.shx\n\nImporting geospatial data\nTo import the MPSZ data set to RStudio, I used the same code chunk in the previous exercise.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nImporting aspatial data\nThe csv data is an aspatial data so read_csv() must be used instead of st_read():\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\nData preparation\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\nI don’t fully understand this entire code chunk yet but I know it filtered for data from 2020 only and did some aggregations based on the age groups, PA, and AZ. New fields like YOUNG and AGED .\nNext, I joined this data with the mpsz data via SZ. However, we still need to make sure that the SZ values are uppercase to match mpsz’s SUBZONE_N.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThen the 2 data sets can be joined.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLastly, write the rds of the combined data set.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Choropleth Mapping Geospatial Data Using tmap",
    "text": "Choropleth Mapping Geospatial Data Using tmap\n\nUsing qtm()\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nI tried to create an interactive map by using view instead of plot but an error about invalid polygons was returned.\n\n\nUsing tmap elements\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nFrom this part, I saw that with tm_shape as base, thematic maps can be created by doing + with the tmap actions. I will explore this later but I found a good reference on where to start: https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html.\n\n\nClassification methods\n\nQuantile\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nEqual\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nTakeaways\nMy main takeaway for this is that the quantile classification deals with outliers better. In this data set, there is 1 subzone as outlier. If we use equal classification, the map looks homogeneous and does not provide much information as it cannot be seen how the values from one subzone to the other differ.\n\n\n\nColor Scheme\nThe color scheme can be changed by specifying the palette in tm_fill() like below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nMore colors can be found when running tmaptools::palette_explorer() in the console. However, it requires shiny and shinyjs to work. This is a wonderful tool as it can also simulate how the color schemes look from the perspective of people with color blindness. As these maps aim to communicate, it is important for the color schemes chosen to not just be beautiful, but also inclusive.\n\n\nMap Layouts\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nAdding legends to maps is very useful as it provides additional information. However, this feature should not be abused to add multiple visualizations as legend as it can cause more confusion if there is too much information to present.\nMap style can also be changed and it is useful to enhance the visual presentation. After doing some research, I found the other available styles in https://cran.r-project.org/web/packages/tmap/vignettes/tmap-changes.html.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tmap_style(\"natural\")\n\n\n\n\nIn this example, I used the natural style to make it look like the map is surrounded by water (as it is naturally). Adding “furnitures” like compass and scale can also provide more perspective.\n\n\nSmaller Maps\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nI don’t find this very useful as the maps rendered might be too small to inspect. However, the facets with the region can be useful to see the data based on region.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Greens\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping According to Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Greens\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nI find this very useful especially if you just want to map a subset of the data. This can be used when we want to highlight information on certain regions."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#reflections",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#reflections",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Reflections",
    "text": "Reflections\n\nI was exhausted after doing the 2 chapters, and I must change how I do things next week. What I have been doing is understanding each part deeply first before moving on to the next. I think I should do chunks of work first before going back for deep understanding so I have more holistic view of the content and more sustainable for the duration of this course.\nI find tmap very useful and I am looking forward to using it more as it has so many functions to visualize data. Only one’s creativity limits the possibilities of using it."
  },
  {
    "objectID": "In-class_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html",
    "href": "In-class_Ex1/In-class_Ex1.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "Overview goes here"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#overview",
    "href": "In-class_Ex1/In-class_Ex1.html#overview",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "Overview goes here"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#getting-started",
    "href": "In-class_Ex1/In-class_Ex1.html#getting-started",
    "title": "In-class Exercise 1",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below loads the following packages:\n\ntmap: for thematic mapping\nsf: for geospatial data handling\ntidyverse: for non-spatial data handling\n\n\npacman::p_load(tmap, sf, tidyverse)"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#preparing-the-flow-data",
    "href": "In-class_Ex1/In-class_Ex1.html#preparing-the-flow-data",
    "title": "In-class Exercise 1",
    "section": "Preparing the Flow Data",
    "text": "Preparing the Flow Data\n\nImporting the origin and destination data\nFirstly, we will import the Passenger Volume By Origin Destination Bust Stops data set from LTA Data Mall by using read_csv .\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\nTo make it easier to process the PT codes, we will convert the origin and destination PT codes to factor data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\nNext, I want to investigate the commuter flows between 7-10am on weekdays. We need to use the interval 7 &lt;= time &lt;= 9 as the data with time = 9 contains data from 9am to just before 10am.\n\norigtrip_7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n\nImporting geospatial data\nNext we need to import the bus stop locations so that we can correlate them from the PT codes from the origin and destination data from before.\n\nbustop &lt;- st_read(dsn = \"data/geospatial\",\n                  layer = \"BusStop\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `BusStop' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nSince these are just points, we also need some polygon data to figure out where in the Singapore map the bus locations correspond to:\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#changing-the-website-theme",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#changing-the-website-theme",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Changing the website theme",
    "text": "Changing the website theme\nAfter exploring Quarto docs, I found that we can change the theme. I decided on the zephyr theme as it looks most readable and aesthetic for me."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#issues-with-using-github-on-rstudio",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#issues-with-using-github-on-rstudio",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Issues with using Github on Rstudio",
    "text": "Issues with using Github on Rstudio\nIt was recommended to name the project with the convention &lt;github_username&gt;/ISSS624. However, due to restrictions on my machine, I had to deviate from this and create my project elsewhere.\nHence, I couldn’t use usethis::use_github() to setup my Github repository. However, as I use git Github intensively in my job, I did the setup manually myself to use the git functions on RStudio.\nI used these steps for the manual setup.\n\nCreate the repo manually on Github on https://github.com/kjcpaas/ISSS624\nAdd the Github remote on RStudio project\n&gt; git remote add origin git@github.com:kjcpaas/ISSS624.git\n&gt; git remote -v\norigin  git@github.com:kjcpaas/ISSS624.git (fetch)\norigin  git@github.com:kjcpaas/ISSS624.git (push)\nSet remote for head\n&gt; git remote set-head origin --auto\n&gt; git gc\n\nAfter all these, I was able to use the git functions on RStudio."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#data-wrangling",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#data-wrangling",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nImporting geospatial data\nTo import the MPSZ data set to RStudio, I used the same code chunk in the previous exercise.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nImporting aspatial data\nThe csv data is an aspatial data so read_csv() must be used instead of st_read():\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\nData preparation\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\nI don’t fully understand this entire code chunk yet but I know it filtered for data from 2020 only and did some aggregations based on the age groups, PA, and AZ. New fields like YOUNG and AGED .\nNext, I joined this data with the mpsz data via SZ. However, we still need to make sure that the SZ values are uppercase to match mpsz’s SUBZONE_N.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThen the 2 data sets can be joined.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLastly, write the rds of the combined data set.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n⚠️ This failed on the first try so I had to create the rds directory under data/ before trying again."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Choropleth Mapping Geospatial Data Using tmap",
    "text": "Choropleth Mapping Geospatial Data Using tmap\n\nUsing qtm()\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nI tried to create an interactive map by using view instead of plot but an error about invalid polygons was returned.\n\n\nUsing tmap() elements\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nFrom this part, I saw that with tm_shape as base, thematic maps can be created by doing + with the tmap actions. I will explore this later but I found a good reference on where to start: https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html.\n\n\nClassification methods\n\nQuantile\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nEqual\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nMy main takeaway for this is that the quantile classification deals with outliers better. In this data set, there is an outlier subzone. If we use equal classification, the map looks homogeneous and does not provide much information as it cannot be seen how the values from one subzone to the other differ.\nWith quantile classification, these differences can be seen more easily despite the outlier value.\n\n\n\nColor Scheme\nThe color scheme can be changed by specifying the palette in tm_fill() like below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nMore colors can be found when running tmaptools::palette_explorer() in the console. However, it requires shiny and shinyjs to work. This is a wonderful tool as it can also simulate how the color schemes look from the perspective of people with color blindness. As these maps aim to communicate, it is important for the color schemes chosen to not just be beautiful, but also inclusive.\n\n\nMap Layouts\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nAdding legends to maps is very useful as it provides additional information. However, this feature should not be abused to add multiple visualizations as legend as it can cause more confusion if there is too much information to present.\nMap style can also be changed and it is useful to enhance the visual presentation. After doing some research, I found the other available styles in https://cran.r-project.org/web/packages/tmap/vignettes/tmap-changes.html.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tmap_style(\"natural\")\n\n\n\n\nIn this example, I used the natural style to make it look like the map is surrounded by water (as it is naturally). Adding “furnitures” like compass and scale can also provide more perspective.\n\n\nSmaller Maps\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nI don’t find this very useful as the maps rendered might be too small to inspect. However, the facets with the region can be useful to see the data based on region.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Greens\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping According to Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Greens\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nI find this very useful especially if we just want to map a subset of the data. This can be used when we want to highlight information on certain regions."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#preparing-the-data-sets",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#preparing-the-data-sets",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Preparing the data sets",
    "text": "Preparing the data sets\nFirst, I downloaded the different data sets needed in this exercise.\n\nGeospatial\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\n\n\n\nAspatial\n\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\nNext, is putting them under the Hands-on_Ex1 directory, with the following file structure:\nHands-on_Ex1\n└── data\n    ├── aspatial\n    │   └── listings.csv\n    └── geospatial\n        ├── CyclingPathGazette.cpg\n        ├── CyclingPathGazette.dbf\n        ├── CyclingPathGazette.lyr\n        ├── CyclingPathGazette.prj\n        ├── CyclingPathGazette.sbn\n        ├── CyclingPathGazette.sbx\n        ├── CyclingPathGazette.shp\n        ├── CyclingPathGazette.shp.xml\n        ├── CyclingPathGazette.shx\n        ├── MP14_SUBZONE_WEB_PL.dbf\n        ├── MP14_SUBZONE_WEB_PL.prj\n        ├── MP14_SUBZONE_WEB_PL.sbn\n        ├── MP14_SUBZONE_WEB_PL.sbx\n        ├── MP14_SUBZONE_WEB_PL.shp\n        ├── MP14_SUBZONE_WEB_PL.shp.xml\n        ├── MP14_SUBZONE_WEB_PL.shx\n        └── PreSchoolsLocation.kml"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1.html#installing-r-packages",
    "href": "Hands-on_Ex1/Hands-on_Ex1.html#installing-r-packages",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Installing R packages",
    "text": "Installing R packages\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#preparing-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#preparing-the-data-sets",
    "title": "Hands-on Exercise 2: Work in Progress",
    "section": "Preparing the data sets",
    "text": "Preparing the data sets\nAdd what data sets are used"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#installing-r-packages",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#installing-r-packages",
    "title": "Hands-on Exercise 2: Work in Progress",
    "section": "Installing R packages",
    "text": "Installing R packages\nWhat R packages are needed?"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#importing-the-origin-and-destination-data",
    "href": "In-class_Ex1/In-class_Ex1.html#importing-the-origin-and-destination-data",
    "title": "In-class Exercise 1",
    "section": "Importing the origin and destination data",
    "text": "Importing the origin and destination data\nFirstly, we will import the Passenger Volume By Origin Destination Bust Stops data set from LTA Data Mall by using read_csv .\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\nTo make it easier to process the PT codes, we will convert the origin and destination PT codes to factor data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\nNext, I want to investigate the commuter flows between 7-10am on weekdays. We need to use the interval 7 &lt;= time &lt;= 9 as the data with time = 9 contains data from 9am to just before 10am.\n\norigtrip_7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#importing-geospatial-data",
    "href": "In-class_Ex1/In-class_Ex1.html#importing-geospatial-data",
    "title": "In-class Exercise 1",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\nNext we need to import the bus stop locations so that we can correlate them from the PT codes from the origin and destination data from before.\n\nbustop &lt;- st_read(dsn = \"data/geospatial\",\n                  layer = \"BusStop\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `BusStop' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nSince these are just points, we also need some polygon data to figure out where in the Singapore map the bus locations correspond to:\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "",
    "text": "This hands-on exercise covers Chapter 2: Choropleth Mapping with R.\nI learned about the following:\n\nCreating thematic/choropleth maps with tmap\nQuantile and equal classification"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#preparing-the-datasets",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#preparing-the-datasets",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Preparing the datasets",
    "text": "Preparing the datasets\n\nGeospatial\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\n\n\n\nAspatial\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 from Department of Statistics, Singapore\n\nNext, is putting them under the Hands-on_Ex1 directory, with the following file structure:\nHands-on_Ex1\n└── data\n    ├── aspatial\n    │   └── respopagesextod2011to2020.csv\n    └── geospatial\n        ├── MP14_SUBZONE_WEB_PL.dbf\n        ├── MP14_SUBZONE_WEB_PL.prj\n        ├── MP14_SUBZONE_WEB_PL.sbn\n        ├── MP14_SUBZONE_WEB_PL.sbx\n        ├── MP14_SUBZONE_WEB_PL.shp\n        ├── MP14_SUBZONE_WEB_PL.shp.xml\n        └── MP14_SUBZONE_WEB_PL.shx"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#installing-r-packages",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#installing-r-packages",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Installing R packages",
    "text": "Installing R packages\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#importing-geospatial-data",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\nTo import the MPSZ data set to RStudio, I used the same code chunk in the previous exercise.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#importing-aspatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#importing-aspatial-data",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Importing aspatial data",
    "text": "Importing aspatial data\nThe csv data is an aspatial data so read_csv() must be used instead of st_read():\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#data-preparation",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#data-preparation",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Data preparation",
    "text": "Data preparation\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\nI don’t fully understand this entire code chunk yet but I know it filtered for data from 2020 only and did some aggregations based on the age groups, PA, and AZ. New fields like YOUNG and AGED .\nNext, I joined this data with the mpsz data via SZ. However, we still need to make sure that the SZ values are uppercase to match mpsz’s SUBZONE_N.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThen the 2 data sets can be joined.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLastly, write the rds of the combined data set.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n⚠️ This failed on the first try so I had to create the rds directory under data/ before trying again."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#using-qtm",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#using-qtm",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Using qtm()",
    "text": "Using qtm()\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nI tried to create an interactive map by using view instead of plot but an error about invalid polygons was returned."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#using-tmap-elements",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#using-tmap-elements",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Using tmap() elements",
    "text": "Using tmap() elements\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nFrom this part, I saw that with tm_shape as base, thematic maps can be created by doing + with the tmap actions. I will explore this later but I found a good reference on where to start: https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#classification-methods",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#classification-methods",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Classification methods",
    "text": "Classification methods\n\nQuantile\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nEqual\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nMy main takeaway for this is that the quantile classification deals with outliers better. In this data set, there is an outlier subzone. If we use equal classification, the map looks homogeneous and does not provide much information as it cannot be seen how the values from one subzone to the other differ.\nWith quantile classification, these differences can be seen more easily despite the outlier value."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#color-scheme",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#color-scheme",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Color Scheme",
    "text": "Color Scheme\nThe color scheme can be changed by specifying the palette in tm_fill() like below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nMore colors can be found when running tmaptools::palette_explorer() in the console. However, it requires shiny and shinyjs to work. This is a wonderful tool as it can also simulate how the color schemes look from the perspective of people with color blindness. As these maps aim to communicate, it is important for the color schemes chosen to not just be beautiful, but also inclusive."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#map-layouts",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#map-layouts",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Map Layouts",
    "text": "Map Layouts\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nAdding legends to maps is very useful as it provides additional information. However, this feature should not be abused to add multiple visualizations as legend as it can cause more confusion if there is too much information to present.\nMap style can also be changed and it is useful to enhance the visual presentation. After doing some research, I found the other available styles in https://cran.r-project.org/web/packages/tmap/vignettes/tmap-changes.html.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tmap_style(\"natural\")\n\n\n\n\nIn this example, I used the natural style to make it look like the map is surrounded by water (as it is naturally). Adding “furnitures” like compass and scale can also provide more perspective."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#smaller-maps",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#smaller-maps",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Smaller Maps",
    "text": "Smaller Maps\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nI don’t find this very useful as the maps rendered might be too small to inspect. However, the facets with the region can be useful to see the data based on region.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Greens\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#mapping-according-to-criterion",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#mapping-according-to-criterion",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Mapping According to Criterion",
    "text": "Mapping According to Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Greens\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nI find this very useful especially if we just want to map a subset of the data. This can be used when we want to highlight information on certain regions."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "This hands-on exercise covers Chapter 1: Data Wrangling with R.\nI learned about the following:\n\nPublic Data Sets like the ones on data.gov.sg, LTADataMall, and InsideAirbnb.\nHow to import data sets into RStudio\nWrangling geospatial data in using different R packages like sf, tidyverse, etc.\nCreating thematic/choropleth maps with tmap"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#preparing-the-data-sets",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#preparing-the-data-sets",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Preparing the data sets",
    "text": "Preparing the data sets\nFirst, I downloaded the different data sets needed in this exercise.\n\nGeospatial\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\n\n\n\nAspatial\n\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\nNext, is putting them under the Hands-on_Ex1 directory, with the following file structure:\nHands-on_Ex1\n└── data\n    ├── aspatial\n    │   └── listings.csv\n    └── geospatial\n        ├── CyclingPathGazette.cpg\n        ├── CyclingPathGazette.dbf\n        ├── CyclingPathGazette.lyr\n        ├── CyclingPathGazette.prj\n        ├── CyclingPathGazette.sbn\n        ├── CyclingPathGazette.sbx\n        ├── CyclingPathGazette.shp\n        ├── CyclingPathGazette.shp.xml\n        ├── CyclingPathGazette.shx\n        ├── MP14_SUBZONE_WEB_PL.dbf\n        ├── MP14_SUBZONE_WEB_PL.prj\n        ├── MP14_SUBZONE_WEB_PL.sbn\n        ├── MP14_SUBZONE_WEB_PL.sbx\n        ├── MP14_SUBZONE_WEB_PL.shp\n        ├── MP14_SUBZONE_WEB_PL.shp.xml\n        ├── MP14_SUBZONE_WEB_PL.shx\n        └── PreSchoolsLocation.kml"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#installing-r-packages",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#installing-r-packages",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Installing R packages",
    "text": "Installing R packages\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#master-plan-2014-subzone-boundary-web",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#master-plan-2014-subzone-boundary-web",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Master Plan 2014 Subzone Boundary (Web)",
    "text": "Master Plan 2014 Subzone Boundary (Web)\nTo import the data set to RStudio, I used st_read() :\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nI encountered the error below along the way:\nCannot open layer MasterPlan2014SubzoneBoundaryWebKML\nThis is because I originally downloaded the kml file instead of the shp file. After using the shp file, the st_read() succeeded.\n\nℹ️ My biggest take-away for this is that st_read reads shp data set by default. (this would be debunked later)\n\nAfter running the code, we should see the mpsz data in the environment."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#cycling-path-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#cycling-path-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Cycling Path Data",
    "text": "Cycling Path Data\nEquipped with my learning from the previous step, I was able to quickly figure out that importing this data set can be done by simply changing the layer parameter from the previous code:\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nHowever, the difference is that this geometry has polyline features, while the previous has polygon features."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#pre-schools-location-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#pre-schools-location-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Pre-Schools Location Data",
    "text": "Pre-Schools Location Data\nUnlike the others, this data set is in kml format instead of shp format. I used the following code to import:\n\npreschool &lt;- st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nℹ️ Contrary to my previous take-away, st_read() can read kml files by default. In fact, reading shp files require more parameters like dsn and layer."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#checking-the-geometry-of-data-frames",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#checking-the-geometry-of-data-frames",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Checking the geometry of data frames",
    "text": "Checking the geometry of data frames\nUsing st_geometry() returns information about the geometry of the data frame.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nIt gave the same geometric information as when importing the shape data but with additional details like the first 5 geometries."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#getting-overview-of-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#getting-overview-of-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Getting overview of geospatial data",
    "text": "Getting overview of geospatial data\nUsing glimpse() gives useful information about the columns, data types, values. For example:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThis will be very useful to scan for the available data and which columns are useful for analysis."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#revealing-complete-information-of-feature-objects",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#revealing-complete-information-of-feature-objects",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Revealing complete information of feature objects",
    "text": "Revealing complete information of feature objects\nUsing head() can give full information about objects in the data set. For example:\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThis will return the first 5 objects, and the number of objects can be set by specifying a value for n.\nAnother function that is useful for this purpose is tail(), which returns items from the end of the data set. For example:\n\ntail(mpsz, n=2)\n\nSimple feature collection with 2 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 23378.74 ymin: 48569.62 xmax: 28343.2 ymax: 50256.33\nProjected CRS: SVY21\n    OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n322      322          7  THE WHARVES    SBSZ07      N  SEMBAWANG         SB\n323      323          8 SENOKO NORTH    SBSZ08      N  SEMBAWANG         SB\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n322 NORTH REGION       NR 6D89875A351CF51C 2014-12-05 26945.07 49552.79\n323 NORTH REGION       NR A800CBEE879C1BF9 2014-12-05 24665.79 49482.60\n    SHAPE_Leng SHAPE_Area                       geometry\n322  11828.878    1635808 MULTIPOLYGON (((26219.89 50...\n323   7392.129    2241387 MULTIPOLYGON (((26047.11 50...\n\n\nThis returned the items on rows 322 and 323 instead of 1 and 2 if we were to use head().\nHowever, I wonder which use cases these functions would be useful as we can easily inspect the full data when looking at all the Environment Data in RStudio. 🤔"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#plotting-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Plotting Geospatial Data",
    "text": "Plotting Geospatial Data\n\nplot(mpsz, max.plot = 15)\n\n\n\n\nI was pleasantly surprised to find that the rendering of the plots was so fast! It only took 1 second or so on my machine for 300+ features and 15 fields. This is really useful for quick look of the data.\nTrying it on the cycling path data was also very fast though the result was not so useful for me as it needs to be overlayed with a map like above.\n\nplot(cyclingpath)\n\n\n\n\nI wonder how long it would take once we have larger data sets. 🤔\nAs someone not originally from Singapore, I am still familiarizing myself with the countries geography so I’ll plot the regions first.\n\nplot(mpsz['REGION_N'])\n\n\n\n\nThis can still be visualized better, especially the names in the legend got cut off. From the Help pages on RStudio, this function has a lot more parameters and I’ll explore it once I have more time."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#correcting-the-epsg-code",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#correcting-the-epsg-code",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Correcting the EPSG code",
    "text": "Correcting the EPSG code\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nI am not familiar with what the st_crs() returns and I wouldn’t have thought that EPSG needs correcting since I don’t have the domain knowledge. This is one of my biggest take away for this exercise."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#projection-transformation",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#projection-transformation",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Projection Transformation",
    "text": "Projection Transformation\nWhen using st_set_crs(), I got the warning below:\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for that\nAs such, the mpsz3414 data before may not be projected properly despite having the correct EPSG value.\nNext, I will transform the pre-school data:\n\npreschool3414 &lt;- st_transform(preschool, crs=3414)\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Importing and Converting Aspatial Data",
    "text": "Importing and Converting Aspatial Data\nFor aspatial data, I used read_csv() to import the data.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nFrom this, we have candidate geospatial fields that we can use, longitude and latitude.\nChecking the data contents of these field can confirm if we can really use the data.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nAfter confirming that longitude and latitude can be used as geospatial data, I transformed this data to geospatial data.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nChecking the new data frame, it was confirmed that it was transformed to a geospatial data.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#buffering",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#buffering",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Buffering",
    "text": "Buffering\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\nAfter seeing my classmate’s question on Piazza, I was also curious about the effect of nQuadSegs to the area. From the documentation, this is the number of segments created per quadrant.\nMy understanding of this is since each quadrant has 90 degrees, having nQuadSegs = 30 means 1 segment per 3 degrees. If this correct, my hypothesis is that the higher nQuadSegs is, the more accurate it is. This is because nQuadSegs=1 would be a square, and it becomes a polygon with more sides the higher nQuadSegs is. The higher nQuadSegs, the smoother the polygon becomes and it gets closer to being a circle.\nI’m testing the theory below and if my hypothesis is correct, the area should not differ much past nQuadSegs=180\n\nbuffer_cycling0 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 0)\nbuffer_cycling0$AREA &lt;- st_area(buffer_cycling0)\nsum(buffer_cycling0$AREA)\n\n1700331 [m^2]\n\n\n\nbuffer_cycling10 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 10)\nbuffer_cycling10$AREA &lt;- st_area(buffer_cycling10)\nsum(buffer_cycling10$AREA)\n\n1773584 [m^2]\n\n\n\nbuffer_cycling45 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 45)\nbuffer_cycling45$AREA &lt;- st_area(buffer_cycling45)\nsum(buffer_cycling45$AREA)\n\n1774421 [m^2]\n\n\n\nbuffer_cycling90 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 90)\nbuffer_cycling90$AREA &lt;- st_area(buffer_cycling90)\nsum(buffer_cycling90$AREA)\n\n1774454 [m^2]\n\n\n\nbuffer_cycling180 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 180)\nbuffer_cycling180$AREA &lt;- st_area(buffer_cycling180)\nsum(buffer_cycling180$AREA)\n\n1774462 [m^2]\n\n\n\nbuffer_cycling1800 &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 1800)\nbuffer_cycling1800$AREA &lt;- st_area(buffer_cycling1800)\nsum(buffer_cycling1800$AREA)\n\n1774465 [m^2]\n\n\nAs we can see, from 180 to 1800 the area only changed by 3m2 but the differences are larger in lower values. My conclusion is that the higher nQuadSegs, the more accurate the value we will get. However, the calculation took much longer. The extremely small accuracy benefit may not be worth the trade-off in most cases.\nThe result when using nQuadSegs of 30 is already very close to the result when it is 1800.\n\\[\n1774367/1774465 = 99.99\\%\n\\]"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#point-in-polygon-count",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Point-in-polygon count",
    "text": "Point-in-polygon count\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nThis means that there are subzones without pre-school while some have as many as 72.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe subzone with the most pre-schools is Tampines East.\nTo calculate the density of pre-schools:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nLet’s see the top 3 subzones with the highest pre-school density.\n\ntop_n(mpsz3414, 3, `PreSch Density`)\n\nSimple feature collection with 3 features and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25594.22 ymin: 28623.75 xmax: 29976.93 ymax: 48182.13\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO         SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N\n1       27          8             CECIL    DTSZ08      Y DOWNTOWN CORE\n2      278          3     MANDAI ESTATE    MDSZ03      N        MANDAI\n3      291          3 SEMBAWANG CENTRAL    SBSZ03      N     SEMBAWANG\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         DT CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.20\n2         MD   NORTH REGION       NR F6266F7368DBB9AB 2014-12-05 27082.70\n3         SB   NORTH REGION       NR 772A64AB9A93FC3A 2014-12-05 26268.73\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1 29011.33   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n2 45367.46   1633.708   143137.9 MULTIPOLYGON (((27119.56 45...            5\n3 47558.08   3955.118   962437.4 MULTIPOLYGON (((26311.14 46...           27\n            Area   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]\n2 143137.9 [m^2] 34.93134 [1/m^2]\n3 962437.4 [m^2] 28.05377 [1/m^2]\n\n\nDespite Tampines East having the most pre-schools, Cecil has the highest pre-school density. Tampines East might be much bigger than Cecil so its Pre-school Density is lower."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#changing-the-website-theme",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#changing-the-website-theme",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Changing the website theme",
    "text": "Changing the website theme\nAfter exploring Quarto docs, I found that we can change the theme. I decided on the zephyr theme as it looks most readable and aesthetic for me."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1A.html#issues-with-using-github-on-rstudio",
    "href": "Hands-on_Ex1/Hands-on_Ex1A.html#issues-with-using-github-on-rstudio",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "Issues with using Github on Rstudio",
    "text": "Issues with using Github on Rstudio\nIt was recommended to name the project with the convention &lt;github_username&gt;/ISSS624. However, due to restrictions on my machine, I had to deviate from this and create my project elsewhere.\nHence, I couldn’t use usethis::use_github() to setup my Github repository. However, as I use git Github intensively in my job, I did the setup manually myself to use the git functions on RStudio.\nI used these steps for the manual setup.\n\nCreate the repo manually on Github on https://github.com/kjcpaas/ISSS624\nAdd the Github remote on RStudio project\n&gt; git remote add origin git@github.com:kjcpaas/ISSS624.git\n&gt; git remote -v\norigin  git@github.com:kjcpaas/ISSS624.git (fetch)\norigin  git@github.com:kjcpaas/ISSS624.git (push)\nSet remote for head\n&gt; git remote set-head origin --auto\n&gt; git gc\n\nAfter all these, I was able to use the git functions on RStudio."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "",
    "text": "This hands-on exercise covers Chapter 8: Spatial Weights and Applications\nI learned about the following:\n\nCalculating spatial weights\nCalculating spatially lagged variables"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#preparing-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#preparing-the-data-sets",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Preparing the data sets",
    "text": "Preparing the data sets\nData sets used on this exercise were downloaded from E-learn.\n\nGeospatial\n\nHunan county boundary layer (shp format)\n\n\n\nAspatial\n\nHunan’s local development indicators in 2012 (csv format)\n\nNext, is putting them under the Hands-on_Ex2 directory, with the following file structure:\nHands-on_Ex2\n└── data\n    ├── aspatial\n    │   └── Hunan_2012.csv\n    └── geospatial\n        ├── Hunan.dbf\n        ├── Hunan.prj\n        ├── Hunan.qpj\n        ├── Hunan.shp\n        └── Hunan.shx"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#installing-r-packages",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#installing-r-packages",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Installing R packages",
    "text": "Installing R packages\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#importing-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#importing-data-sets",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Importing data sets",
    "text": "Importing data sets\nI used st_read() to import the geospatial shp data.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the previous exercises, we transformed the data with EPSG:3414. However, that is not applicable for this data set as we are not working with Singapore 🇸🇬 data set.\n\n\nAs with the previous exercises, I used read_csv() to import aspatial csv data.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#joining-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#joining-the-data-sets",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Joining the data sets",
    "text": "Joining the data sets\nIn the exercise, we have to join the 2 data sets using this code:\n\nhunan &lt;- left_join(hunan, hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n\n\n\nNote\n\n\n\nWe did not specify any columns to join by but left_join detected common column, County, so it joined the 2 data sets by this column.\nAt the end of this, we are left with 7 columns, which includes GDPPC from the aspatial data, which contains data for Gross Domestic Product per Capita."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-queen-contiguity-based-neighbors",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-queen-contiguity-based-neighbors",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Computing (QUEEN) contiguity based neighbors",
    "text": "Computing (QUEEN) contiguity based neighbors\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThis showed that there are 2 least connected regions, 30 and 65. Furthermore, there is 1 county is most connected, 85.\nBelow I analyzed these counties of interest\n\nLeast connected counties\nFirst, I checked the names of the least connected counties.\n\nhunan$County[c(30, 65)]\n\n[1] \"Xinhuang\" \"Linxiang\"\n\n\nThe least connected counties are Xinhuang in the West and Linxiang in the Northeast.\nIt makes sense for these counties to be least connected as they are counties that only have 1 neighbors each, according to the map.\n\nhunan$County[c(\n  wm_q[[30]],\n  wm_q[[65]]\n)]\n\n[1] \"Zhijiang\" \"Yueyang\" \n\n\nXinhuang borders Zhijiang to the East, while Linxiang borders Yueyang to the Southwest.\n\n\nMost connected county\n\nhunan$County[85]\n\n[1] \"Taoyuan\"\n\n\nThe most connected county is Taoyuan with 11 neighbors. It’s neighbors are:\n\nhunan$County[wm_q[[85]]]\n\n [1] \"Anxiang\"  \"Hanshou\"  \"Jinshi\"   \"Linli\"    \"Shimen\"   \"Yuanling\"\n [7] \"Anhua\"    \"Nan\"      \"Cili\"     \"Sangzhi\"  \"Taojiang\"\n\n\nThis makes perfect sense as Taoyuan is a relatively large, inner county."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#creating-rook-contiguity-based-neighbors",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#creating-rook-contiguity-based-neighbors",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Creating (ROOK) contiguity based neighbors",
    "text": "Creating (ROOK) contiguity based neighbors\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThis operation resulted in 8 fewer non-zero links. The most connected region, Taoyuan, has one less neighbor. However, the least connected regions stayed the same.\n\nsetdiff(hunan$County[wm_q[[85]]], hunan$County[wm_r[[85]]])\n\n[1] \"Nan\"\n\n\nNan is not considered a neighbor of Taoyuan using the Rook method. I check the documentation of poly2nb() to understand why.\n\n\n\n\n\n\nNote\n\n\n\nWhen setting queen=false, it requires boundaries to be more that just one point. On the other hand, with queen=true, it requires the objects to shared only a single point.\nAs such, having 8 less links means 8 pairs of counties only share a single point in their boundaries.\n\n\nLooking at the map, Nan indeed only touches Taoyuan at a single point:"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#visualising-contiguity-weights",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Visualising contiguity weights",
    "text": "Visualising contiguity weights\nTo plot the contiguity, we need to get the centroids of each county region. To get this for a single county, the following code can be used.\n\nhunan$geometry[1] %&gt;% st_centroid(.x)\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 112.1531 ymin: 29.44346 xmax: 112.1531 ymax: 29.44346\nGeodetic CRS:  WGS 84\n\n\nHowever, we needed to plot each longitude and latitude separately and create a new data frame for centroid coordinates from those. In order to do that, I copied the code chunks from the exercise.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting contiguity based neighbors map\nI plotted the Queen and Rooks maps on the same plot instead of the recommended way in the exercise. This is so I could see which neighbors where present in the Queen method but were not present in the Rook method.\nThey are the red lines in the map.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"blue\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#plotting-contiguity-based-neighbors-map",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#plotting-contiguity-based-neighbors-map",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Plotting contiguity based neighbors map",
    "text": "Plotting contiguity based neighbors map\nI plotted the Queen and Rooks maps on the same plot instead of the recommended way in the exercise. This is so I could see which neighbors where present in the Queen method but were not present in the Rook method.\nThey are the red lines in the map.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"blue\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#determining-cut-off-distance",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#determining-cut-off-distance",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Determining cut-off distance",
    "text": "Determining cut-off distance\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n\n\n\n\nNote\n\n\n\nThis means that the (centroids of) closest neighbors are 24.79 km apart while the farthest neighbors are 61.79 km apart.\nTo ensure that all counties will have at least one neighbors, we set the cut-off distance to the maximum distance, or 61.79 km."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-fixed-distance-weight-matrix",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Computing fixed distance weight matrix",
    "text": "Computing fixed distance weight matrix\nTo figure out the neighbors within the 62km distance (rounded out from the previous result), we use dnearneigh() .\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nTip\n\n\n\nThe average number of links here correspond to the average number of neighbors each county has.\nThat means for every county in China, there are 3.681818 other counties within 62 km of them, on average.\n\n\nThe example below gives a glimpse of neighbors each county has.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nAnother observation here is that Taoyuan, which had 11 contiguity-based neighbors, now only has 2 neighbors when using distance-based methods.\n\nwm_d62[88]\n\n[[1]]\n[1] 59 87"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#plotting-distance-based-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#plotting-distance-based-matrix",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Plotting distance-based matrix",
    "text": "Plotting distance-based matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n💡 I found out that plotting the red lines first before the black lines would just display black lines.\nThe technique of rendering the superset before the subset is a good technique to display the difference in the different plots.\nAfter realizing this, I applied the same technique in the Queen and Rook maps in [##Visualising contiguity weights]."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Computing adaptive distance weight matrix",
    "text": "Computing adaptive distance weight matrix\nThere are cases in which knowing the k-nearest neighbors is useful. It can be done by passing k to knearneigh:\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nPlotting this in a map and overlapping with the wm_d62 map, we can see that more neighbor links (in red) were added so that each county has 6 neighbors.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, add=TRUE, col=\"red\", length=0.08)\nplot(wm_d62, coords, add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#row-standardized-weights-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#row-standardized-weights-matrix",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Row-standardized weights matrix",
    "text": "Row-standardized weights matrix\nNext we assign the weight of 1/(# of neighbors) to each neighbor.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nNext I inspected some weights values to check if the results are consistent with our expectations.\n\nrswm_q$weights[c(1, 10, 30, 85)]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[2]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[3]]\n[1] 1\n\n[[4]]\n [1] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n [7] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n\n\nAs expected, their values are equal to 1/(# of neighbors).\nNext, the same was also done to derive a row standardised distance weight matrix.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\nChecking some of the matrix values:\n\nrswm_ids$weights[c(1, 10, 30, 85)]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[3]]\n[1] 0.02090587\n\n[[4]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n\n\n\n\n\n\n\nNote\n\n\n\nResults seem to be the same as when using nbdists() and lapply() in Weights based on IDW.\n\n\nFinally, we get some summary of the values.\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Spatial lag with row-standardized weights",
    "text": "Spatial lag with row-standardized weights\nFirst, I computed the spatially lagged values for each polygon.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nThe spatially lagged GDPPC values were appended to the Hunan data using the code below:\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, the GDPPC and spatial lag GDPPC were plotted for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe spatial correlation seems to appear more positive among counties in the East."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Spatial lag as a sum of neighboring values",
    "text": "Spatial lag as a sum of neighboring values\nThe spatial lag as a sum of neighboring values was calculated by assigning binary weights.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nThen, these weights were applied to the GDPPC values, and appending the lag_sum data to thehunan data set.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\nhunan &lt;- left_join(hunan, lag.res)\n\nLastly, I plotted the map.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe lag_sum plot looks more scattered compared to the lag plot."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-window-average",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-window-average",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Spatial window average",
    "text": "Spatial window average\nFirst, I added the diagonal element to the neighbor list.\n\nwm_qs &lt;- include.self(wm_q)\n\nNext, I calculated the weights for the new list.\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nThen, I creates the lag variable from the weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nSubsequently, I processed the data for further analysis.\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nI inspected the different lag values to figure out if there was any pattern. It was hard to do by eye on this table.\n\nhunan %&gt;%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nAfter all the data processing, I could finally plot the spatial window average.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe range of values became narrower, from 10,000 - 60,000 to 10,000 - 50,000. Furthermore, the map looks “cleaner” for the lag_window_average."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-window-sum",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-window-sum",
    "title": "Hands-on Exercisa 2A: Spatial Weights and Applications",
    "section": "Spatial window sum",
    "text": "Spatial window sum\nFirst, I added the diagonal element to the neighbor list.\n\nwm_qs &lt;- include.self(wm_q)\n\nThen, binary weights were calculated from this new list.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, data was processed for further analysis.\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nNext, I compared the lag_sum and w_sum values to check for patterns. Hard to see in this table format.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nFinally, I plotted the maps.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html",
    "title": "Hands-on Exercisa 2B: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "This hands-on exercise covers Chapter 9: Global Measures of Spatial Autocorrelation\nI learned about the following:\n\nSpatial correlation\nGlobal Spatial Autocorrelation (GSA) statistics\nLocal Indicator of Spatial Association (LISA) statistics\nGetis-Ord's Gi-statistics"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#preparing-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#preparing-the-data-sets",
    "title": "Hands-on Exercisa 2B: Global Measures of Spatial Autocorrelation",
    "section": "Preparing the data sets",
    "text": "Preparing the data sets\nData sets used on this exercise were downloaded from E-learn.\n\nGeospatial\n\nHunan county boundary layer (shp format)\n\n\n\nAspatial\n\nHunan’s local development indicators in 2012 (csv format)\n\nNext, is putting them under the Hands-on_Ex2 directory, with the following file structure:\nHands-on_Ex2\n└── data\n    ├── aspatial\n    │   └── Hunan_2012.csv\n    └── geospatial\n        ├── Hunan.dbf\n        ├── Hunan.prj\n        ├── Hunan.qpj\n        ├── Hunan.shp\n        └── Hunan.shx"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#installing-r-packages",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#installing-r-packages",
    "title": "Hands-on Exercisa 2B: Global Measures of Spatial Autocorrelation",
    "section": "Installing R packages",
    "text": "Installing R packages\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#importing-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#importing-data-sets",
    "title": "Hands-on Exercisa 2B: Global Measures of Spatial Autocorrelation",
    "section": "Importing data sets",
    "text": "Importing data sets\nI used st_read() to import the geospatial shp data.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the previous exercises, we transformed the data with EPSG:3414. However, that is not applicable for this data set as we are not working with Singapore 🇸🇬 data set.\n\n\nAs with the previous exercises, I used read_csv() to import aspatial csv data.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#joining-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#joining-the-data-sets",
    "title": "Hands-on Exercisa 2B: Global Measures of Spatial Autocorrelation",
    "section": "Joining the data sets",
    "text": "Joining the data sets\nIn the exercise, we have to join the 2 data sets using this code:\n\nhunan &lt;- left_join(hunan, hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n\n\n\nNote\n\n\n\nWe did not specify any columns to join by but left_join detected common column, County, so it joined the 2 data sets by this column.\nAt the end of this, we are left with 7 columns, which includes GDPPC from the aspatial data, which contains data for Gross Domestic Product per Capita."
  }
]