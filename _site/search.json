[
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#importing-the-data",
    "href": "In-class_Ex2/In-class_Ex2B.html#importing-the-data",
    "title": "In-class Exercise 2: GLSA",
    "section": "Importing the data",
    "text": "Importing the data\nFirst, we will import the geospatial data in shp format.\n\nhunan = st_read(dsn = \"data/geospatial\",\n                layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nSecond, we import the aspatial data Hunan_2012, which contains the GDP Per Capita (GDPPC) of Chinese counties in 2012.\n\nhunan2012 = read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#computing-gi",
    "href": "In-class_Ex2/In-class_Ex2B.html#computing-gi",
    "title": "In-class Exercise 2C: EHSA",
    "section": "Computing Gi*",
    "text": "Computing Gi*\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1)\nGDPPC_nb\n\nSimple feature collection with 88 features and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                                   nb\n1                  1, 2, 3, 4, 57, 85\n2                1, 2, 57, 58, 78, 85\n3                      1, 3, 4, 5, 85\n4                       1, 3, 4, 5, 6\n5                      3, 4, 5, 6, 85\n6                 4, 5, 6, 69, 75, 85\n7                   7, 67, 71, 74, 84\n8        8, 9, 46, 47, 56, 78, 80, 86\n9            8, 9, 66, 68, 78, 84, 86\n10 10, 16, 17, 19, 20, 22, 70, 72, 73\n                                                                                                           wt\n1                                      0.00000000, 0.01526149, 0.03515537, 0.02176677, 0.02836978, 0.01029857\n2                                      0.01526149, 0.00000000, 0.01601100, 0.01911052, 0.02327058, 0.01591694\n3                                                  0.03515537, 0.00000000, 0.04581089, 0.04116397, 0.01208437\n4                                                  0.02176677, 0.04581089, 0.00000000, 0.04637578, 0.01585302\n5                                                  0.04116397, 0.04637578, 0.00000000, 0.01896212, 0.01351099\n6                                      0.01585302, 0.01896212, 0.00000000, 0.02710909, 0.01140718, 0.01080890\n7                                                  0.00000000, 0.01621067, 0.01536702, 0.01133628, 0.01836488\n8              0.00000000, 0.01930410, 0.02675555, 0.02151751, 0.01076895, 0.02608065, 0.01519804, 0.01337412\n9                          0.01930410, 0.00000000, 0.01651371, 0.01798519, 0.01473155, 0.03015561, 0.01612293\n10 0.00000000, 0.02737233, 0.01390810, 0.01458881, 0.02156771, 0.02419268, 0.02350470, 0.01784174, 0.01621545\n     NAME_2  ID_3    NAME_3   ENGTYPE_3 Shape_Leng Shape_Area    County\n1   Changde 21098   Anxiang      County   1.869074 0.10056190   Anxiang\n2   Changde 21100   Hanshou      County   2.360691 0.19978745   Hanshou\n3   Changde 21101    Jinshi County City   1.425620 0.05302413    Jinshi\n4   Changde 21102        Li      County   3.474325 0.18908121        Li\n5   Changde 21103     Linli      County   2.289506 0.11450357     Linli\n6   Changde 21104    Shimen      County   4.171918 0.37194707    Shimen\n7  Changsha 21109   Liuyang County City   4.060579 0.46016789   Liuyang\n8  Changsha 21110 Ningxiang      County   3.323754 0.26614198 Ningxiang\n9  Changsha 21111 Wangcheng      County   2.292093 0.13049161 Wangcheng\n10 Chenzhou 21112     Anren      County   2.240739 0.13343936     Anren\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n# Did not work. Check after class\n#gi_stars &lt;- GDPPC_nb %&gt;%\n#  group_by(Year) %&gt;%\n#  mutate(gi_star = local_gstar_perm(\n#    GDPPC, nb, wt)) %&gt;%\n#  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html",
    "title": "Hands-on Exercise 2: Work in Progress",
    "section": "",
    "text": "In this hands-on exercise, I learned about the following:\n\nPut summarry of learnings here"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#preparing-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#preparing-the-data-sets",
    "title": "Hands-on Exercise 2: Work in Progress",
    "section": "Preparing the data sets",
    "text": "Preparing the data sets\nAdd what data sets are used"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#installing-r-packages",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#installing-r-packages",
    "title": "Hands-on Exercise 2: Work in Progress",
    "section": "Installing R packages",
    "text": "Installing R packages\nWhat R packages are needed?"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "This hands-on exercise covers Chapter 9: Global Measures of Spatial Autocorrelation\nI learned about the following:\n\nSpatial correlation using Moranâ€™s I and Gearyâ€™s C\nCorrelograms\n\n\n\nData sets used on this exercise were downloaded from E-learn.\n\n\n\nHunan county boundary layer (shp format)\n\n\n\n\n\nHunanâ€™s local development indicators in 2012 (csv format)\n\nNext, is putting them under the Hands-on_Ex2 directory, with the following file structure:\nHands-on_Ex2\nâ””â”€â”€ data\n    â”œâ”€â”€ aspatial\n    â”‚   â””â”€â”€ Hunan_2012.csv\n    â””â”€â”€ geospatial\n        â”œâ”€â”€ Hunan.dbf\n        â”œâ”€â”€ Hunan.prj\n        â”œâ”€â”€ Hunan.qpj\n        â”œâ”€â”€ Hunan.shp\n        â””â”€â”€ Hunan.shx\n\n\n\n\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#preparing-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#preparing-the-data-sets",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Data sets used on this exercise were downloaded from E-learn.\n\n\n\nHunan county boundary layer (shp format)\n\n\n\n\n\nHunanâ€™s local development indicators in 2012 (csv format)\n\nNext, is putting them under the Hands-on_Ex2 directory, with the following file structure:\nHands-on_Ex2\nâ””â”€â”€ data\n    â”œâ”€â”€ aspatial\n    â”‚   â””â”€â”€ Hunan_2012.csv\n    â””â”€â”€ geospatial\n        â”œâ”€â”€ Hunan.dbf\n        â”œâ”€â”€ Hunan.prj\n        â”œâ”€â”€ Hunan.qpj\n        â”œâ”€â”€ Hunan.shp\n        â””â”€â”€ Hunan.shx"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#installing-r-packages",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#installing-r-packages",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "I used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#importing-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#importing-data-sets",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Importing data sets",
    "text": "Importing data sets\nI used st_read() to import the geospatial shp data.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the previous exercises, we transformed the data with EPSG:3414. However, that is not applicable for this data set as we are not working with Singapore ðŸ‡¸ðŸ‡¬ data set.\n\n\nAs with the previous exercises, I used read_csv() to import aspatial csv data.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#joining-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#joining-the-data-sets",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Joining the data sets",
    "text": "Joining the data sets\nIn the exercise, we have to join the 2 data sets using this code:\n\nhunan &lt;- left_join(hunan, hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n\n\n\nNote\n\n\n\nWe did not specify any columns to join by but left_join detected common column, County, so it joined the 2 data sets by this column.\nAt the end of this, we are left with 7 columns, which includes GDPPC from the aspatial data, which contains data for Gross Domestic Product per Capita."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#visualizing-regional-development-indicator",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#visualizing-regional-development-indicator",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Visualizing Regional Development Indicator",
    "text": "Visualizing Regional Development Indicator\nNext, I plotted the GDPPC maps using equal interval classification and equal quantile classification.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nFirst, I built the neighbor list using Queen contiguity-based neighbors. This means the regions must share a border (minimum a point) to be considered neighbors.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#row-standardized-weights-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#row-standardized-weights-matrix",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Row-standardized weights matrix",
    "text": "Row-standardized weights matrix\nNext, I assigned weights to each neighboring county with value 1/(# of neighbors). This could be done by using style=\"W\" to nb2listw().\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#global-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#global-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Moranâ€™s I",
    "text": "Global Spatial Autocorrelation: Moranâ€™s I\n\nMoranâ€™s I test\nNext, I used Moranâ€™s I statistical testing using moran.test().\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Moranâ€™s I value is 0.30075, which is greater than 0. This means that observations are clustered, and tend to be similar.\nThe p-value is also very close to 0, which indicates high confidence on the correlation.\n\n\n\n\nComputing Monte Carlo Moranâ€™s I\nNext, a Monte Carlo simulation was performed for the Moranâ€™s I statistic. 1000 simulations were performed by the code below:\n\nset.seed(1234)\nbperm = moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Moranâ€™s I value is 0.30075, same result as that of the Moranâ€™s I test. Similarly, it means that observations are clustered, and tend to be similar.\nThe p-value is also very close to 0, which indicates high confidence on the correlation.\n\n\n\n\nVisualizing Monte Carlo Moranâ€™s I\nFirst, I examined the statistics of the Monte Carlo Moranâ€™s I. I checked the mean, variance, and the quantiles.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nNext, I also plotted the histogram.\n\n\n\n\n\n\nImportant\n\n\n\nI plotted using ggplot2 as an additional challenge from the exercise.\n\n\n\nmc_results_df &lt;- data.frame(moran_i = bperm$res)\nggplot(mc_results_df, aes(x = moran_i)) +\n  geom_histogram(bins = 20, fill = \"grey\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"red\") +\n  labs(x = \"Sumilated Moran's I\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom this Monte Carlo simulations, results are skewed to the left, meaning most of the Moranâ€™s I simulations result in negative values. It means that in most simulation results, there is dispersion so there is no spatial correlation.\nThis is quite contradictory to the statistic from moran.test.\nHowever, as this is a simulation set using seed 1234, results could be different in other simulations because the sampling is different."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#global-spatial-autocorrelation-gearys",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#global-spatial-autocorrelation-gearys",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Gearyâ€™s",
    "text": "Global Spatial Autocorrelation: Gearyâ€™s\nNext I used Gearyâ€™s method for spatial correlation.\n\nGearyâ€™s C test\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nTip\n\n\n\nGearyâ€™s C statistic is 0.6907, which is less than 1. This means that observations are clustered, and tend to be similar. P-value is also very close to 0, suggesting high-confidence.\n\nIt is consistent with the conclusions in Moranâ€™s I test.\n\n\n\n\nComputing Monte Carlo Gearyâ€™s C\nSimilarly, I did permutation test via Monte Carlo simulations.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Moranâ€™s I value is 0.6907, same result as that of the Gearyâ€™s C test. Similarly, it means that observations are clustered, and tend to be similar.\nThe p-value is also very close to 0, which indicates high confidence on the correlation.\n\n\n\n\nVisualizing Monte Carlo Gearyâ€™s C\nFirst, I examined the statistics of the Monte Carlo Gearyâ€™s C. I checked the mean, variance, and the quantiles.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\nFinally, visualizing it.\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom this Monte Carlo simulations, results are quite balanced on 1, which makes it inconclusive as to the spatial clustering and dispersion.\nThis is quite contrary to the statistic resulting from geary.test(), which was more conclusive.\nHowever, as this is a simulation set using seed 1234, results could be different in other simulations because the sampling is different."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#compute-morans-i-correlogram",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Compute Moranâ€™s I correlogram",
    "text": "Compute Moranâ€™s I correlogram\nFirst, I generated the correlogram for Moransâ€™s I.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nThis did not provide me much information and I didnâ€™t know how to interpret it so I printed the full result.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nTip\n\n\n\nFrom my understanding, since Moranâ€™s I values are greater than 0 and highest on lag 1, it means that the spatial correlation is most significant the closer the regions are."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2B.html#compute-gearys-c-correlogram",
    "href": "Hands-on_Ex2/Hands-on_Ex2B.html#compute-gearys-c-correlogram",
    "title": "Hands-on Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "Compute Gearyâ€™s C correlogram",
    "text": "Compute Gearyâ€™s C correlogram\nNext, I generated the correlogram for Gearyâ€™s C.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nNext was to print the results.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Gearyâ€™s C values are closest to 0 on the lag distance 1. Similar to Compute Moranâ€™s I correlogram, the spatial correlation is strongest the closer the regions are.\nThe pattern is inverse of the Moranâ€™s I correlogram, which makes sense as Moranâ€™s I and Gearyâ€™s C trends are inverse of each other."
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html",
    "href": "Take-home_Ex1/Take-home_Ex1.html",
    "title": "Take Home Exercise 1: Geospatial Analysis for the Public Good",
    "section": "",
    "text": "The aim of this study is to uncover spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.\nThe main modes of analysis to be used here are Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA).\nIn doing these study, we will be looking at bus trips started during the hours below.\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nMore details about the study can be found here."
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#preparing-the-data-sets",
    "href": "Take-home_Ex1/Take-home_Ex1.html#preparing-the-data-sets",
    "title": "Take Home Exercise 1: Geospatial Analysis for the Public Good",
    "section": "Preparing the data sets",
    "text": "Preparing the data sets\n\nGeospatial\nThese data sets are in shp format.\n\nMaster Plan 2019 Subzone Boundary (Web), originally from data.gov.sg but used the one provided on E-learn.\nBus Stop Locations, available publicly from LTA DataMall\n\n\n\nAspatial\nThese data sets are in csv format.\n\nPassenger Volume By Origin Destination Bus Stops from LTA DataMall via API (need to request for access)\n\nAugust 2023\nSeptember 2023\nOctober 2023 - we will focus on this as the main data set"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#preparing-the-data-directory",
    "href": "Take-home_Ex1/Take-home_Ex1.html#preparing-the-data-directory",
    "title": "Take Home Exercise 1: Geospatial Analysis for the Public Good",
    "section": "Preparing the data/ directory",
    "text": "Preparing the data/ directory\nBefore starting our analysis, we have to organize the data sets in a directory.\n\nGeospatial data will be located under data/geospatial\nAspatial data will be located under data/aspatial\ndata/rds to be created to store data that we can reuse and to make our code reproduceable.\n\nFinally, we are left with the following file structure:\nTake-home_Ex1\nâ”œâ”€â”€ Take-home_Ex1.qmd\nâ””â”€â”€ data\n    â”œâ”€â”€ aspatial\n    â”‚   â”œâ”€â”€ origin_destination_bus_202308.csv\n    â”‚   â”œâ”€â”€ origin_destination_bus_202309.csv\n    â”‚   â””â”€â”€ origin_destination_bus_202310.csv\n    â”œâ”€â”€ geospatial\n    â”‚   â”œâ”€â”€ BusStop.cpg\n    â”‚   â”œâ”€â”€ BusStop.dbf\n    â”‚   â”œâ”€â”€ BusStop.lyr\n    â”‚   â”œâ”€â”€ BusStop.prj\n    â”‚   â”œâ”€â”€ BusStop.sbn\n    â”‚   â”œâ”€â”€ BusStop.sbx\n    â”‚   â”œâ”€â”€ BusStop.shp\n    â”‚   â”œâ”€â”€ BusStop.shp.xml\n    â”‚   â”œâ”€â”€ BusStop.shx\n    â”‚   â”œâ”€â”€ MPSZ-2019.cpg\n    â”‚   â”œâ”€â”€ MPSZ-2019.dbf\n    â”‚   â”œâ”€â”€ MPSZ-2019.prj\n    â”‚   â”œâ”€â”€ MPSZ-2019.qmd\n    â”‚   â”œâ”€â”€ MPSZ-2019.shp\n    â”‚   â””â”€â”€ MPSZ-2019.shx\n    â””â”€â”€ rds"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#setting-up-the-r-environment",
    "href": "Take-home_Ex1/Take-home_Ex1.html#setting-up-the-r-environment",
    "title": "Take Home Exercise 1: Geospatial Analysis for the Public Good",
    "section": "Setting Up the R Environment",
    "text": "Setting Up the R Environment\nAfter preparing the data sets, we can finally proceed to load the R packages needed for this study.\n\ntmap: for thematic mapping\nsf: for geospatial data handling\ntidyverse: for non-spatial data handling\nspdep: for spatial dependence analysis (weighting schemes, statistics)\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#importing-data-into-r-environment",
    "href": "Take-home_Ex1/Take-home_Ex1.html#importing-data-into-r-environment",
    "title": "Take Home Exercise 1: Geospatial Analysis for the Public Good",
    "section": "Importing data into R environment",
    "text": "Importing data into R environment\n\nBusStop data set\nThe BusStop data set is a in shp format. We can import it by using st_read() from the sf package.\n\nbusstops &lt;- st_read(dsn = \"data/geospatial\",\n                    layer = \"BusStop\")\n\nReading layer `BusStop' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Take-home_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\n\n\n\nTip\n\n\n\nAs this already uses SVY21 datum that is appropriate for Singapore ðŸ‡¸ðŸ‡¬ local context, we can proceed with using data on its own.\n\n\nNext, letâ€™s take a look at the available columns to identify which columns we can use for analysis. We will decide this later after looking at other data sets.\n\nglimpse(busstops)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338â€¦\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"Bâ€¦\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE INDâ€¦\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),â€¦\n\n\nLastly, letâ€™s do a quick plot to see a visual glimpse of the data.\n\nplot(busstops['BUS_STOP_N'])\n\n\n\n\nThis is not enough information to do the analysis as we are missing information on which regions of Singapore ðŸ‡¸ðŸ‡¬ the bus stops are located."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#importing-the-data",
    "href": "In-class_Ex2/In-class_Ex2A.html#importing-the-data",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Importing the data",
    "text": "Importing the data\nFirst, we will import the geospatial data in shp format.\n\nhunan = st_read(dsn = \"data/geospatial\",\n                layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nSecond, we import the aspatial data Hunan_2012, which contains the GDP Per Capita (GDPPC) of Chinese counties in 2012.\n\nhunan2012 = read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#combining-them-all-together",
    "href": "In-class_Ex2/In-class_Ex2A.html#combining-them-all-together",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Combining them all together",
    "text": "Combining them all together\nAs seen from the import above, each of the dataframes have 88 rows each. Each row corresponds to a record per county.\nHowever, we are already interested in the following columns:\n\nCounty\nGDPPC\n\n\nhunan &lt;- left_join(hunan, hunan2012)%&gt;%\n  select(7, 15)\n\n\n\n\n\n\n\nNote\n\n\n\nWe do not need to specify the columns to join as both dataframes have the County column so left_join() is able to detect that this is the column to join by."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#computing-local-morans-i",
    "href": "In-class_Ex2/In-class_Ex2A.html#computing-local-morans-i",
    "title": "In-class Exercise 2: LISA",
    "section": "Computing local Moranâ€™s I",
    "text": "Computing local Moranâ€™s I\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n      .before = 1) %&gt;%\n  unnest(local_moran)\nlisa\n\nSimple feature collection with 88 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 Ã— 17\n         ii        eii     var_ii    z_ii    p_ii p_ii_sim p_folded_sim skewness\n      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.00147 -0.00208   0.000455    0.0286 9.77e-1     0.86         0.43   -0.967\n 2  0.0259  -0.00121   0.0121      0.246  8.06e-1     0.96         0.48   -0.492\n 3 -0.0120  -0.0290    0.104       0.0526 9.58e-1     0.72         0.36    0.909\n 4  0.00102  0.0000335 0.00000409  0.489  6.25e-1     0.6          0.3     0.574\n 5  0.0148  -0.00491   0.00159     0.494  6.21e-1     0.56         0.28    1.26 \n 6 -0.0388  -0.0160    0.00484    -0.328  7.43e-1     0.94         0.47    0.637\n 7  3.37    -0.0767    1.89        2.51   1.22e-2     0.06         0.03    0.997\n 8  1.56    -0.00585   0.975       1.59   1.13e-1     0.18         0.09    0.768\n 9  4.42    -0.224     1.18        4.27   1.96e-5     0.02         0.01    0.740\n10 -0.399    0.0144    0.0637     -1.64   1.01e-1     0.14         0.07   -0.309\n# â„¹ 78 more rows\n# â„¹ 9 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;, geometry &lt;POLYGON [Â°]&gt;"
  },
  {
    "objectID": "Take-home_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "Take-home_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "This hands-on exercise covers Chapter 10: Local Measures of Spatial Autocorrelation\nI learned about the following:\n\nGlobal Spatial Autocorrelation (GSA) statistics\nLocal Indicator of Spatial Association (LISA) statistics\nGetis-Ordâ€™s Gi-statistics\n\n\n\nData sets used on this exercise were downloaded from E-learn.\n\n\n\nHunan county boundary layer (shp format)\n\n\n\n\n\nHunanâ€™s local development indicators in 2012 (csv format)\n\nNext, is putting them under the Hands-on_Ex2 directory, with the following file structure:\nHands-on_Ex2\nâ””â”€â”€ data\n    â”œâ”€â”€ aspatial\n    â”‚   â””â”€â”€ Hunan_2012.csv\n    â””â”€â”€ geospatial\n        â”œâ”€â”€ Hunan.dbf\n        â”œâ”€â”€ Hunan.prj\n        â”œâ”€â”€ Hunan.qpj\n        â”œâ”€â”€ Hunan.shp\n        â””â”€â”€ Hunan.shx\n\n\n\n\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#preparing-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#preparing-the-data-sets",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Data sets used on this exercise were downloaded from E-learn.\n\n\n\nHunan county boundary layer (shp format)\n\n\n\n\n\nHunanâ€™s local development indicators in 2012 (csv format)\n\nNext, is putting them under the Hands-on_Ex2 directory, with the following file structure:\nHands-on_Ex2\nâ””â”€â”€ data\n    â”œâ”€â”€ aspatial\n    â”‚   â””â”€â”€ Hunan_2012.csv\n    â””â”€â”€ geospatial\n        â”œâ”€â”€ Hunan.dbf\n        â”œâ”€â”€ Hunan.prj\n        â”œâ”€â”€ Hunan.qpj\n        â”œâ”€â”€ Hunan.shp\n        â””â”€â”€ Hunan.shx"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#installing-r-packages",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#installing-r-packages",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "I used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#importing-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#importing-data-sets",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Importing data sets",
    "text": "Importing data sets\nI used st_read() to import the geospatial shp data.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the previous exercises, we transformed the data with EPSG:3414. However, that is not applicable for this data set as we are not working with Singapore ðŸ‡¸ðŸ‡¬ data set.\n\n\nAs with the previous exercises, I used read_csv() to import aspatial csv data.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#joining-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#joining-the-data-sets",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Joining the data sets",
    "text": "Joining the data sets\nIn the exercise, we have to join the 2 data sets using this code:\n\nhunan &lt;- left_join(hunan, hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n\n\n\nNote\n\n\n\nWe did not specify any columns to join by but left_join detected common column, County, so it joined the 2 data sets by this column.\nAt the end of this, we are left with 7 columns, which includes GDPPC from the aspatial data, which contains data for Gross Domestic Product per Capita."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#visualizing-regional-development-indicator",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#visualizing-regional-development-indicator",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Visualizing Regional Development Indicator",
    "text": "Visualizing Regional Development Indicator\nNext, I plotted the GDPPC maps using equal interval classification and equal quantile classification.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nFirst, I built the neighbor list using Queen contiguity-based neighbors. This means the regions must share a border (minimum a point) to be considered neighbors.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#row-standardized-weights-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#row-standardized-weights-matrix",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Row-standardized weights matrix",
    "text": "Row-standardized weights matrix\nNext, I assigned weights to each neighboring county with value 1/(# of neighbors). This could be done by using style=\"W\" to nb2listw().\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#global-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#global-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Moranâ€™s I",
    "text": "Global Spatial Autocorrelation: Moranâ€™s I\n\nMoranâ€™s I test\nNext, I used Moranâ€™s I statistical testing using moran.test().\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Moranâ€™s I value is 0.30075, which is greater than 0. This means that observations are clustered, and tend to be similar.\nThe p-value is also very close to 0, which indicates high confidence on the correlation.\n\n\n\n\nComputing Monte Carlo Moranâ€™s I\nNext, a Monte Carlo simulation was performed for the Moranâ€™s I statistic. 1000 simulations were performed by the code below:\n\nset.seed(1234)\nbperm = moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Moranâ€™s I value is 0.30075, same result as that of the Moranâ€™s I test. Similarly, it means that observations are clustered, and tend to be similar.\nThe p-value is also very close to 0, which indicates high confidence on the correlation.\n\n\n\n\nVisualizing Monte Carlo Moranâ€™s I\nFirst, I examined the statistics of the Monte Carlo Moranâ€™s I. I checked the mean, variance, and the quantiles.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nNext, I also plotted the histogram.\n\n\n\n\n\n\nImportant\n\n\n\nI plotted using ggplot2 as an additional challenge from the exercise.\n\n\n\nmc_results_df &lt;- data.frame(moran_i = bperm$res)\nggplot(mc_results_df, aes(x = moran_i)) +\n  geom_histogram(bins = 20, fill = \"grey\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"red\") +\n  labs(x = \"Sumilated Moran's I\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom this Monte Carlo simulations, results are skewed to the left, meaning most of the Moranâ€™s I simulations result in negative values. It means that in most simulation results, there is dispersion so there is no spatial correlation.\nThis is quite contradictory to the statistic from moran.test.\nHowever, as this is a simulation set using seed 1234, results could be different in other simulations because the sampling is different."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#global-spatial-autocorrelation-gearys",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#global-spatial-autocorrelation-gearys",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Gearyâ€™s",
    "text": "Global Spatial Autocorrelation: Gearyâ€™s\nNext I used Gearyâ€™s method for spatial correlation.\n\nGearyâ€™s C test\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nTip\n\n\n\nGearyâ€™s C statistic is 0.6907, which is less than 1. This means that observations are clustered, and tend to be similar. P-value is also very close to 0, suggesting high-confidence.\n\nIt is consistent with the conclusions in Moranâ€™s I test.\n\n\n\n\nComputing Monte Carlo Gearyâ€™s C\nSimilarly, I did permutation test via Monte Carlo simulations.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Moranâ€™s I value is 0.6907, same result as that of the Gearyâ€™s C test. Similarly, it means that observations are clustered, and tend to be similar.\nThe p-value is also very close to 0, which indicates high confidence on the correlation.\n\n\n\n\nVisualizing Monte Carlo Gearyâ€™s C\nFirst, I examined the statistics of the Monte Carlo Gearyâ€™s C. I checked the mean, variance, and the quantiles.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\nFinally, visualizing it.\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom this Monte Carlo simulations, results are quite balanced on 1, which makes it inconclusive as to the spatial clustering and dispersion.\nThis is quite contrary to the statistic resulting from geary.test(), which was more conclusive.\nHowever, as this is a simulation set using seed 1234, results could be different in other simulations because the sampling is different."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#compute-morans-i-correlogram",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Compute Moranâ€™s I correlogram",
    "text": "Compute Moranâ€™s I correlogram\nFirst, I generated the correlogram for Moransâ€™s I.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nThis did not provide me much information and I didnâ€™t know how to interpret it so I printed the full result.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nTip\n\n\n\nFrom my understanding, since Moranâ€™s I values are greater than 0 and highest on lag 1, it means that the spatial correlation is most significant the closer the regions are."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#compute-gearys-c-correlogram",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#compute-gearys-c-correlogram",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Compute Gearyâ€™s C correlogram",
    "text": "Compute Gearyâ€™s C correlogram\nNext, I generated the correlogram for Gearyâ€™s C.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nNext was to print the results.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Gearyâ€™s C values are closest to 0 on the lag distance 1. Similar to Compute Moranâ€™s I correlogram, the spatial correlation is strongest the closer the regions are.\nThe pattern is inverse of the Moranâ€™s I correlogram, which makes sense as Moranâ€™s I and Gearyâ€™s C trends are inverse of each other."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#computing-local-morans-i",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#computing-local-morans-i",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Computing Local Moranâ€™s I",
    "text": "Computing Local Moranâ€™s I\nFirst, I started with computing local Moranâ€™s I values.\nThe code chunks below were used to compute local Moranâ€™s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nThis code chunk result in a matrix with columns:\n\nIi: the local Moranâ€™s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe local Moranâ€™s I values were inspected by:\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#mapping-local-morans-i",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#mapping-local-morans-i",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Mapping local Moranâ€™s I",
    "text": "Mapping local Moranâ€™s I\nBefore proceeding with the mapping, I appended localMI dataframe onto the hunan dataframe.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nThen, I plotted a cloropeth map of the local Moranâ€™s I values and the p-values using tmap functions. These maps were plotted side by side for easier analysis.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#plotting-moran-scatterplot",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#plotting-moran-scatterplot",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Plotting Moran scatterplot",
    "text": "Plotting Moran scatterplot\nIn order to do this, I have to plot the Moranâ€™s I scatterplot first. This can be via moran.plot().\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis can be be interpreted such that the counties on the upper-right quadrant (e.g., Shaosan, Ningxian, Liuyang, Wangchen, Changsa) are within an affluent region, i.e., cluster of counties with high GDP per capita.\nSome other counties of interest are Zixing and Lengshuijiang, which are more affluent than their neighbors. Lastly, Pingjian is less affluent compared to its neighbors."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#plotting-moran-scatterplot-with-standardized-variable",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#plotting-moran-scatterplot-with-standardized-variable",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Plotting Moran scatterplot with standardized variable",
    "text": "Plotting Moran scatterplot with standardized variable\nNext is to scale the plot by normalizing the axes, which should align the axes to 0. scale() was used for this purpose.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nAfter scaling, I replotted the scatterplot.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#preparing-lisa-map-classes",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Preparing LISA map classes",
    "text": "Preparing LISA map classes\nTo prepare LISA cluster map, I had to first create a numeric vector with the same number of elements as localMI, which is 88.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext was to compute the lag values and centering on the mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)\n\nSimilarly, i also centered the local Moranâ€™s I values around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nI also set the significant value to 0.05 as per standards.\n\nsignif &lt;- 0.05\n\nThen, I defined the low-low (1), low-high (2), high-low (3) and high-high (4) categories. This corresponds to the quadrants in the scatterplot from Plotting Moran scatterplot.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4\n\nLastly, was to add a category for non-significant Moranâ€™s I values.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#plotting-lisa-map",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#plotting-lisa-map",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Plotting LISA map",
    "text": "Plotting LISA map\nAfter preparing the classes, I could finally plot the LISA map. As with the other maps so far, I used tmap() functions to created this map.\nFor easier analysis, I plotted the LISA map next to the GDPPC map.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI was expecting the 2 standalone orange counties from the GDPPC map (Zixing and Lengshuijiang) to be part of the high-low category. This is because they are relatively more affluent than their neighbors.\nThey were also on the high-low quadrant in the scatterplot. Hence, this result was surprising for me.\nA possible explanation for this is that their GDPPC are just a little bit higher than 60,000, while their neighbors are in the high 50,000s. Visually, they distinct but a closer look at the number might reveal that the values are not really far-off.\n\n\nI also plotted the local Moranâ€™s I values and p-values side by side again to find clues as to why.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs I mentioned, Zixing and Lengshuijiang were part of the high-low category as I originally expected.\nThe p-value provides a sound explanation why. This is because the p-values for these counties are 0.100 or more, which is more than the significance value that was set, which was 0.05.\nWe can say that the p-value map can be use as a filter such that those counties with p-values greater than the significance value are considered insignificant, and only those are not included in this group will be categorized."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#deriving-spatial-weight-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#deriving-spatial-weight-matrix",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Deriving spatial weight matrix",
    "text": "Deriving spatial weight matrix\n\n\n\n\n\n\nImportant\n\n\n\nThe code chunks used in this part are the same as the ones used in Hands-on Exercise 2A: Spatial Weights and Applications. I didnâ€™t dive deep into these part as these was already learned.\nFor this exercise, binary spatial weights are used.\n\n\nIn order to calculate the spatial weights, I needed to get determine the cut-off distance first. This was done by deriving the centroids and calculating the distances to the nearest neighbor for each county.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\nThese are the same steps as in [Hands-on Exercise 2A: Spatial Weights and Applications](/Hands-on_Ex2/Hands-on_Ex2A.html#determining-cut-off-distance), where we determined the cut-off distance to be 62km.\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nFinally, the spatial weights matrix can be generated.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nAs in the previous exercise, we could standardize the number of neighbors. This is because denser areas have more neighbors, while rural areas have less.\nThe code chunks below demonstrates how to standardize to 8 neighbors.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#gi-statistics-with-using-fixed-distance-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#gi-statistics-with-using-fixed-distance-weights",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Gi statistics with using fixed distance weights",
    "text": "Gi statistics with using fixed distance weights\nContinuing from the steps above, I looked at two cases. In this part, I used the fixed distance weights.\nFirst, I calculated the Gi statistics using the fixed distance weights.\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nNext is to add the Gi statistics to the hunan data frame.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nFinally, we could map the Gi values.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere is a cluster of counties with high GDDPC in the Eastern part of China.\nA striking observation is that the other orange cities outside of this cluster are cold in the local Gi map. This means that they are surrounded by counties with low GDPPC.\nThere should be caution when interpreting the map on the right as it is not intuitive because the values are actually based on the neighbors, and not the counties themselves."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2C.html#gi-statistics-with-using-adaptive-distance-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2C.html#gi-statistics-with-using-adaptive-distance-weights",
    "title": "Hands-on Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Gi statistics with using adaptive distance weights",
    "text": "Gi statistics with using adaptive distance weights\nNext we calculate the Gi statistics using adaptive distance weights.\nThe steps are the same as in Gi statistics with using fixed distance weights but instead using the adaptive weights (knn_lw) instead of the fixed weights(wm62_lw).\nFirst was to calculate the Gi statistics.\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\ngi.adaptive\n\n [1]  0.274428799  0.300225037  0.030447697 -0.009771412 -0.033921570\n [6] -0.154780126  4.034649782  2.057586016  4.378892586  1.479129376\n[11]  0.761743842 -0.648205275 -0.773677838  0.589236922  1.040407601\n[16]  0.368526533 -0.604240867 -0.241840937  0.031714037 -0.110547691\n[21]  0.761314356  1.175580259 -0.884714136 -0.860993329 -1.643096490\n[26] -1.290687016 -1.422253022 -0.675281508 -1.719511109 -1.210266137\n[31] -1.300914263 -1.599085669 -1.298761870 -1.836622587  1.637619520\n[36] -0.721435309 -1.958848641 -1.665195897 -1.868014845 -1.183536130\n[41] -0.169560764 -2.084882362 -2.181780084 -2.081025645 -0.499000625\n[46]  2.194733590  2.495469794 -1.695557884 -0.745540634 -1.193763093\n[51] -1.821073681 -1.894085866 -1.570969008 -1.055766446 -1.299966539\n[56] -0.201823610  0.498063690  0.581955247 -0.876827566 -0.955484907\n[61] -0.723004897 -0.790993867 -0.183585082  1.129758266  2.271097895\n[66]  3.047193741  4.995149600  4.022126163 -0.313165513  0.384924896\n[71]  3.018245449  0.561045961  0.210102660  4.365942776 -1.210175378\n[76]  2.391729501 -1.188720061  3.068344267 -0.600223372  1.046676007\n[81] -1.427632954 -0.156355526  1.176546366  3.726230897 -0.327758027\n[86]  2.972571047 -1.009008013 -0.989393051\nattr(,\"internals\")\n              Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.09720587 0.09195402 0.0003662397  0.274428799   7.837551e-01\n [2,] 0.09769063 0.09195402 0.0003651040  0.300225037   7.640055e-01\n [3,] 0.09253816 0.09195402 0.0003680612  0.030447697   9.757100e-01\n [4,] 0.09176695 0.09195402 0.0003665281 -0.009771412   9.922037e-01\n [5,] 0.09130429 0.09195402 0.0003668767 -0.033921570   9.729397e-01\n [6,] 0.08898762 0.09195402 0.0003673079 -0.154780126   8.769947e-01\n [7,] 0.16751891 0.09195402 0.0003507748  4.034649782   5.468380e-05\n [8,] 0.13054918 0.09195402 0.0003518436  2.057586016   3.962989e-02\n [9,] 0.17277103 0.09195402 0.0003406253  4.378892586   1.192839e-05\n[10,] 0.12001759 0.09195402 0.0003599760  1.479129376   1.391057e-01\n[11,] 0.10633361 0.09195402 0.0003563487  0.761743842   4.462129e-01\n[12,] 0.07951853 0.09195402 0.0003680448 -0.648205275   5.168522e-01\n[13,] 0.07714548 0.09195402 0.0003663568 -0.773677838   4.391213e-01\n[14,] 0.10311529 0.09195402 0.0003587953  0.589236922   5.557024e-01\n[15,] 0.11178796 0.09195402 0.0003634216  1.040407601   2.981506e-01\n[16,] 0.09902122 0.09195402 0.0003677535  0.368526533   7.124807e-01\n[17,] 0.08068910 0.09195402 0.0003475655 -0.604240867   5.456835e-01\n[18,] 0.08732412 0.09195402 0.0003665092 -0.241840937   8.089034e-01\n[19,] 0.09256190 0.09195402 0.0003673900  0.031714037   9.747001e-01\n[20,] 0.08984049 0.09195402 0.0003655276 -0.110547691   9.119750e-01\n[21,] 0.10653391 0.09195402 0.0003667585  0.761314356   4.464693e-01\n[22,] 0.11447605 0.09195402 0.0003670374  1.175580259   2.397626e-01\n[23,] 0.07508563 0.09195402 0.0003635312 -0.884714136   3.763108e-01\n[24,] 0.07555112 0.09195402 0.0003629457 -0.860993329   3.892417e-01\n[25,] 0.06043622 0.09195402 0.0003679474 -1.643096490   1.003630e-01\n[26,] 0.06742593 0.09195402 0.0003611483 -1.290687016   1.968122e-01\n[27,] 0.06478946 0.09195402 0.0003647974 -1.422253022   1.549528e-01\n[28,] 0.07912867 0.09195402 0.0003607191 -0.675281508   4.994969e-01\n[29,] 0.05932898 0.09195402 0.0003599915 -1.719511109   8.552135e-02\n[30,] 0.06893033 0.09195402 0.0003618998 -1.210266137   2.261768e-01\n[31,] 0.06724327 0.09195402 0.0003608067 -1.300914263   1.932878e-01\n[32,] 0.06134370 0.09195402 0.0003664310 -1.599085669   1.098016e-01\n[33,] 0.06714525 0.09195402 0.0003648812 -1.298761870   1.940257e-01\n[34,] 0.05762358 0.09195402 0.0003493969 -1.836622587   6.626563e-02\n[35,] 0.12317148 0.09195402 0.0003633868  1.637619520   1.015011e-01\n[36,] 0.07825698 0.09195402 0.0003604615 -0.721435309   4.706417e-01\n[37,] 0.05490035 0.09195402 0.0003578169 -1.958848641   5.013052e-02\n[38,] 0.06013762 0.09195402 0.0003650661 -1.665195897   9.587368e-02\n[39,] 0.05649408 0.09195402 0.0003603425 -1.868014845   6.176000e-02\n[40,] 0.06958160 0.09195402 0.0003573248 -1.183536130   2.365967e-01\n[41,] 0.08870667 0.09195402 0.0003667818 -0.169560764   8.653556e-01\n[42,] 0.05226797 0.09195402 0.0003623370 -2.084882362   3.707998e-02\n[43,] 0.05058836 0.09195402 0.0003594662 -2.181780084   2.912577e-02\n[44,] 0.05256094 0.09195402 0.0003583316 -2.081025645   3.743156e-02\n[45,] 0.08249954 0.09195402 0.0003589829 -0.499000625   6.177789e-01\n[46,] 0.13351191 0.09195402 0.0003585448  2.194733590   2.818271e-02\n[47,] 0.13980943 0.09195402 0.0003677540  2.495469794   1.257905e-02\n[48,] 0.05972453 0.09195402 0.0003613115 -1.695557884   8.996964e-02\n[49,] 0.07779955 0.09195402 0.0003604495 -0.745540634   4.559450e-01\n[50,] 0.06933428 0.09195402 0.0003590369 -1.193763093   2.325707e-01\n[51,] 0.05717238 0.09195402 0.0003647919 -1.821073681   6.859566e-02\n[52,] 0.05561872 0.09195402 0.0003680088 -1.894085866   5.821361e-02\n[53,] 0.06225124 0.09195402 0.0003574860 -1.570969008   1.161898e-01\n[54,] 0.07183294 0.09195402 0.0003632178 -1.055766446   2.910749e-01\n[55,] 0.06738016 0.09195402 0.0003573408 -1.299966539   1.936124e-01\n[56,] 0.08811771 0.09195402 0.0003613143 -0.201823610   8.400546e-01\n[57,] 0.10147288 0.09195402 0.0003652580  0.498063690   6.184392e-01\n[58,] 0.10310390 0.09195402 0.0003670801  0.581955247   5.605968e-01\n[59,] 0.07526754 0.09195402 0.0003621606 -0.876827566   3.805803e-01\n[60,] 0.07370784 0.09195402 0.0003646671 -0.955484907   3.393325e-01\n[61,] 0.07823737 0.09195402 0.0003599264 -0.723004897   4.696769e-01\n[62,] 0.07683091 0.09195402 0.0003655412 -0.790993867   4.289476e-01\n[63,] 0.08846487 0.09195402 0.0003612141 -0.183585082   8.543390e-01\n[64,] 0.11362359 0.09195402 0.0003678997  1.129758266   2.585781e-01\n[65,] 0.13552322 0.09195402 0.0003680335  2.271097895   2.314105e-02\n[66,] 0.15029172 0.09195402 0.0003665206  3.047193741   2.309888e-03\n[67,] 0.18713548 0.09195402 0.0003630845  4.995149600   5.879018e-07\n[68,] 0.16912010 0.09195402 0.0003680793  4.022126163   5.767515e-05\n[69,] 0.08597972 0.09195402 0.0003639373 -0.313165513   7.541549e-01\n[70,] 0.09930460 0.09195402 0.0003646621  0.384924896   7.002931e-01\n[71,] 0.14976364 0.09195402 0.0003668522  3.018245449   2.542429e-03\n[72,] 0.10267460 0.09195402 0.0003651229  0.561045961   5.747662e-01\n[73,] 0.09598415 0.09195402 0.0003679379  0.210102660   8.335875e-01\n[74,] 0.17564058 0.09195402 0.0003674137  4.365942776   1.265756e-05\n[75,] 0.06894940 0.09195402 0.0003613546 -1.210175378   2.262116e-01\n[76,] 0.13777971 0.09195402 0.0003671080  2.391729501   1.676920e-02\n[77,] 0.06924543 0.09195402 0.0003649397 -1.188720061   2.345498e-01\n[78,] 0.15052389 0.09195402 0.0003643681  3.068344267   2.152485e-03\n[79,] 0.08060684 0.09195402 0.0003573967 -0.600223372   5.483574e-01\n[80,] 0.11191592 0.09195402 0.0003637301  1.046676007   2.952490e-01\n[81,] 0.06473996 0.09195402 0.0003633737 -1.427632954   1.533975e-01\n[82,] 0.08896972 0.09195402 0.0003643008 -0.156355526   8.757528e-01\n[83,] 0.11452640 0.09195402 0.0003680752  1.176546366   2.393766e-01\n[84,] 0.15719339 0.09195402 0.0003065349  3.726230897   1.943644e-04\n[85,] 0.08568420 0.09195402 0.0003659344 -0.327758027   7.430946e-01\n[86,] 0.14892272 0.09195402 0.0003672891  2.972571047   2.953169e-03\n[87,] 0.07271488 0.09195402 0.0003635650 -1.009008013   3.129708e-01\n[88,] 0.07310269 0.09195402 0.0003630331 -0.989393051   3.224709e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = knn_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThen attaching the Gi statistics to the hunan data frame.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\nAnd finally, mapping it.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWith this plot, the clusters are a lot more clearer and we can clearly see that the East side is the hot spot in terms on GDDPC.\nHowever, we can also notice that on the Southwest, the most affluent county is a cold spot in the Gi map because it is surrounded by less affluent counties.\n\n\nAnother observation is that the Gi map using adaptive distance weights are less scattered and bigger compared to the Gi map using fixed distance weights."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "",
    "text": "This hands-on exercise covers Chapter 8: Spatial Weights and Applications\nI learned about the following:\n\nCalculating spatial weights\nCalculating spatially lagged variables"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#preparing-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#preparing-the-data-sets",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Preparing the data sets",
    "text": "Preparing the data sets\nData sets used on this exercise were downloaded from E-learn.\n\nGeospatial\n\nHunan county boundary layer (shp format)\n\n\n\nAspatial\n\nHunanâ€™s local development indicators in 2012 (csv format)\n\nNext, is putting them under the Hands-on_Ex2 directory, with the following file structure:\nHands-on_Ex2\nâ””â”€â”€ data\n    â”œâ”€â”€ aspatial\n    â”‚   â””â”€â”€ Hunan_2012.csv\n    â””â”€â”€ geospatial\n        â”œâ”€â”€ Hunan.dbf\n        â”œâ”€â”€ Hunan.prj\n        â”œâ”€â”€ Hunan.qpj\n        â”œâ”€â”€ Hunan.shp\n        â””â”€â”€ Hunan.shx"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#installing-r-packages",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#installing-r-packages",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Installing R packages",
    "text": "Installing R packages\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#importing-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#importing-data-sets",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Importing data sets",
    "text": "Importing data sets\nI used st_read() to import the geospatial shp data.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the previous exercises, we transformed the data with EPSG:3414. However, that is not applicable for this data set as we are not working with Singapore ðŸ‡¸ðŸ‡¬ data set.\n\n\nAs with the previous exercises, I used read_csv() to import aspatial csv data.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#joining-the-data-sets",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#joining-the-data-sets",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Joining the data sets",
    "text": "Joining the data sets\nIn the exercise, we have to join the 2 data sets using this code:\n\nhunan &lt;- left_join(hunan, hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n\n\n\nNote\n\n\n\nWe did not specify any columns to join by but left_join detected common column, County, so it joined the 2 data sets by this column.\nAt the end of this, we are left with 7 columns, which includes GDPPC from the aspatial data, which contains data for Gross Domestic Product per Capita."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-queen-contiguity-based-neighbors",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-queen-contiguity-based-neighbors",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Computing (QUEEN) contiguity based neighbors",
    "text": "Computing (QUEEN) contiguity based neighbors\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThis showed that there are 2 least connected regions, 30 and 65. Furthermore, there is 1 county is most connected, 85.\nBelow I analyzed these counties of interest\n\nLeast connected counties\nFirst, I checked the names of the least connected counties.\n\nhunan$County[c(30, 65)]\n\n[1] \"Xinhuang\" \"Linxiang\"\n\n\nThe least connected counties are Xinhuang in the West and Linxiang in the Northeast.\nIt makes sense for these counties to be least connected as they are counties that only have 1 neighbors each, according to the map.\n\nhunan$County[c(\n  wm_q[[30]],\n  wm_q[[65]]\n)]\n\n[1] \"Zhijiang\" \"Yueyang\" \n\n\nXinhuang borders Zhijiang to the East, while Linxiang borders Yueyang to the Southwest.\n\n\nMost connected county\n\nhunan$County[85]\n\n[1] \"Taoyuan\"\n\n\nThe most connected county is Taoyuan with 11 neighbors. Itâ€™s neighbors are:\n\nhunan$County[wm_q[[85]]]\n\n [1] \"Anxiang\"  \"Hanshou\"  \"Jinshi\"   \"Linli\"    \"Shimen\"   \"Yuanling\"\n [7] \"Anhua\"    \"Nan\"      \"Cili\"     \"Sangzhi\"  \"Taojiang\"\n\n\nThis makes perfect sense as Taoyuan is a relatively large, inner county."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#creating-rook-contiguity-based-neighbors",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#creating-rook-contiguity-based-neighbors",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Creating (ROOK) contiguity based neighbors",
    "text": "Creating (ROOK) contiguity based neighbors\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThis operation resulted in 8 fewer non-zero links. The most connected region, Taoyuan, has one less neighbor. However, the least connected regions stayed the same.\n\nsetdiff(hunan$County[wm_q[[85]]], hunan$County[wm_r[[85]]])\n\n[1] \"Nan\"\n\n\nNan is not considered a neighbor of Taoyuan using the Rook method. I check the documentation of poly2nb() to understand why.\n\n\n\n\n\n\nNote\n\n\n\nWhen setting queen=false, it requires boundaries to be more that just one point. On the other hand, with queen=true, it requires the objects to shared only a single point.\nAs such, having 8 less links means 8 pairs of counties only share a single point in their boundaries.\n\n\nLooking at the map, Nan indeed only touches Taoyuan at a single point:"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#visualising-contiguity-weights",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Visualising contiguity weights",
    "text": "Visualising contiguity weights\nTo plot the contiguity, we need to get the centroids of each county region. To get this for a single county, the following code can be used.\n\nhunan$geometry[1] %&gt;% st_centroid(.x)\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 112.1531 ymin: 29.44346 xmax: 112.1531 ymax: 29.44346\nGeodetic CRS:  WGS 84\n\n\nHowever, we needed to plot each longitude and latitude separately and create a new data frame for centroid coordinates from those. In order to do that, I copied the code chunks from the exercise.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting contiguity based neighbors map\nI plotted the Queen and Rooks maps on the same plot instead of the recommended way in the exercise. This is so I could see which neighbors where present in the Queen method but were not present in the Rook method.\nThey are the red lines in the map.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"blue\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#determining-cut-off-distance",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#determining-cut-off-distance",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Determining cut-off distance",
    "text": "Determining cut-off distance\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n\n\n\n\nNote\n\n\n\nThis means that the (centroids of) closest neighbors are 24.79 km apart while the farthest neighbors are 61.79 km apart.\nTo ensure that all counties will have at least one neighbors, we set the cut-off distance to the maximum distance, or 61.79 km."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-fixed-distance-weight-matrix",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Computing fixed distance weight matrix",
    "text": "Computing fixed distance weight matrix\nTo figure out the neighbors within the 62km distance (rounded out from the previous result), we use dnearneigh() .\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nTip\n\n\n\nThe average number of links here correspond to the average number of neighbors each county has.\nThat means for every county in China, there are 3.681818 other counties within 62 km of them, on average.\n\n\nThe example below gives a glimpse of neighbors each county has.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nAnother observation here is that Taoyuan, which had 11 contiguity-based neighbors, now only has 2 neighbors when using distance-based methods.\n\nwm_d62[88]\n\n[[1]]\n[1] 59 87"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#plotting-distance-based-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#plotting-distance-based-matrix",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Plotting distance-based matrix",
    "text": "Plotting distance-based matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nðŸ’¡ I found out that plotting the red lines first before the black lines would just display black lines.\nThe technique of rendering the superset before the subset is a good technique to display the difference in the different plots.\nAfter realizing this, I applied the same technique in the Queen and Rook maps in [##Visualising contiguity weights]."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Computing adaptive distance weight matrix",
    "text": "Computing adaptive distance weight matrix\nThere are cases in which knowing the k-nearest neighbors is useful. It can be done by passing k to knearneigh:\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nPlotting this in a map and overlapping with the wm_d62 map, we can see that more neighbor links (in red) were added so that each county has 6 neighbors.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, add=TRUE, col=\"red\", length=0.08)\nplot(wm_d62, coords, add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#row-standardized-weights-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#row-standardized-weights-matrix",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Row-standardized weights matrix",
    "text": "Row-standardized weights matrix\nNext we assign the weight of 1/(# of neighbors) to each neighbor.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nNext I inspected some weights values to check if the results are consistent with our expectations.\n\nrswm_q$weights[c(1, 10, 30, 85)]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[2]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[3]]\n[1] 1\n\n[[4]]\n [1] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n [7] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n\n\nAs expected, their values are equal to 1/(# of neighbors).\nNext, the same was also done to derive a row standardised distance weight matrix.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\nChecking some of the matrix values:\n\nrswm_ids$weights[c(1, 10, 30, 85)]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[3]]\n[1] 0.02090587\n\n[[4]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n\n\n\n\n\n\n\nNote\n\n\n\nResults seem to be the same as when using nbdists() and lapply() in Weights based on IDW.\n\n\nFinally, we get some summary of the values.\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Spatial lag with row-standardized weights",
    "text": "Spatial lag with row-standardized weights\nFirst, I computed the spatially lagged values for each polygon.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nThe spatially lagged GDPPC values were appended to the Hunan data using the code below:\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, the GDPPC and spatial lag GDPPC were plotted for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe spatial correlation seems to appear more positive among counties in the East."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Spatial lag as a sum of neighboring values",
    "text": "Spatial lag as a sum of neighboring values\nThe spatial lag as a sum of neighboring values was calculated by assigning binary weights.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nThen, these weights were applied to the GDPPC values, and appending the lag_sum data to thehunan data set.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\nhunan &lt;- left_join(hunan, lag.res)\n\nLastly, I plotted the map.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe lag_sum plot looks more scattered compared to the lag plot."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-window-average",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-window-average",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Spatial window average",
    "text": "Spatial window average\nFirst, I added the diagonal element to the neighbor list.\n\nwm_qs &lt;- include.self(wm_q)\n\nNext, I calculated the weights for the new list.\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nThen, I creates the lag variable from the weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nSubsequently, I processed the data for further analysis.\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nI inspected the different lag values to figure out if there was any pattern. It was hard to do by eye on this table.\n\nhunan %&gt;%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523â€¦\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684â€¦\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,â€¦\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649â€¦\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288â€¦\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675â€¦\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,â€¦\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299â€¦\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688â€¦\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734â€¦\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117â€¦\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358â€¦\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143â€¦\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578â€¦\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394â€¦\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843â€¦\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259â€¦\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198â€¦\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007â€¦\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149â€¦\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, â€¦\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276â€¦\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,â€¦\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778â€¦\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858â€¦\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512â€¦\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842â€¦\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,â€¦\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561â€¦\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,â€¦\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485â€¦\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895â€¦\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661â€¦\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472â€¦\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,â€¦\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642â€¦\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317â€¦\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812â€¦\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305â€¦\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,â€¦\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254â€¦\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,â€¦\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345â€¦\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627â€¦\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275â€¦\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742â€¦\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783â€¦\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844â€¦\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206â€¦\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034â€¦\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712â€¦\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,â€¦\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521â€¦\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835â€¦\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499â€¦\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716â€¦\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074â€¦\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,â€¦\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661â€¦\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123â€¦\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892â€¦\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957â€¦\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,â€¦\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134â€¦\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418â€¦\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139â€¦\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152â€¦\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264â€¦\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017â€¦\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573â€¦\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346â€¦\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,â€¦\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324â€¦\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411â€¦\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,â€¦\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,â€¦\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318â€¦\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265â€¦\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207â€¦\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946â€¦\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513â€¦\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613â€¦\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963â€¦\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722â€¦\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855â€¦\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,â€¦\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,â€¦\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472â€¦\n\n\n\n\n\nAfter all the data processing, I could finally plot the spatial window average.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe range of values became narrower, from 10,000 - 60,000 to 10,000 - 50,000. Furthermore, the map looks â€œcleanerâ€ for the lag_window_average."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-window-sum",
    "href": "Hands-on_Ex2/Hands-on_Ex2A.html#spatial-window-sum",
    "title": "Hands-on Exercise 2A: Spatial Weights and Applications",
    "section": "Spatial window sum",
    "text": "Spatial window sum\nFirst, I added the diagonal element to the neighbor list.\n\nwm_qs &lt;- include.self(wm_q)\n\nThen, binary weights were calculated from this new list.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, data was processed for further analysis.\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nNext, I compared the lag_sum and w_sum values to check for patterns. Hard to see in this table format.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523â€¦\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684â€¦\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,â€¦\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649â€¦\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288â€¦\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675â€¦\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,â€¦\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299â€¦\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688â€¦\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734â€¦\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117â€¦\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358â€¦\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143â€¦\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578â€¦\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394â€¦\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843â€¦\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259â€¦\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198â€¦\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007â€¦\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149â€¦\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, â€¦\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276â€¦\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,â€¦\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778â€¦\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858â€¦\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512â€¦\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842â€¦\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,â€¦\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561â€¦\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,â€¦\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485â€¦\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895â€¦\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661â€¦\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472â€¦\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,â€¦\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642â€¦\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317â€¦\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812â€¦\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305â€¦\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,â€¦\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254â€¦\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,â€¦\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345â€¦\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627â€¦\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275â€¦\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742â€¦\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783â€¦\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844â€¦\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206â€¦\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034â€¦\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712â€¦\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,â€¦\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521â€¦\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835â€¦\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499â€¦\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716â€¦\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074â€¦\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,â€¦\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661â€¦\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123â€¦\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892â€¦\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957â€¦\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,â€¦\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134â€¦\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418â€¦\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139â€¦\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152â€¦\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264â€¦\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017â€¦\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573â€¦\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346â€¦\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,â€¦\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324â€¦\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411â€¦\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,â€¦\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,â€¦\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318â€¦\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265â€¦\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207â€¦\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946â€¦\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513â€¦\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613â€¦\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963â€¦\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722â€¦\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855â€¦\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,â€¦\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,â€¦\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472â€¦\n\n\n\n\n\nFinally, I plotted the maps.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html",
    "href": "In-class_Ex1/In-class_Ex1.html",
    "title": "In-class Exercise 1: Bus Commuter Flow by Origin",
    "section": "",
    "text": "In this exercise, we will learn how to create choropleth map from bus data and commuter data."
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#importing-the-origin-and-destination-data",
    "href": "In-class_Ex1/In-class_Ex1.html#importing-the-origin-and-destination-data",
    "title": "In-class Exercise 1: Bus Commuter Flow by Origin",
    "section": "Importing the origin and destination data",
    "text": "Importing the origin and destination data\nFirstly, we will import the Passenger Volume By Origin Destination Bust Stops data set from LTA Data Mall by using read_csv .\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\nTo make it easier to process the PT codes, we will convert the origin and destination PT codes to factor data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\nNext, I want to investigate the commuter flows between 7-10am on weekdays.\n\n\n\n\n\n\nTip\n\n\n\nWe need to use the interval 7 &lt;= time &lt;= 9 as the data with time = 9 contains data from 9am to just before 10am.\n\n\n\norigin7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nNext, we save the data in rds format for future use.\n\n\n\n\n\n\nImportant\n\n\n\nIn order for the code below to work, we need to create the rds/ directory under data/.\n\n\n\nwrite_rds(origin7_9, \"data/rds/origin7_9.rds\")\n\nIt can be imported back later on with read_rds().\n\norigin7_9 &lt;- read_rds(\"data/rds/origin7_9.rds\")"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#importing-geospatial-data",
    "href": "In-class_Ex1/In-class_Ex1.html#importing-geospatial-data",
    "title": "In-class Exercise 1: Bus Commuter Flow by Origin",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\nNext we need to import the bus stop locations so that we can correlate them from the PT codes from the origin and destination data from before.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                  layer = \"BusStop\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `BusStop' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nSince these are just points, we also need some polygon data to figure out where in the Singapore map the bus locations correspond to:\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html#combining-busstop-and-mpsz",
    "href": "In-class_Ex1/In-class_Ex1.html#combining-busstop-and-mpsz",
    "title": "In-class Exercise 1: Bus Commuter Flow by Origin",
    "section": "Combining busstop and mpsz",
    "text": "Combining busstop and mpsz\nWe first combine that 2 data frames by figuring out which polygon in mpsz each points in busstop are contained in.\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\nglimpse(busstop_mpsz)\n\nRows: 5,156\nColumns: 2\n$ BUS_STOP_N &lt;chr&gt; \"13099\", \"13089\", \"06151\", \"13211\", \"13139\", \"13109\", \"1311â€¦\n$ SUBZONE_C  &lt;chr&gt; \"RVSZ05\", \"RVSZ05\", \"SRSZ01\", \"SRSZ01\", \"SRSZ01\", \"SRSZ01\",â€¦\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nst_drop_geometry() removes the geometry from the data frame, making the data aspatial.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nbusstop_mpsz has 5 less items than busstop. This is because these bus stops are outside of Singapore ðŸ‡¸ðŸ‡¬ border.\nFor example, some bus routes start/end in Johor Bahru in Malaysia ðŸ‡²ðŸ‡¾.\n\n\nFinally, we now now which subzone each bus stop is located in.\nBefore proceeding, we should save the busstop_mpsz so we wonâ€™t need to recalculate it later on.\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.csv\")\n\nNext is to join the busstop_mpsz data with origin7_9.\n\norigin_data &lt;- left_join(origin7_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C)\n\nNext is to check for duplicate records.\n\nduplicate &lt;- origin_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nglimpse(duplicate)\n\nRows: 26\nColumns: 3\n$ ORIGIN_BS &lt;chr&gt; \"11009\", \"11009\", \"22501\", \"22501\", \"43709\", \"43709\", \"47201â€¦\n$ TRIPS     &lt;dbl&gt; 13826, 13826, 9743, 9743, 1118, 1118, 23998, 23998, 6218, 62â€¦\n$ ORIGIN_SZ &lt;chr&gt; \"QTSZ01\", \"QTSZ01\", \"JWSZ09\", \"JWSZ09\", \"BKSZ07\", \"BKSZ07\", â€¦\n\n\nIn this case, there are some duplicates so we need to clean it up further. This can be done using unique().\n\norigin_data &lt;- unique(origin_data)\n\nLetâ€™s check if the duplicates have been removed.\n\nduplicate &lt;- origin_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nglimpse(duplicate)\n\nRows: 0\nColumns: 3\n$ ORIGIN_BS &lt;chr&gt; \n$ TRIPS     &lt;dbl&gt; \n$ ORIGIN_SZ &lt;chr&gt; \n\n\nThe duplicates have been removed so we can proceed with merging origin_data with mpsz to figure out the subzone names on the bus stop locations.\n\nmpsz_origtrip &lt;- left_join(mpsz, \n                           origin_data,\n                           by = c(\"SUBZONE_C\" = \"ORIGIN_SZ\"))\n\nBefore proceeding, letâ€™s save this data as rds.\n\nwrite_rds(origin7_9, \"data/rds/origin7_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "",
    "text": "This hands-on exercise covers Chapter 2: Choropleth Mapping with R.\nI learned about the following:\n\nCreating thematic/choropleth maps with tmap\nQuantile and equal classification"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#preparing-the-datasets",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#preparing-the-datasets",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Preparing the datasets",
    "text": "Preparing the datasets\n\nGeospatial\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\n\n\n\nAspatial\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 from Department of Statistics, Singapore\n\nNext, is putting them under the Hands-on_Ex1 directory, with the following file structure:\nHands-on_Ex1\nâ””â”€â”€ data\n    â”œâ”€â”€ aspatial\n    â”‚   â””â”€â”€ respopagesextod2011to2020.csv\n    â””â”€â”€ geospatial\n        â”œâ”€â”€ MP14_SUBZONE_WEB_PL.dbf\n        â”œâ”€â”€ MP14_SUBZONE_WEB_PL.prj\n        â”œâ”€â”€ MP14_SUBZONE_WEB_PL.sbn\n        â”œâ”€â”€ MP14_SUBZONE_WEB_PL.sbx\n        â”œâ”€â”€ MP14_SUBZONE_WEB_PL.shp\n        â”œâ”€â”€ MP14_SUBZONE_WEB_PL.shp.xml\n        â””â”€â”€ MP14_SUBZONE_WEB_PL.shx"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#installing-r-packages",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#installing-r-packages",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Installing R packages",
    "text": "Installing R packages\nI used the code below to install the R packages used in the exercise:\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#importing-geospatial-data",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\nTo import the MPSZ data set to RStudio, I used the same code chunk in the previous exercise.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#importing-aspatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#importing-aspatial-data",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Importing aspatial data",
    "text": "Importing aspatial data\nThe csv data is an aspatial data so read_csv() must be used instead of st_read():\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#data-preparation",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#data-preparation",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Data preparation",
    "text": "Data preparation\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\nI donâ€™t fully understand this entire code chunk yet but I know it filtered for data from 2020 only and did some aggregations based on the age groups, PA, and AZ. New fields like YOUNG and AGED .\nNext, I joined this data with the mpsz data via SZ. However, we still need to make sure that the SZ values are uppercase to match mpszâ€™s SUBZONE_N.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThen the 2 data sets can be joined.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLastly, write the rds of the combined data set.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\nâš ï¸ This failed on the first try so I had to create the rds directory under data/ before trying again."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#using-qtm",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#using-qtm",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Using qtm()",
    "text": "Using qtm()\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nI tried to create an interactive map by using view instead of plot but an error about invalid polygons was returned."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#using-tmap-elements",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#using-tmap-elements",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Using tmap() elements",
    "text": "Using tmap() elements\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nFrom this part, I saw that with tm_shape as base, thematic maps can be created by doing + with the tmap actions. I will explore this later but I found a good reference on where to start: https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#classification-methods",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#classification-methods",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Classification methods",
    "text": "Classification methods\n\nQuantile\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nEqual\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nMy main takeaway for this is that the quantile classification deals with outliers better. In this data set, there is an outlier subzone. If we use equal classification, the map looks homogeneous and does not provide much information as it cannot be seen how the values from one subzone to the other differ.\nWith quantile classification, these differences can be seen more easily despite the outlier value."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#color-scheme",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#color-scheme",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Color Scheme",
    "text": "Color Scheme\nThe color scheme can be changed by specifying the palette in tm_fill() like below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nMore colors can be found when running tmaptools::palette_explorer() in the console. However, it requires shiny and shinyjs to work. This is a wonderful tool as it can also simulate how the color schemes look from the perspective of people with color blindness. As these maps aim to communicate, it is important for the color schemes chosen to not just be beautiful, but also inclusive."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#map-layouts",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#map-layouts",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Map Layouts",
    "text": "Map Layouts\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nAdding legends to maps is very useful as it provides additional information. However, this feature should not be abused to add multiple visualizations as legend as it can cause more confusion if there is too much information to present.\nMap style can also be changed and it is useful to enhance the visual presentation. After doing some research, I found the other available styles in https://cran.r-project.org/web/packages/tmap/vignettes/tmap-changes.html.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tmap_style(\"natural\")\n\n\n\n\nIn this example, I used the natural style to make it look like the map is surrounded by water (as it is naturally). Adding â€œfurnituresâ€ like compass and scale can also provide more perspective."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#smaller-maps",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#smaller-maps",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Smaller Maps",
    "text": "Smaller Maps\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nI donâ€™t find this very useful as the maps rendered might be too small to inspect. However, the facets with the region can be useful to see the data based on region.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Greens\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1B.html#mapping-according-to-criterion",
    "href": "Hands-on_Ex1/Hands-on_Ex1B.html#mapping-according-to-criterion",
    "title": "Hands on Exercise 1A: Choropleth Mapping with R",
    "section": "Mapping According to Criterion",
    "text": "Mapping According to Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Greens\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nI find this very useful especially if we just want to map a subset of the data. This can be used when we want to highlight information on certain regions."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#plotting-a-choropleth-map",
    "href": "In-class_Ex2/In-class_Ex2A.html#plotting-a-choropleth-map",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Plotting a choropleth map",
    "text": "Plotting a choropleth map\nNext is to plot the map of GDP per capita values.\n\ntmap_mode(\"plot\")\ntm_shape(hunan) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"GDP per capita by county in China (2012)\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.height = 0.35, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#queens-method",
    "href": "In-class_Ex2/In-class_Ex2A.html#queens-method",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Queenâ€™s method",
    "text": "Queenâ€™s method\n\n\n\n\n\n\nImportant\n\n\n\nst_continguity() used queen = TRUE as default. If not specified, it will use the Queenâ€™s method.\n\n\n\nnb_queen &lt;- hunan %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         .before = 1)\nsummary(nb_queen)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n    nb          County              GDPPC                geometry \n NULL:NULL   Length:88          Min.   : 8497   POLYGON      :88  \n             Class :character   1st Qu.:14566   epsg:4326    : 0  \n             Mode  :character   Median :20433   +proj=long...: 0  \n                                Mean   :24405                     \n                                3rd Qu.:27224                     \n                                Max.   :88656                     \n\n\nTo prettify the output of head(), we can use kable.\n\nkable(head(nb_queen,\n           n=10))\n\n\n\n\n\n\n\n\n\n\nnb\nCounty\nGDPPC\ngeometry\n\n\n\n\n2, 3, 4, 57, 85\nAnxiang\n23667\nPOLYGON ((112.0625 29.75523â€¦\n\n\n1, 57, 58, 78, 85\nHanshou\n20981\nPOLYGON ((112.2288 29.11684â€¦\n\n\n1, 4, 5, 85\nJinshi\n34592\nPOLYGON ((111.8927 29.6013,â€¦\n\n\n1, 3, 5, 6\nLi\n24473\nPOLYGON ((111.3731 29.94649â€¦\n\n\n3, 4, 6, 85\nLinli\n25554\nPOLYGON ((111.6324 29.76288â€¦\n\n\n4, 5, 69, 75, 85\nShimen\n27137\nPOLYGON ((110.8825 30.11675â€¦\n\n\n67, 71, 74, 84\nLiuyang\n63118\nPOLYGON ((113.9905 28.5682,â€¦\n\n\n9, 46, 47, 56, 78, 80, 86\nNingxiang\n62202\nPOLYGON ((112.7181 28.38299â€¦\n\n\n8, 66, 68, 78, 84, 86\nWangcheng\n70666\nPOLYGON ((112.7914 28.52688â€¦\n\n\n16, 17, 19, 20, 22, 70, 72, 73\nAnren\n12761\nPOLYGON ((113.1757 26.82734â€¦"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2C.html#importing-the-data",
    "href": "In-class_Ex2/In-class_Ex2C.html#importing-the-data",
    "title": "In-class Exercise 2C: EHSA",
    "section": "Importing the data",
    "text": "Importing the data\nFirst, we will import the geospatial data in shp format.\n\nhunan = st_read(dsn = \"data/geospatial\",\n                layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/kjcpaas/Documents/Grad School/ISSS624/Project/ISSS624/In-class_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nSecond, we import the aspatial data Hunan_GDPPC, which contains the GDP Per Capita (GDPPC) of Chinese counties.\n\nGDPPC = read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2C.html#computing-gi",
    "href": "In-class_Ex2/In-class_Ex2C.html#computing-gi",
    "title": "In-class Exercise 2C: EHSA",
    "section": "Computing Gi*",
    "text": "Computing Gi*\n\nDeriving spatial weights\nSimilar to the previous exercises, we calculate inverse distance first. However, we now have a time column in our data which is Year.\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\nGDPPC_nb\n\n# A tibble: 1,496 Ã— 5\n    Year County    GDPPC nb        wt       \n   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   \n 1  2005 Anxiang    8184 &lt;int [6]&gt; &lt;dbl [6]&gt;\n 2  2005 Hanshou    6560 &lt;int [6]&gt; &lt;dbl [6]&gt;\n 3  2005 Jinshi     9956 &lt;int [5]&gt; &lt;dbl [5]&gt;\n 4  2005 Li         8394 &lt;int [5]&gt; &lt;dbl [5]&gt;\n 5  2005 Linli      8850 &lt;int [5]&gt; &lt;dbl [5]&gt;\n 6  2005 Shimen     9244 &lt;int [6]&gt; &lt;dbl [6]&gt;\n 7  2005 Liuyang   13406 &lt;int [5]&gt; &lt;dbl [5]&gt;\n 8  2005 Ningxiang 11687 &lt;int [8]&gt; &lt;dbl [8]&gt;\n 9  2005 Wangcheng 14659 &lt;int [7]&gt; &lt;dbl [7]&gt;\n10  2005 Anren      7423 &lt;int [9]&gt; &lt;dbl [9]&gt;\n# â„¹ 1,486 more rows\n\n\n\n\nComputing local Gi*\n\ngi_stars &lt;- GDPPC_nb %&gt;%\n  group_by(Year) %&gt;%\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;%\n  tidyr::unnest(gi_star)\ngi_stars\n\n# A tibble: 1,496 Ã— 13\n# Groups:   Year [17]\n    Year County    GDPPC nb        wt     gi_star   e_gi  var_gi p_value   p_sim\n   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1  2005 Anxiang    8184 &lt;int [6]&gt; &lt;dbl&gt;    0.398 0.0116 3.04e-6  0.331  0.741  \n 2  2005 Hanshou    6560 &lt;int [6]&gt; &lt;dbl&gt;   -0.237 0.0109 2.86e-6 -0.0151 0.988  \n 3  2005 Jinshi     9956 &lt;int [5]&gt; &lt;dbl&gt;    1.05  0.0127 3.65e-6  0.470  0.638  \n 4  2005 Li         8394 &lt;int [5]&gt; &lt;dbl&gt;    0.966 0.0119 3.62e-6  0.761  0.446  \n 5  2005 Linli      8850 &lt;int [5]&gt; &lt;dbl&gt;    1.05  0.0119 2.78e-6  0.967  0.333  \n 6  2005 Shimen     9244 &lt;int [6]&gt; &lt;dbl&gt;    0.210 0.0120 2.94e-6 -0.127  0.899  \n 7  2005 Liuyang   13406 &lt;int [5]&gt; &lt;dbl&gt;    3.91  0.0142 3.17e-6  3.02   0.00251\n 8  2005 Ningxiang 11687 &lt;int [8]&gt; &lt;dbl&gt;    1.61  0.0126 2.17e-6  0.967  0.333  \n 9  2005 Wangcheng 14659 &lt;int [7]&gt; &lt;dbl&gt;    3.88  0.0141 2.52e-6  2.66   0.00771\n10  2005 Anren      7423 &lt;int [9]&gt; &lt;dbl&gt;    1.67  0.0113 2.23e-6  1.83   0.0669 \n# â„¹ 1,486 more rows\n# â„¹ 3 more variables: p_folded_sim &lt;dbl&gt;, skewness &lt;dbl&gt;, kurtosis &lt;dbl&gt;"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#combining-them-all-together",
    "href": "In-class_Ex2/In-class_Ex2B.html#combining-them-all-together",
    "title": "In-class Exercise 2: GLSA",
    "section": "Combining them all together",
    "text": "Combining them all together\nAs seen from the import above, each of the dataframes have 88 rows each. Each row corresponds to a record per county.\nHowever, we are already interested in the following columns:\n\nCounty\nGDPPC\n\n\nhunan &lt;- left_join(hunan, hunan2012)%&gt;%\n  select(7, 15)\n\n\n\n\n\n\n\nNote\n\n\n\nWe do not need to specify the columns to join as both dataframes have the County column so left_join() is able to detect that this is the column to join by."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#computing-local-morans-i",
    "href": "In-class_Ex2/In-class_Ex2B.html#computing-local-morans-i",
    "title": "In-class Exercise 2: LISA",
    "section": "Computing local Moranâ€™s I",
    "text": "Computing local Moranâ€™s I\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n      .before = 1) %&gt;%\n  unnest(local_moran)\nlisa\n\nSimple feature collection with 88 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 Ã— 17\n         ii       eii     var_ii   z_ii      p_ii p_ii_sim p_folded_sim skewness\n      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.00147  0.00111  0.000479   -0.118 0.906         0.84         0.42   -0.558\n 2  0.0259  -0.0139   0.0103      0.391 0.696         0.84         0.42   -0.421\n 3 -0.0120   0.0550   0.118      -0.195 0.845         0.9          0.45    0.956\n 4  0.00102 -0.000229 0.00000491  0.565 0.572         0.56         0.28    1.16 \n 5  0.0148  -0.00489  0.00125     0.557 0.578         0.52         0.26    1.04 \n 6 -0.0388   0.00156  0.00684    -0.488 0.626         0.68         0.34    0.982\n 7  3.37     0.00712  1.69        2.59  0.00972       0.06         0.03    1.78 \n 8  1.56    -0.137    0.659       2.09  0.0365        0.06         0.03    0.453\n 9  4.42    -0.181    1.36        3.94  0.0000803     0.02         0.01    0.738\n10 -0.399   -0.0235   0.0854     -1.29  0.198         0.26         0.13   -0.965\n# â„¹ 78 more rows\n# â„¹ 9 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;, geometry &lt;POLYGON [Â°]&gt;"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#identifying-neighbors-via-queens-method",
    "href": "In-class_Ex2/In-class_Ex2A.html#identifying-neighbors-via-queens-method",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Identifying neighbors via Queenâ€™s method",
    "text": "Identifying neighbors via Queenâ€™s method\n\n\n\n\n\n\nImportant\n\n\n\nst_continguity() used queen = TRUE as default. If not specified, it will use the Queenâ€™s method.\n\n\n\nnb_queen &lt;- hunan %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         .before = 1)\nsummary(nb_queen)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n    nb          County              GDPPC                geometry \n NULL:NULL   Length:88          Min.   : 8497   POLYGON      :88  \n             Class :character   1st Qu.:14566   epsg:4326    : 0  \n             Mode  :character   Median :20433   +proj=long...: 0  \n                                Mean   :24405                     \n                                3rd Qu.:27224                     \n                                Max.   :88656                     \n\n\nTo prettify the output of head(), we can use kable.\n\nkable(head(nb_queen,\n           n=10))\n\n\n\n\n\n\n\n\n\n\nnb\nCounty\nGDPPC\ngeometry\n\n\n\n\n2, 3, 4, 57, 85\nAnxiang\n23667\nPOLYGON ((112.0625 29.75523â€¦\n\n\n1, 57, 58, 78, 85\nHanshou\n20981\nPOLYGON ((112.2288 29.11684â€¦\n\n\n1, 4, 5, 85\nJinshi\n34592\nPOLYGON ((111.8927 29.6013,â€¦\n\n\n1, 3, 5, 6\nLi\n24473\nPOLYGON ((111.3731 29.94649â€¦\n\n\n3, 4, 6, 85\nLinli\n25554\nPOLYGON ((111.6324 29.76288â€¦\n\n\n4, 5, 69, 75, 85\nShimen\n27137\nPOLYGON ((110.8825 30.11675â€¦\n\n\n67, 71, 74, 84\nLiuyang\n63118\nPOLYGON ((113.9905 28.5682,â€¦\n\n\n9, 46, 47, 56, 78, 80, 86\nNingxiang\n62202\nPOLYGON ((112.7181 28.38299â€¦\n\n\n8, 66, 68, 78, 84, 86\nWangcheng\n70666\nPOLYGON ((112.7914 28.52688â€¦\n\n\n16, 17, 19, 20, 22, 70, 72, 73\nAnren\n12761\nPOLYGON ((113.1757 26.82734â€¦"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#identifying-neighbors-via-rooks-method",
    "href": "In-class_Ex2/In-class_Ex2A.html#identifying-neighbors-via-rooks-method",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Identifying neighbors via Rookâ€™s method",
    "text": "Identifying neighbors via Rookâ€™s method\nWe do the same for the Rookâ€™s method. This time, we need to supply queen = FALSE to st_contiguity().\n\nnb_rook &lt;- hunan %&gt;% \n  mutate(nb = st_contiguity(geometry, queen = FALSE),\n         .before = 1)\nsummary(nb_rook)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n    nb          County              GDPPC                geometry \n NULL:NULL   Length:88          Min.   : 8497   POLYGON      :88  \n             Class :character   1st Qu.:14566   epsg:4326    : 0  \n             Mode  :character   Median :20433   +proj=long...: 0  \n                                Mean   :24405                     \n                                3rd Qu.:27224                     \n                                Max.   :88656                     \n\n\n\nkable(head(nb_rook,\n           n=10))\n\n\n\n\n\n\n\n\n\n\nnb\nCounty\nGDPPC\ngeometry\n\n\n\n\n3, 4, 57, 85\nAnxiang\n23667\nPOLYGON ((112.0625 29.75523â€¦\n\n\n57, 58, 78, 85\nHanshou\n20981\nPOLYGON ((112.2288 29.11684â€¦\n\n\n1, 4, 5, 85\nJinshi\n34592\nPOLYGON ((111.8927 29.6013,â€¦\n\n\n1, 3, 5, 6\nLi\n24473\nPOLYGON ((111.3731 29.94649â€¦\n\n\n3, 4, 6, 85\nLinli\n25554\nPOLYGON ((111.6324 29.76288â€¦\n\n\n4, 5, 69, 75, 85\nShimen\n27137\nPOLYGON ((110.8825 30.11675â€¦\n\n\n67, 71, 74, 84\nLiuyang\n63118\nPOLYGON ((113.9905 28.5682,â€¦\n\n\n9, 46, 47, 56, 78, 80, 86\nNingxiang\n62202\nPOLYGON ((112.7181 28.38299â€¦\n\n\n8, 66, 68, 78, 84, 86\nWangcheng\n70666\nPOLYGON ((112.7914 28.52688â€¦\n\n\n16, 19, 20, 22, 70, 72, 73\nAnren\n12761\nPOLYGON ((113.1757 26.82734â€¦"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#identifying-higher-order-contiguity-neighbors",
    "href": "In-class_Ex2/In-class_Ex2A.html#identifying-higher-order-contiguity-neighbors",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Identifying higher-order contiguity neighbors",
    "text": "Identifying higher-order contiguity neighbors\nThis simply means neighbors of neighbors.\n\nnb2_queen &lt;-  hunan %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         nb2 = st_nb_lag_cumul(nb, 2),\n         .before = 1)\nsummary(nb2_queen)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 1324 \nPercentage nonzero weights: 17.09711 \nAverage number of links: 15.04545 \nLink number distribution:\n\n 5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 26 28 33 \n 2  1  6  4  5  4  8  5 10  4  4  8  4  8  5  2  2  1  2  1  1  1 \n2 least connected regions:\n30 88 with 5 links\n1 most connected region:\n56 with 33 links\n\n\n    nb         nb2          County              GDPPC                geometry \n NULL:NULL   NULL:NULL   Length:88          Min.   : 8497   POLYGON      :88  \n                         Class :character   1st Qu.:14566   epsg:4326    : 0  \n                         Mode  :character   Median :20433   +proj=long...: 0  \n                                            Mean   :24405                     \n                                            3rd Qu.:27224                     \n                                            Max.   :88656                     \n\n\n\nkable(head(nb2_queen))\n\n\n\n\n\n\n\n\n\n\n\nnb\nnb2\nCounty\nGDPPC\ngeometry\n\n\n\n\n2, 3, 4, 57, 85\n2, 3, 4, 5, 6, 32, 56, 57, 58, 64, 69, 75, 76, 78, 85\nAnxiang\n23667\nPOLYGON ((112.0625 29.75523â€¦\n\n\n1, 57, 58, 78, 85\n1, 3, 4, 5, 6, 8, 9, 32, 56, 57, 58, 64, 68, 69, 75, 76, 78, 85\nHanshou\n20981\nPOLYGON ((112.2288 29.11684â€¦\n\n\n1, 4, 5, 85\n1, 2, 4, 5, 6, 32, 56, 57, 69, 75, 78, 85\nJinshi\n34592\nPOLYGON ((111.8927 29.6013,â€¦\n\n\n1, 3, 5, 6\n1, 2, 3, 5, 6, 57, 69, 75, 85\nLi\n24473\nPOLYGON ((111.3731 29.94649â€¦\n\n\n3, 4, 6, 85\n1, 2, 3, 4, 6, 32, 56, 57, 69, 75, 78, 85\nLinli\n25554\nPOLYGON ((111.6324 29.76288â€¦\n\n\n4, 5, 69, 75, 85\n1, 2, 3, 4, 5, 32, 53, 55, 56, 57, 69, 75, 78, 85\nShimen\n27137\nPOLYGON ((110.8825 30.11675â€¦"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#deriving-fixed-distance-weights",
    "href": "In-class_Ex2/In-class_Ex2A.html#deriving-fixed-distance-weights",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Deriving fixed-distance weights",
    "text": "Deriving fixed-distance weights\nFirst is to determine the upper limit for the distance for the nearest neigbor.\n\ngeo &lt;- sf::st_geometry(hunan)\nnb &lt;- st_knn(geo, longlat = TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\n\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  21.56   29.11   36.89   37.34   43.21   65.80 \n\n\nWe use the max value of the result, 65.80. For simplicity, letâ€™s set it to 66.\nNow we can calculate the fixed-distance weights.\n\nwm_fd &lt;- hunan %&gt;%\n  mutate(nb = st_dist_band(geometry,\n                           upper = 66),\n               wt = st_weights(nb),\n               .before = 1)\nwm_fd\n\nSimple feature collection with 88 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                       nb\n1      2, 3, 4, 5, 57, 64\n2       1, 57, 58, 78, 85\n3             1, 4, 5, 57\n4              1, 3, 5, 6\n5          1, 3, 4, 6, 69\n6                4, 5, 69\n7              67, 71, 84\n8       9, 46, 47, 78, 80\n9   8, 46, 66, 68, 84, 86\n10 16, 20, 22, 70, 72, 73\n                                                                 wt    County\n1  0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667   Anxiang\n2                                           0.2, 0.2, 0.2, 0.2, 0.2   Hanshou\n3                                            0.25, 0.25, 0.25, 0.25    Jinshi\n4                                            0.25, 0.25, 0.25, 0.25        Li\n5                                           0.2, 0.2, 0.2, 0.2, 0.2     Linli\n6                                   0.3333333, 0.3333333, 0.3333333    Shimen\n7                                   0.3333333, 0.3333333, 0.3333333   Liuyang\n8                                           0.2, 0.2, 0.2, 0.2, 0.2 Ningxiang\n9  0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667 Wangcheng\n10 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667     Anren\n   GDPPC                       geometry\n1  23667 POLYGON ((112.0625 29.75523...\n2  20981 POLYGON ((112.2288 29.11684...\n3  34592 POLYGON ((111.8927 29.6013,...\n4  24473 POLYGON ((111.3731 29.94649...\n5  25554 POLYGON ((111.6324 29.76288...\n6  27137 POLYGON ((110.8825 30.11675...\n7  63118 POLYGON ((113.9905 28.5682,...\n8  62202 POLYGON ((112.7181 28.38299...\n9  70666 POLYGON ((112.7914 28.52688...\n10 12761 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2A.html#calculate-inverse-distance-weights",
    "href": "In-class_Ex2/In-class_Ex2A.html#calculate-inverse-distance-weights",
    "title": "In-class Exercise 2: Spatial Weights with sfdep",
    "section": "Calculate inverse distance weights",
    "text": "Calculate inverse distance weights\n\nwm_idw &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\nwm_idw\n\nSimple feature collection with 88 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                                              wts\n1                                      0.01526149, 0.03515537, 0.02176677, 0.02836978, 0.01029857\n2                                      0.01526149, 0.01601100, 0.01911052, 0.02327058, 0.01591694\n3                                                  0.03515537, 0.04581089, 0.04116397, 0.01208437\n4                                                  0.02176677, 0.04581089, 0.04637578, 0.01585302\n5                                                  0.04116397, 0.04637578, 0.01896212, 0.01351099\n6                                      0.01585302, 0.01896212, 0.02710909, 0.01140718, 0.01080890\n7                                                  0.01621067, 0.01536702, 0.01133628, 0.01836488\n8              0.01930410, 0.02675555, 0.02151751, 0.01076895, 0.02608065, 0.01519804, 0.01337412\n9                          0.01930410, 0.01651371, 0.01798519, 0.01473155, 0.03015561, 0.01612293\n10 0.02737233, 0.01390810, 0.01458881, 0.02156771, 0.02419268, 0.02350470, 0.01784174, 0.01621545\n      County GDPPC                       geometry\n1    Anxiang 23667 POLYGON ((112.0625 29.75523...\n2    Hanshou 20981 POLYGON ((112.2288 29.11684...\n3     Jinshi 34592 POLYGON ((111.8927 29.6013,...\n4         Li 24473 POLYGON ((111.3731 29.94649...\n5      Linli 25554 POLYGON ((111.6324 29.76288...\n6     Shimen 27137 POLYGON ((110.8825 30.11675...\n7    Liuyang 63118 POLYGON ((113.9905 28.5682,...\n8  Ningxiang 62202 POLYGON ((112.7181 28.38299...\n9  Wangcheng 70666 POLYGON ((112.7914 28.52688...\n10     Anren 12761 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html",
    "href": "In-class_Ex2/In-class_Ex2B.html",
    "title": "In-class Exercise 2: GLSA",
    "section": "",
    "text": "This introduces sfdep functions for analysis related to Global and Local Measures of Association."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#plotting-a-choropleth-map",
    "href": "In-class_Ex2/In-class_Ex2B.html#plotting-a-choropleth-map",
    "title": "In-class Exercise 2: GLSA",
    "section": "Plotting a choropleth map",
    "text": "Plotting a choropleth map\nNext is to plot the map of GDP per capita values.\n\ntmap_mode(\"plot\")\ntm_shape(hunan) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"GDP per capita by county in China (2012)\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.height = 0.35, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#deriving-contiguity-weights-queens-method",
    "href": "In-class_Ex2/In-class_Ex2B.html#deriving-contiguity-weights-queens-method",
    "title": "In-class Exercise 2: GLSA",
    "section": "Deriving Contiguity Weights: Queenâ€™s Method",
    "text": "Deriving Contiguity Weights: Queenâ€™s Method\n\nwm_q &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \nwm_q\n\nSimple feature collection with 88 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n      County GDPPC                       geometry\n1    Anxiang 23667 POLYGON ((112.0625 29.75523...\n2    Hanshou 20981 POLYGON ((112.2288 29.11684...\n3     Jinshi 34592 POLYGON ((111.8927 29.6013,...\n4         Li 24473 POLYGON ((111.3731 29.94649...\n5      Linli 25554 POLYGON ((111.6324 29.76288...\n6     Shimen 27137 POLYGON ((110.8825 30.11675...\n7    Liuyang 63118 POLYGON ((113.9905 28.5682,...\n8  Ningxiang 62202 POLYGON ((112.7181 28.38299...\n9  Wangcheng 70666 POLYGON ((112.7914 28.52688...\n10     Anren 12761 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#computing-global-morans-i",
    "href": "In-class_Ex2/In-class_Ex2B.html#computing-global-morans-i",
    "title": "In-class Exercise 2: GLSA",
    "section": "Computing Global Moranâ€™s I",
    "text": "Computing Global Moranâ€™s I\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#performing-global-morans-i-test",
    "href": "In-class_Ex2/In-class_Ex2B.html#performing-global-morans-i-test",
    "title": "In-class Exercise 2: GLSA",
    "section": "Performing Global Moranâ€™s I test",
    "text": "Performing Global Moranâ€™s I test\n\n\n\n\n\n\nTip\n\n\n\nThis is preferred over just calculating the statistic.\n\n\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#performing-global-morans-i-test-1",
    "href": "In-class_Ex2/In-class_Ex2B.html#performing-global-morans-i-test-1",
    "title": "In-class Exercise 2: GLSA",
    "section": "Performing Global Moranâ€™s I test",
    "text": "Performing Global Moranâ€™s I test\n\n\n\n\n\n\nTip\n\n\n\nThis is the ideal method in practice.\n\n\n\nset.seed(1234)\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#visualizing-morans-i",
    "href": "In-class_Ex2/In-class_Ex2B.html#visualizing-morans-i",
    "title": "In-class Exercise 2: GLSA",
    "section": "Visualizing Moranâ€™s I",
    "text": "Visualizing Moranâ€™s I\nIn visualizing the Moranâ€™s I values, plot using the ii column.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#visualizing-p-value-of-morans-i",
    "href": "In-class_Ex2/In-class_Ex2B.html#visualizing-p-value-of-morans-i",
    "title": "In-class Exercise 2: GLSA",
    "section": "Visualizing p-value of Moranâ€™s I",
    "text": "Visualizing p-value of Moranâ€™s I\nTo visualize the p-value, plot using p_ii_sim.\n\n\n\n\n\n\nWarning\n\n\n\nThese are from simulation results\n\n\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#visualizing-local-morans-i-and-p-value",
    "href": "In-class_Ex2/In-class_Ex2B.html#visualizing-local-morans-i-and-p-value",
    "title": "In-class Exercise 2: GLSA",
    "section": "Visualizing local Moranâ€™s I and p-value",
    "text": "Visualizing local Moranâ€™s I and p-value\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#visualizing-lisa-map",
    "href": "In-class_Ex2/In-class_Ex2B.html#visualizing-lisa-map",
    "title": "In-class Exercise 2: GLSA",
    "section": "Visualizing LISA map",
    "text": "Visualizing LISA map\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#computing-local-gi-statistics",
    "href": "In-class_Ex2/In-class_Ex2B.html#computing-local-gi-statistics",
    "title": "In-class Exercise 2: GLSA",
    "section": "Computing local Gi* statistics",
    "text": "Computing local Gi* statistics\nWe need to compute the inverse distance weights first.\n\nwm_idw &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\nwm_idw\n\nSimple feature collection with 88 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                                              wts\n1                                      0.01526149, 0.03515537, 0.02176677, 0.02836978, 0.01029857\n2                                      0.01526149, 0.01601100, 0.01911052, 0.02327058, 0.01591694\n3                                                  0.03515537, 0.04581089, 0.04116397, 0.01208437\n4                                                  0.02176677, 0.04581089, 0.04637578, 0.01585302\n5                                                  0.04116397, 0.04637578, 0.01896212, 0.01351099\n6                                      0.01585302, 0.01896212, 0.02710909, 0.01140718, 0.01080890\n7                                                  0.01621067, 0.01536702, 0.01133628, 0.01836488\n8              0.01930410, 0.02675555, 0.02151751, 0.01076895, 0.02608065, 0.01519804, 0.01337412\n9                          0.01930410, 0.01651371, 0.01798519, 0.01473155, 0.03015561, 0.01612293\n10 0.02737233, 0.01390810, 0.01458881, 0.02156771, 0.02419268, 0.02350470, 0.01784174, 0.01621545\n      County GDPPC                       geometry\n1    Anxiang 23667 POLYGON ((112.0625 29.75523...\n2    Hanshou 20981 POLYGON ((112.2288 29.11684...\n3     Jinshi 34592 POLYGON ((111.8927 29.6013,...\n4         Li 24473 POLYGON ((111.3731 29.94649...\n5      Linli 25554 POLYGON ((111.6324 29.76288...\n6     Shimen 27137 POLYGON ((110.8825 30.11675...\n7    Liuyang 63118 POLYGON ((113.9905 28.5682,...\n8  Ningxiang 62202 POLYGON ((112.7181 28.38299...\n9  Wangcheng 70666 POLYGON ((112.7914 28.52688...\n10     Anren 12761 POLYGON ((113.1757 26.82734...\n\n\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 Ã— 13\n   gi_star   e_gi    var_gi p_value   p_sim p_folded_sim skewness kurtosis nb   \n     &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;nb&gt; \n 1  0.0416 0.0114   6.41e-6  0.0493 9.61e-1         0.7      0.35    0.875 &lt;int&gt;\n 2 -0.333  0.0106   3.84e-6 -0.0941 9.25e-1         1        0.5     0.661 &lt;int&gt;\n 3  0.281  0.0126   7.51e-6 -0.151  8.80e-1         0.9      0.45    0.640 &lt;int&gt;\n 4  0.411  0.0118   9.22e-6  0.264  7.92e-1         0.6      0.3     0.853 &lt;int&gt;\n 5  0.387  0.0115   9.56e-6  0.339  7.34e-1         0.62     0.31    1.07  &lt;int&gt;\n 6 -0.368  0.0118   5.91e-6 -0.583  5.60e-1         0.72     0.36    0.594 &lt;int&gt;\n 7  3.56   0.0151   7.31e-6  2.61   9.01e-3         0.06     0.03    1.09  &lt;int&gt;\n 8  2.52   0.0136   6.14e-6  1.49   1.35e-1         0.2      0.1     1.12  &lt;int&gt;\n 9  4.56   0.0144   5.84e-6  3.53   4.17e-4         0.04     0.02    1.23  &lt;int&gt;\n10  1.16   0.0104   3.70e-6  1.82   6.86e-2         0.12     0.06    0.416 &lt;int&gt;\n# â„¹ 78 more rows\n# â„¹ 4 more variables: wts &lt;list&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [Â°]&gt;"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#visualizing-gi",
    "href": "In-class_Ex2/In-class_Ex2B.html#visualizing-gi",
    "title": "In-class Exercise 2: GLSA",
    "section": "Visualizing Gi*",
    "text": "Visualizing Gi*\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#visualizing-p-value-of-hcsa",
    "href": "In-class_Ex2/In-class_Ex2B.html#visualizing-p-value-of-hcsa",
    "title": "In-class Exercise 2: GLSA",
    "section": "Visualizing p-value of HCSA",
    "text": "Visualizing p-value of HCSA\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#visualizing-local-hcsa",
    "href": "In-class_Ex2/In-class_Ex2B.html#visualizing-local-hcsa",
    "title": "In-class Exercise 2: GLSA",
    "section": "Visualizing local HCSA",
    "text": "Visualizing local HCSA\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2B.html#visualizing-hot-spot-and-cold-spot-areas",
    "href": "In-class_Ex2/In-class_Ex2B.html#visualizing-hot-spot-and-cold-spot-areas",
    "title": "In-class Exercise 2: GLSA",
    "section": "Visualizing hot spot and cold spot areas",
    "text": "Visualizing hot spot and cold spot areas\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2C.html",
    "href": "In-class_Ex2/In-class_Ex2C.html",
    "title": "In-class Exercise 2C: EHSA",
    "section": "",
    "text": "For this exercise, we will do spatio-temporal analysis to understand spatial patterns with additional factor of time."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2C.html#arrange-to-show-significant-emerging-hotcold-spots",
    "href": "In-class_Ex2/In-class_Ex2C.html#arrange-to-show-significant-emerging-hotcold-spots",
    "title": "In-class Exercise 2C: EHSA",
    "section": "Arrange to show significant emerging hot/cold spots",
    "text": "Arrange to show significant emerging hot/cold spots\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:5)\nemerging\n\n# A tibble: 5 Ã— 6\n  County        tau         sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Shuangfeng  0.868 0.00000143   118  136.  589.\n2 Xiangtan    0.868 0.00000143   118  136.  589.\n3 Xiangxiang  0.868 0.00000143   118  136.  589.\n4 Chengbu    -0.824 0.00000482  -112  136.  589.\n5 Dongan     -0.824 0.00000482  -112  136.  589."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2C.html#performing-emerging-hot-spot-analysis",
    "href": "In-class_Ex2/In-class_Ex2C.html#performing-emerging-hot-spot-analysis",
    "title": "In-class Exercise 2C: EHSA",
    "section": "Performing Emerging Hot spot Analysis",
    "text": "Performing Emerging Hot spot Analysis\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st,\n  .var = \"GDPPC\",\n  k = 1,\n  nsim = 99\n)\n\n\nVisualizing the distribution of EHSA classes\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\nFigure above shows that sporadic cold spots class has the high numbers of county. Visualizing EHSA\nTo generate a map, we have to add geospatial component to the data to we have join ehsa with hunan.\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\nThen we can finally generate the map.\n\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)"
  }
]