---
title: "Take Home Exercise 2: A Case Study of Singapore Public Bus Commuter Flows"
author: "Kristine Joy Paas"
date: "6 Dec 2023"
date-modified: "last-modified"
format: html
execute: 
  echo: true
  eval: false
  warning: false
---

# Overview

The aim of this exercise to study the bus commuter flow patterns in Singapore to gain insights that support decision-making.

We will be examining the **weekend morning peak hours** (11 AM - 2 PM) to figure out where people go during weekends and holidays.

We will also be the modelling the spatial interaction between the different locations in Singapore, related to the bus commuter patterns.

Check <https://isss624-ay2023-24nov.netlify.app/take-home_ex02> for the full requirements of this exercise.

As this process is expected to have a lot of intermediate steps, **Save**, **Load**, and **Data clear** points are available to make our data wrangling more efficient.

::: callout-tip
### Save point

This is where data is written as `rds` files using `write_rds()` for important data sets that will be used in later analysis. Examples are:

-   Flow data, attractive and propulsive forces
-   Critical outputs of expensive calculations
-   Cleaned up data for lightweight processing
:::

::: callout-note
### Load point

This is where data is loaded from `rds` files using `read_rds()`. They were previously generated by the save point.

**TIP**: Skip to the load points to progress without running the code above it
:::

::: callout-warning
### Data clear point

This is where data that will not be used anymore are cleared. The data in RStudio environment will pile up and set `#| eval: false` in code chunks if you want skip the clearing. For example, the code below won't be run.

```{r}
#| eval: false
message <- "This code chunk executed"
```
:::

# Setup

```{r}
#| label: setup
pacman::p_load(sf, sp, tmap, tidyverse, knitr, sfdep, stplanr, reshape2)
tmap_mode("plot")
tmap_style("natural")
set.seed(1234)
```

# Data Wrangling

## Importing the Singapore subzone map

First, we will import the **Master Plan 2019 Subzone Boundary (Web)** data set that has been used in class. We will only keep the `SUBZONE_N` column and the geometry as we will only use this as the **base for our visualizations**.

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                layer = "MPSZ-2019") %>%
  select(SUBZONE_N)
kable(head(mpsz))
```

::: {.callout-caution appearance="simple"}
### Correcting the projection

This data frame using the global GPS standard, [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We need to convert this to [**SVY21**](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) projection that is more appropriate for Singapore ðŸ‡¸ðŸ‡¬ context.

```{r}
mpsz <- mpsz %>% st_transform(crs=3414)
```
:::

::: {.callout-tip collapse="true"}
### Save point

Let's save this geometry with corrected projection from plotting purposes.

```{r}
write_rds(mpsz, "data/rds/mpsz.rds")
```
:::

## Generating Hexagons for the Traffic Analysis Zone

To start our analysis, we will first build the honeycomb grid needed for our [traffic analysis zone (TAZ)](https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf). These hexagons must have a distance of **375m** from the center of the hexagon to the midpoint of each edge.

### Import Bus Stop Data

Next, we need to import the bus stop data as we will generate the honeycomb grid based on locations with bus stops.

```{r}
busstops <- st_read(dsn = "data/geospatial",
                    layer = "BusStop")
kable(head(busstops))
```

::: {.callout-caution collapse="true" appearance="simple"}
#### Correcting the projection

We want to use [SVY21](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) as the projection for this study as it is the projection used for local Singaporean context.

After the import, it shows that the **Projected CRS**is **SVY21**. However, checking the CRS with `st_crs()` tells a different story.

```{r}
st_crs(busstops)
```

As we can see EPSG value is **9001**, which correspond to [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We have to fix the projection by transforming to EPSG value of **3414**, which corresponds to **SVY21**.

```{r}
busstops <- st_transform(busstops, crs = 3414)
```
:::

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of bus stops in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.005, title = "Bus Stops") +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```

```{r}
busstops <- busstops %>% st_intersection(mpsz) %>% select(BUS_STOP_N, )
```

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tmap_style("natural")
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of bus stops in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.005, title = "Bus Stops") +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```

::: {.callout-important appearance="simple" collapse="true"}
#### Removing the bus stops outside Singapore

The map shows that there are bus stops in our data set that are outside Singapore bounds (green area). We can remove these points from our `busstops` data by using `st_intersection()`.

We will use this as `busstops` contains points, the intersection of the 2 geometries will generate points corresponding to the bus stops within Singapore.

We will also just retain the `BUS_STOP_N` to remove the columns we do not need.

```{r}
busstops <- busstops %>% st_intersection(mpsz) %>% select(BUS_STOP_N, )
```

Visualizing again, all the bus stops are now within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tmap_style("natural")
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of bus stops in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.005, title = "Bus Stops") +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```
:::

### Creating the honeycomb grid

Finally, we can generate the honeycomb grid using `st_make_grid()`, providing *cellsize* of **750m**.

::: {.callout-tip collapse="true" appearance="simple"}
#### Calculating cellsize

[Apothem](https://www.merriam-webster.com/dictionary/apothem) is defined as *the perpendicular from the center of a regular polygon to one of the sides**.***

The specification is this study requires hexagons to be **375 m** from the center of the hexagon to the center of one of it's edge.

![](images/apothem.png){fig-align="center"}

As such, this corresponds to the length of 2 opposite apothems, which is **750 m**.

The edge length is **not** the same as apothem. It is **433.013 m**m.

$$
375m/cos(30) = 433.013m
$$
:::

```{r}
honeycomb <- busstops %>% st_make_grid(cellsize = 750,
                                       what="polygons",
                                       square = FALSE) %>%
  st_sf() %>%
  filter(lengths(st_intersects(geometry, busstops)) > 0)
```

::: {.callout-tip collapse="true" appearance="simple"}
#### Code Explanation

st_make_grid()

:   Creates a grid that covers the entire bus stop geometry, including areas without bus stop.

st_sf()

:   Converts to simple feature data set

st_intersects()

:   Checks if the hexagons have bus stops

filter()

:   Removes hexagons without bus stops
:::

Let's plot the map to visually inspect if the hexagons cover all the bus stop locations.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Honeycomb grid corresponding to Singapore bus stops",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.001, title = "Bus Stops") +
  tm_grid(alpha = 0.2)
```

### Assigning id to each hexagon

Now that we have hexagons properly generated, we will assign id for each hexagon to be used as a unique identifier. We will store this id under the `HEX_ID` column, and can be used in joining data frames.

```{r}
honeycomb$HEX_ID <- sprintf("H%04d", seq_len(nrow(honeycomb))) %>% as.factor()
kable(head(honeycomb))
```

::: {.callout-tip collapse="true"}
### Save point

Let's save `honeycomb` as it contains the main geometry we will use in analysis.

```{r}
write_rds(honeycomb, "data/rds/honeycomb.rds")
```
:::

## Extracting hexagon-based bus commuter data

Next, we will extract the bus commuter data going from 1 hexagon to another.

### Importing the bus commuter data

We will use the *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API for the months of **October 2023**.

The data set is an aspatial data in `csv` format so we will use `read_csv()` to import the data.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
kable(head(odbus))
```

::: {.callout-tip appearance="simple"}
If you want to use data for the other months, just find and replace `202310` to your desired month in `YYYYMM` format.
:::

### Filtering the relevant data

We only need the data for the **weekend morning peak period**, which is from 11 AM - 2 PM on weekends and holidays. As such, we will filter the data for the relevant hours.

We will also rename the `ORIGIN_PT_CODE` and `DESTINATION_PT_CODE` to be consistent with the naming with `busstops` as these columns can be associated to `busstops`'s `BUS_STOP_N`

::: {.callout-tip collapse="true" appearance="simple"}
#### How to filter data by *TIME_PER_HOUR*

The `TIME_PER_HOUR` in data set covers the data from the start to the end of the hour in **24-hour format**, i.e. when `TIME_PER_HOUR = 16`, this means bus taps from `4:00 PM` ton`4:59:59PM`.

Hence, if we want to get 6 to 9am data, we will filter by:

```         
TIME_PER_HOUR >= 6 & TIME_PER_HOUR < 9
```
:::

```{r}
od_trips <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter( TIME_PER_HOUR >= 11 &
            TIME_PER_HOUR < 14
          ) %>%
  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  rename(
    ORIG_BUS_STOP_N = ORIGIN_PT_CODE,
    DEST_BUS_STOP_N = DESTINATION_PT_CODE
  )
kable(head(od_trips))
```

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need `odbus` anymore as we already extracted the data relevant to our analysis.

```{r}
#| eval: true
rm(odbus)
```
:::

### Adding hexagon information to *od_trips* data

#### Generating lookup table for bus stop to associated hexagon

To connect the trip data to the their corresponding hexagon, we need to create a lookup table. This will serve as a glue in associating the aspatial `od_trips` data frame to the `honeycomb` data frame.

This can be done via `st_intersection()`.

```{r}
bs_hex <- st_intersection(busstops, honeycomb) %>%
  st_drop_geometry() %>%
  select(c(BUS_STOP_N, HEX_ID))
kable(head(bs_hex))
```

#### Joining *od_trips* and *bs_hex*

Next, we need to associate each origin bus stop and destination bus stop to their corresponding hexagons.

We can use that by doing `inner_join()` twice, once for the origin and another for the destination.

::: {.callout-tip collapse="true"}
##### Why *inner_join()* instead of *left_join()*?

We will use `inner_join` as there are `BUS_STOP_N` values in `od_trips` data that are not in `bs_hex`.

```{r}
c(
  od_trips$ORIG_BUS_STOP_N[!(od_trips$ORIG_BUS_STOP_N %in% bs_hex$BUS_STOP_N)],
  od_trips$DEST_BUS_STOP_N[!(od_trips$DEST_BUS_STOP_N %in% bs_hex$BUS_STOP_N)]
) %>% unique() %>% length()
```

There are **59** bus stops in `od_trips` that are not in `bs_hex`. **5** of these can be attributed the bus stops we removed due to them being out in Singapore. Others may be due to the *BusStops* data set not having complete information.

The proper way to handle this is to validate the existence of each of these bus stops and look at public sources (e.g. Google Maps, LTA data) and add coordinate data. However, as we do not have much to do this task, we have to **remove** these bus stops from our analysis as **we do not have geospatial data** to associate to the hexagons from the data sets available to us.

Therefore, we will use `inner_join` to keep only the observations in `trips` with the matching bus stops in `bs_hex`.
:::

::: panel-tabset
##### Origin

```{r}
od_trips <- od_trips %>%
  inner_join(bs_hex,
             by = c("ORIG_BUS_STOP_N" = "BUS_STOP_N")) %>%
  rename(ORIG_HEX_ID = HEX_ID)
```

##### Destination

```{r}
od_trips <- od_trips %>%
  inner_join(bs_hex,
             by = c("DEST_BUS_STOP_N" = "BUS_STOP_N")) %>%
  rename(DEST_HEX_ID = HEX_ID)
```
:::

#### Aggregating data by hexagon

Similar to [Filtering the relevant data], we will perform aggregations by `ORIG_HEX_ID` and `DEST_HEX_ID` to have an aggregated sum of trips by hexagon instead of bus stops.

```{r}
od_hex <- od_trips %>%
  group_by(ORIG_HEX_ID, DEST_HEX_ID) %>%
  summarise(TRIPS = sum(TRIPS))
kable(head(od_hex))
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `od_hex` as it contains the data needed to visualize flow data. Take note that this **includes intra-zonal trips**.

```{r}
write_rds(od_hex, "data/rds/od_hex202310.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need `busstops`, `bs_hex`, `od_trips` anymore as we already have the necessary data for doing hexagon-based analysis in `od_hex`.

```{r}
#| eval: true
rm(busstops)
rm(bs_hex)
rm(od_trips)
```
:::

# Origin-Destination Flows

::: {.callout-note collapse="true"}
## Load point

We can run from this point by loading these data.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
honeycomb <- read_rds("data/rds/honeycomb.rds")
od_hex <- read_rds("data/rds/od_hex202310.rds")
```
:::

The next part focuses on visualizing the bus commuter flows, figuring the potential propulsive and attractiveness variables.

## Generating the flow lines

First, we will generate the flow lines using `od2line()`. `honeycomb` will be supplied as the `zone` as it contains the hexagons we are using as the **traffic analysis zones**.

```{r}
flowlines <- od_hex %>% od2line(
  honeycomb,
  zone_code = "HEX_ID")
```

## Initial inspection of the flow lines

Next, we will do an initial inspection of the flow lines to check if they have been generated correctly.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  
  tm_shape(flowlines) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7, 10),
           title.lwd = "# of bus trips",
           n = 6,
           alpha = 0.8) +
  
  tm_layout(main.title = "Bus Passenger flow for Weekends/Holidays 11 AM - 2PM (October 2023)",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2)
```

::: {.callout-tip appearance="simple"}
### Insights

The flow lines are sparse at the West side of Singapore, the **Jurong** and **Choa Chu Kang** areas. This is consistent with the observations that we have in the [Take-home Exercise 1](Take-home_Ex1/Take-home_Ex1) that these areas are least busy in terms of bus rides.

The busiest zones can be seen in this visualization as the zones **where the lines converge**. However, it is hard to see more closely in this web of lines we need a different visualization to inspect the busiest bus flows.
:::

## Visualizing the busiest flows

To visualize the busiest flows, we have to reduce the dataset into the most useful ones by:

-   Removing the intra-zonal flows, which may have come from passengers riding until the next stop only

-   Visualizing only the busiest flows

::: {.callout-tip appearance="simple"}
### Helper function for removing intra-zonal data

To help in processing just the inter-zonal flows, we will create a helper function to remove the intra-zonal data. We only need to check if `ORIG_HEX_ID` is the same as `DEST_HEX_ID`.

This function uses `filter()` to remove the rows that do not satisfy the above condition.

```{r}
remove_intra <- function(df) {
  df %>% filter(
    ORIG_HEX_ID != DEST_HEX_ID
  )
}
```
:::

### Determining the cut-off value for *TRIPS*

To identify the cut-off for our visualization, we will use `summary()` to check the distribution of the data

```{r}
remove_intra(flowlines)$TRIPS %>% summary()
```

As can be seen in the summary, the **3rd quartile** is still very low compared to the visualization values in the flow line, which starts as **2000**.

Let's look at the distribution at from `quantile()` to find an appropriate cut-off value.

```{r}
remove_intra(flowlines)$TRIPS %>%
  quantile(probs = c(0.8, 0.9, 0.95, 0.99, 0.995, 0.999))
```

### Visualizing the top 5% busiest flows {#visualizing-the-top-5-busiest-flows}

We will use the value for the 95th percentile as it removes much of the low traffic so we can see patterns. At the same time, it leaves enough so that important details are not lost.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  
  tm_shape(
    flowlines %>%
      remove_intra() %>%
      filter(TRIPS > 376)) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7, 10),
           title.lwd = "# of bus trips",
           n = 6,
           alpha = 0.8) +
  
  tm_layout(main.title = "Top 5% Bus Passenger Flow for Weekends/Holidays 11 AM - 2PM (October 2023)",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2)
```

::: {.callout-tip appearance="simple"}
### Insights

It is notable that the thickest flow lines are for relatively short distances, like the bus rides to and from **Woodlands Checkpoint** to **Kranji Station**. We should consider the existence of train stations as attractive or propulsive variables. This can also be observed in some residential areas like **Jurong East** or **Woodlands**.

Also, there are longer bus rides for the weekend peak, probably indicating people more willing to travel longer distances for recreation and meeting family and friends.
:::

::: {.callout-tip collapse="true"}
### Save point

Let's save `flowlines` as it contains the flow data that we will be using in the next parts of the analysis

```{r}
write_rds(flowlines, "data/rds/flowlines202310.rds")
```
:::

# Attractiveness and Propulsiveness Variables

## Possible motivations for riding the bus

Based on real-world knowledge and observations from [Origin-Destination Flows], we will identify some possible motivations for people to ride the bus during weekend morning peak period. These are:

-   People leaving their homes to go to their destination

-   Transferring from train or another bus to reach their destination

-   Visiting Leisure, Entertainment, and F&B establishments for recreation

-   Going to shops for groceries and other errands

-   Visiting family and friends' homes

With these motivations, we have the following propulsiveness and attractiveness variables.

::: panel-tabset
## Attractiveness

Attractiveness variables are factors that can motivate people to go to their destinations. In our case, these are what *motivates people to ride to their destination bus stop*.

Number of transport points (MRT exits and bus stops)

:   To transfer to another mode of transport to their final destination

Population at the destination (HDB population)

:   To visit family and friends

Number of retail outlets

:   For shopping and errands

Number of leisure, recreation, entertainment areas

:   To unwind and spend time with family and friends

Number of F&B outlets

:   For eating out, a basic human need and mode of socializing

## Propulsiveness

Propulsiveness variables are factors that influence people to ride the bus from specific zones.

Number of transport points (MRT exits and bus stops)

:   To transfer to another mode of transport to their final destination

Population at the destination (HDB population)

:   To visit family and friends
:::

## Required data

To summarize, these are the list of data needed, and the data sources we will be using to derive the values for these variables.

::: {.callout-note appearance="simple"}
Those with **Notes** have additional processing needed on top of just counting how many points intersect the hexagons.

Those already in the `data/` directory are datasets provided or have peviously been used in class.
:::

| Data                               | Source                                                                         | Notes                                  |
|-------------------|--------------------------------|---------------------|
| `BUS_STOP_COUNT`                   | `data/geospatial/BusStop.shp`                                                  |                                        |
| `ENTERTN_COUNT`                    | `data/geospatial/entertn.shp`                                                  |                                        |
| `F_AND_B_COUNT`                    | `data/geospatial/F&B.shp`                                                      |                                        |
| `HDB_COUNT` / `HDB_DWELLING_COUNT` | `data/aspatial/hdb.csv`                                                        | These will serve as population proxies |
| `LEISURE_COUNT`                    | `data/geospatial/Liesure&Recreation.shp`                                       |                                        |
| `RETAIL_COUNT`                     | `data/geospatial/Retails.shp`                                                  |                                        |
| `TRAIN_EXITS_COUNT`                | *Train Station Exit* dataset from [LTA DataMall](https://datamall.lta.gov.sg/) | Need to download from LTA DataMall     |

# Preparing variable data

::: {.callout-note collapse="true"}
## Load point

We can run from this point by loading these data.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
honeycomb <- read_rds("data/rds/honeycomb.rds")
flowlines <- read_rds("data/rds/flowlines202310.rds")
```

We also need to define the `remove_intra()` as we are removing the intra_zonal flows from our visualization.

```{r}
remove_intra <- function(df) {
  df %>% filter(
    ORIG_HEX_ID != DEST_HEX_ID
  )
}
```
:::

We will store the variable in a single `sf` object derived from `honeycomb`.

```{r}
var_hc <- honeycomb
```

We will then prepare the variables, starting with those that don't need extra processing. We will use a combination of `lengths()` and `st_intersects()` to determine how many of each establishment type are in each hexagon.

::: panel-tabset
## Bus Stops

::: {.callout-note appearance="simple"}
We are using the same steps to import the bus stop data set from [Import Bus Stop Data].
:::

```{r}
var_hc$BUS_STOP_COUNT <- lengths(
  st_intersects(var_hc,
                st_read(dsn = "data/geospatial",
                        layer = "BusStop") %>%
                  st_transform(crs = 3414)))
```

## Entertainment

```{r}
entertn <- st_read(dsn = "data/geospatial", layer = "entertn")
```

::: {.callout-important appearance="simple"}
### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Entertainment Spots in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(entertn) +
  tm_dots(col = "red", size = 0.005, title = "Entertainment Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
var_hc$ENTERTN_COUNT <- lengths(st_intersects(var_hc, entertn))
```

## F&B

```{r}
f_and_b <- st_read(dsn = "data/geospatial", layer = "F&B")
```

::: {.callout-important appearance="simple"}
### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of F&B Establishments in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(f_and_b) +
  tm_dots(col = "red", size = 0.005, title = "F&B Establishments Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
var_hc$F_AND_B_COUNT <- lengths(st_intersects(var_hc, f_and_b))
```

## Leisure & Recreation

```{r}
leis_rec <- st_read(dsn = "data/geospatial", layer = "Liesure&Recreation")
```

::: {.callout-important appearance="simple"}
### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Leisure & Recreation Spots in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(leis_rec) +
  tm_dots(col = "red", size = 0.005, title = "Leisure & Recreation Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
var_hc$LEISURE_COUNT <- lengths(st_intersects(var_hc, leis_rec))
```

## Retail

```{r}
retail <- st_read(dsn = "data/geospatial", layer = "Retails")
```

::: {.callout-important appearance="simple"}
### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Retail Outlets in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(retail) +
  tm_dots(col = "red", size = 0.005, title = "Retail Outlets") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
var_hc$RETAIL_COUNT <- lengths(st_intersects(var_hc, retail))
```
:::

We now have the variables in `var_hc`.

```{r}
kable(head(var_hc))
```

Now, we will process the other variables that need additional processing.

## Train Station Exits

We will download the *Train Station Exit Point* from [LTA DataMall](https://datamall.lta.gov.sg/content/dam/datamall/datasets/Geospatial/TrainStationExit.zip). This is a geospatial `shp` file so we can import it the same way as the previous datasets.

```{r}
train_exits <- st_read(dsn = "data/geospatial", layer = "Train_Station_Exit_Layer")
```

::: {.callout-caution collapse="true" appearance="simple"}
### Correcting the projection

We want to use [SVY21](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) as the projection for this study as it is the projection used for local Singaporean context.

After the import, it shows that the **Projected CRS**is **SVY21**. However, checking the CRS with `st_crs()` tells a different story.

```{r}
st_crs(train_exits)
```

As we can see EPSG value is **9001**, which correspond to [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We have to fix the projection by transforming to EPSG value of **3414**, which corresponds to **SVY21**.

```{r}
train_exits <- st_transform(train_exits, crs = 3414)
```
:::

### Visual inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Train Station Exits in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(train_exits) +
  tm_dots(col = "red", size = 0.005, title = "Train Station Exits") +
  tm_grid(alpha = 0.2)
```

```{r}
var_hc$TRAIN_EXITS_COUNT <- lengths(st_intersects(var_hc, train_exits))
```

::: {.callout-warning collapse="true"}
### Data clear point

We do not need the data used to read the `shp` contents anymore as we have already derived the variables from them.

```{r}
#| eval: true
rm(busstops)
rm(entertn)
rm(f_and_b)
rm(leis_rec)
rm(retail)
rm(train_exits)
```
:::

## HDB Population

Next, we will derive the population data for each zone. We will use aspatial dataset provided, `hdb.csv`.

### Importing the data

We will first import the aspatial `hdb.csv`.

```{r}
hdb_csv <- read_csv("data/aspatial/hdb.csv")
kable(head(hdb_csv))
```

::: {.callout-tip appearance="minimal"}
Despite being an aspatial dataset, there are columns where we can derive geospatial data from, `lng` and `lat`.
:::

We will first convert this to a `sf` data type, which uses **WGS 84** and transform it to **SVY21**.

```{r}
hdb_sf <- hdb_csv %>% st_as_sf(coords = c("lng", "lat"),
                               crs = 4326) %>%
  st_transform(crs = 3414)
```

::: {.callout-important appearance="simple"}
#### Visual inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of HDB Blocks in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(hdb_sf) +
  tm_dots(col = "red", size = 0.001, title = "HDB Blocks") +
  tm_grid(alpha = 0.2)
```
:::

::: {.callout-note collapse="true"}
#### On the HDB-related variables

We will not have an accurate number for the population for each zone as we have incomplete data of residents in each zone. We have to account for other housing options like private residents, dormitories, etc.

For this study, we will use both the number of **HDB per zone** and the **number of dwellings** in each zone as a population proxy.
:::

### Removing unnecessary data

Now that we have inspected the the data contents, we can proceed with trimming out the unnecessary elements. We will only retain the **residential** blocks (there are commercial and market blocks without residents), the **total_dwelling_units** column, and lastly, the geometry.

```{r}
hdb_filtered_sf <- hdb_sf %>%
  filter(residential == "Y") %>%
  select(total_dwelling_units)
```

### Adding *HDB_COUNT*

This variable will contain the number of **HDB blocks** in a zone. We will use the same methods to count the number locations in the zone, by using `lengths()` and `st_intersects()`.

```{r}
# TODO: Remove if this is unnecessary after all
var_hc$HDB_COUNT <- lengths(st_intersects(var_hc, hdb_filtered_sf))
```

### Adding *HDB_DWELLING_COUNT*

While `HDB_COUNT` can be a good population proxy, we need to consider that HDB blocks have different sizes. For example, taller and wider blocks may have more units compared to shorter blocks.

As such, we will use `total_dwelling_units` to improve our population proxy.

We need to aggregate the sum of `total_dwelling_units` per hexagon, and doing a `left_join()` with `var_hc`.

```{r}
var_hc <- var_hc %>%
  left_join(
    st_intersection(hdb_filtered_sf, var_hc) %>%
      st_drop_geometry() %>%
      group_by(HEX_ID) %>%
      summarize(HDB_DWELLING_COUNT = sum(total_dwelling_units))
  )
var_hc$HDB_DWELLING_COUNT[is.na(var_hc$HDB_DWELLING_COUNT)] <- 0
kable(head(var_hc))
```

::: {.callout-note appearance="simple"}
According to the [2022 official statistics](https://www.singstat.gov.sg/find-data/search-by-theme/households/households/latest-data) from Department of Statistics, the average household size is **3.09 person**.

While we can multiply the number of dwellings with this number to estimate the number of residents per zone, it is wise to stop at `HDB_DWELLING_COUNT` as the other variables all represent the number of a location type per zone. If we have a variable with a different unit, i.e. *persons*, the simulations may not give us the expected results.
:::

::: {.callout-warning collapse="true"}
### Data clear point

We do not need the intermediate data used to derive the HDB-based variables so we can remove them from the environment.

```{r}
rm(hdb_csv)
rm(hdb_sf)
rm(hdb_filtered_sf)
```
:::

## Visualizing the attractiveness and propulsiveness variables

Next, we will visualize the [Attractiveness and Propulsiveness Variables] with the flowline, to check if the busiest bus flows correspond to these factors we identified.

To simplify the visualization, we will add the counts for the different variables. We will do this by using `mutate()` to generate the sums.

::: {.callout-note collapse="true" appearance="simple"}
### Why we need to generate totals without the population proxy

When we do a summary of the variable values, we can see that `HDB_DWELLING_COUNT` is higher than the other variable values.

```{r}
kable(summary(var_hc))
```

If we visualize the factors, we won't be able to see the influence of the other factors to the flows.
:::

```{r}
var_totals_hc <- var_hc
var_totals_hc <- var_totals_hc %>%
  mutate(ATTRACTIVENESS_TOTAL =
           BUS_STOP_COUNT + TRAIN_EXITS_COUNT +
           HDB_DWELLING_COUNT +
           RETAIL_COUNT +
           LEISURE_COUNT +
           ENTERTN_COUNT +
           F_AND_B_COUNT) %>%
  mutate(ATTRACTIVENESS_NO_POP_TOTAL =
           BUS_STOP_COUNT + TRAIN_EXITS_COUNT +
           RETAIL_COUNT +
           LEISURE_COUNT +
           ENTERTN_COUNT +
           F_AND_B_COUNT) %>%
  mutate(PROPULSIVENESS_TOTAL =
           BUS_STOP_COUNT + TRAIN_EXITS_COUNT +
           HDB_DWELLING_COUNT) %>%
  mutate(PROPULSIVENESS_NO_POP_TOTAL =
           BUS_STOP_COUNT + TRAIN_EXITS_COUNT) %>%
  select(HEX_ID,
         ATTRACTIVENESS_TOTAL,
         ATTRACTIVENESS_NO_POP_TOTAL,
         PROPULSIVENESS_TOTAL,
         PROPULSIVENESS_NO_POP_TOTAL)
kable(head(var_totals_hc))
```

::: {.callout-note appearance="minimal"}
We will use **tabsets** to compare the 2 maps by switching between tabs.
:::

### Visualizing all variables

::: panel-tabset
#### Attractiveness

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("white", title = "Singapore Boundary") +
  
  tm_shape(var_totals_hc) +
  tm_polygons("ATTRACTIVENESS_TOTAL", palette = "Greens", style = "quantile") +
  
  tm_shape(
    flowlines %>%
      remove_intra() %>%
      filter(TRIPS > 376)) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7, 10),
           title.lwd = "# of bus trips",
           n = 6,
           alpha = 0.5) +
  
  tm_layout(main.title = "Top 5% Bus Passenger flows and Attractiveness Factors",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2) +
  tm_credits("*Passenger data from weekend/holidays 11AM - 2PM\n(October 2023)",
             bg.color = "white", bg.alpha = 0.5,
             position = c("right", "top"))
```

#### Propulsiveness

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("white", title = "Singapore Boundary") +
  
  tm_shape(var_totals_hc) +
  tm_polygons("PROPULSIVENESS_TOTAL", palette = "Purples", style = "quantile") +
  
  tm_shape(
    flowlines %>%
      remove_intra() %>%
      filter(TRIPS > 376)) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7, 10),
           title.lwd = "# of bus trips",
           n = 6,
           alpha = 0.5) +
  
  tm_layout(main.title = "Top 5% Bus Passenger flows and Propulsiveness Factors",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2) +
  tm_credits("*Passenger data from weekend/holidays 11AM - 2PM\n(October 2023)",
             bg.color = "white", bg.alpha = 0.5,
             position = c("right", "top"))
```
:::

::: {.callout-tip appearance="simple"}
#### Insights

The maps have similar patterns on the attractiveness and propulsiveness factors. This is to be expected as these values are heavily influenced by `HDB_DWELLINGS_COUNT`.

The zones with high attractiveness and propulsiveness correspond the popular intersections of the flowlines. This indicates that there is **high usage of buses in residential areas**.

However, we are not clear on whether passengers board or alight the buses more in residential hubs at this point in time. A flow analysis will help us gain further insights on this matter.
:::

### Visualizing without population

Now, we will plot the maps of the attractiveness and propulsiveness factors without `HDB_DWELLING_COUNT` to see the effects of the factors we identified, without the population factor.

::: panel-tabset
#### Attractiveness

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("white", title = "Singapore Boundary") +
  
  tm_shape(var_totals_hc) +
  tm_polygons("ATTRACTIVENESS_NO_POP_TOTAL", palette = "Greens", style = "quantile") +
  
  tm_shape(
    flowlines %>%
      remove_intra() %>%
      filter(TRIPS > 376)) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7, 10),
           title.lwd = "# of bus trips",
           n = 6,
           alpha = 0.5) +
  
  tm_layout(main.title = "Top 5% Bus Passenger flows and Attractiveness Factors (w/o Population)",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2) +
  tm_credits("*Passenger data from weekend/holidays 11AM - 2PM\n(October 2023)",
             bg.color = "white", bg.alpha = 0.5,
             position = c("right", "top"))
```

#### Propulsiveness

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("white", title = "Singapore Boundary") +
  
  tm_shape(var_totals_hc) +
  tm_polygons("PROPULSIVENESS_NO_POP_TOTAL", palette = "Purples", style = "quantile") +
  
  tm_shape(
    flowlines %>%
      remove_intra() %>%
      filter(TRIPS > 376)) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7, 10),
           title.lwd = "# of bus trips",
           n = 6,
           alpha = 0.5) +
  
  tm_layout(main.title = "Top 5% Bus Passenger flows and Propulsiveness Factors (w/o Population)",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2) +
  tm_credits("*Passenger data from weekend/holidays 11AM - 2PM\n(October 2023)",
             bg.color = "white", bg.alpha = 0.5,
             position = c("right", "top"))
```
:::

::: {.callout-tip appearance="simple"}
#### Insights

Compared to the plots that include `HDB_DWELLING_COUNT`, the flows match the attractiveness and propulsiveness maps less.

We need to consider that we simplified the visualizations by adding all the variables so details like the effect of each location type in bus ridership are loss, especially on the attractiveness map, as we have more variables.

The propulsiveness map correspond to the flow lines better, but that is because we include the bus stops, which are the origin and destinations of our data set.

Once we model the flows, we can better see the effects of the individual variables, e.g. `TRAIN_EXITS_COUNT`, `RETAIL_COUNT`.
:::

We must also consider that we [visualized only the top 5% of `TRIPS` count](#visualizing-the-top-5-busiest-flows), so if there are zones with passengers from multiple bus stops, they will not show up. For example, **1000 trips coming from a single bus stop** will show up but **100 trips from 10 different bus stops** won't show up.

Another thing of note is that the busiest pair, which is from **Kranji to Woodlands Checkpoint** do not correspond strongly with the attractiveness and propulsiveness factors we defined. We may need details like **passengers alighting from train stations** as a propulsiveness variable, and add **international access** as attractiveness variable.

::: {.callout-warning collapse="true"}
### Data clear point

We do not need `var_totals_hc` anymore so we can remove it. Also, as we are done with the flow visualizations, we also can remove `flowlines`

```{r}
#| eval: true
rm(var_totals_hc)
rm(flowlines)
```
:::

# Preparing modelling data

::: {.callout-note collapse="true"}
## Load point

We can run from this point by loading these data.

```{r}
honeycomb <- read_rds("data/rds/honeycomb.rds")
od_hex <- read_rds("data/rds/od_hex202310.rds")
```

We also need to define the `remove_intra()` as we are removing the intra_zonal flows from our visualization.

```{r}
remove_intra <- function(df) {
  df %>% filter(
    ORIG_HEX_ID != DEST_HEX_ID
  )
}
```
:::

Now that we have the data for the variables, we will now make further preparations to shape data that can be used with `glm()` for our flow models.

## Modelling data shape

To make our data usable for modeling, we need to create a data set with the following columns:

-   `ORIG_HEX_ID` - corresponding to the origin zone

-   `DEST_HEX_ID` - corresponding to the destination zone

-   `DISTANCE` - distance between the origin and destination hexagons, this is the **cost** variable of the model

-   `ORIG_*_COUNT` - propulsiveness variables

-   `DEST_*_COUNT` - attractiveness variables

-   `TRIPS` - the dependent variable

Lastly, the size of this data must be , $N_{hexagons}^2 = 831^2$ which in our case is:

```{r}
nrow(honeycomb) ^ 2
```

## Calculating distances

We will first calculate the distances from each hexagon to each of the other hexagon as in our modelling, this will serve as the **cost** variable, as people need to spend more time by travelling long distance to their destination.

### Generating distance matrix

We will use `spDists()` to generate the matrix from our `honeycomb`, which requires a *Spatial* data frame. We also need to name the columns and rows to the corresponding `HEX_ID` of the hexagons.

```{r}
dist_mat <- spDists(as(honeycomb, "Spatial"),
                    longlat = FALSE)
colnames(dist_mat) <- paste0(honeycomb$HEX_ID)
rownames(dist_mat) <- paste0(honeycomb$HEX_ID)
kable(head(dist_mat, n=c(8, 8)))
```

::: {.callout-tip appearance="minimal"}
As expected, many of the distances are **multiples of 750** as we set our hexagon size to 750m edge-to-edge. This also means that the distance between centroids of adjacent hexagons is **750m**.
:::

### Generating a pivot table

To generate data with the specifications we defined in [Modelling data shape], we must generate a pivot table from our distance matrix, `dist_mat`.

We will use `melt()`, for this purpose and rename the columns to names we defined in our modelling data shape.

```{r}
dist_tbl <- melt(dist_mat) %>%
  rename(DISTANCE = value) %>%
  rename(ORIG_HEX_ID = Var1) %>%
  rename(DEST_HEX_ID = Var2)
kable(head(dist_tbl))
```

### Setting intra-zonal distances

Intra-zonal distances are currently **0**. This can be a result of passengers taking a short bus ride to the next stop. We have to set these to a value other than 0.

::: {.callout-important collapse="true" appearance="simple"}
#### Why can't we just keep them as 0?

As we are going to use **log-based Poisson models**, *log* operations will be applied to all independent variables (including distance).

$log(0) = undefined$ so we have to set it to a value **greater than 0**, as distances are **positive** in this context.
:::

::: {.callout-tip collapse="true" appearance="simple"}
#### What do we use as intra-zonal distance? Answer: 200m

To consider the intra-zonal distance for this context, we need to consider why people board and alight within the same zone.

The most plausible explanation is people riding the bus to the immediate next stop. With this thought process, we can base the intra-zonal distance from some of the closest bus stops within the same route, **School of the Arts** (Stop ID: 08079) and **Peace Ctr** (Stop ID: 07011).

![](images/sota_to_peace_ctr.png){fig-align="center"}

Bus routes like [**147**](https://www.transitlink.com.sg/eservice/eguide/service_route.php?service=147)and [**166**](https://www.transitlink.com.sg/eservice/eguide/service_route.php?service=166) pass by these bus stops so it is possible for the above scenario to happen here. As these may not be closest bus stops within the same route, we will round the value down to **200m**.
:::

We will set the intra-zonal distances to **200m**.

```{r}
dist_tbl$DISTANCE[dist_tbl$ORIG_HEX_ID == dist_tbl$DEST_HEX_ID] <- 200
summary(dist_tbl$DISTANCE)
```

::: {.callout-note appearance="simple"}
`dist_tbl` will be the base of our modelling data as it contains all the possible pairs of our set of hexagons.

As such, we will initiate our modelling data using this data frame.

```{r}
model_data <- dist_tbl
```
:::

::: {.callout-warning collapse="true"}
### Data clear point

We do not need `dist_mat` and `dist_tbl` anymore as we have the model data in `model_data`

```{r}
#| eval: true
rm(dist_mat)
rm(dist_tbl)
```
:::

## Adding the variables

::: panel-tabset
### Trips

We will get the `TRIPS` data from `od_hex`.

::: {.callout-note collapse="true" appearance="simple"}
#### Recap of od_hex

```{r}
kable(head(od_hex))
```
:::

We will use `left_join()` to join this data with `model_data`, and set those with `NA` values to `0`.

```{r}
model_data <- left_join(model_data, od_hex)
model_data$TRIPS[is.na(model_data$TRIPS)] <- 0
kable(head(model_data))
```

### Propulsiveness

We will add the propulsiveness variables as `ORIG_*_COUNT` columns as they are factors forcing passengers to board the bus from specific origins.

Similarly, we will do this by joining `var_hc`, selecting the propulsiveness variables, and doing a `left_join()` with `model_data`. We also need to rename the included variables by adding a prefix `ORIG_` using `rename_with()`.

```{r}
propulsiveness <- var_hc %>%
  st_drop_geometry() %>%
  select(c(
    HEX_ID,
    BUS_STOP_COUNT,
    TRAIN_EXITS_COUNT,
    HDB_DWELLING_COUNT)) %>%
  rename_with(~paste("ORIG_", .x, sep = ""))

model_data <- left_join(model_data, propulsiveness)
rm(propulsiveness)

kable(head(model_data))
```

### Attractiveness

We will add the attractiveness variables as `DEST_*_COUNT` columns as they are factors attracting bus passengers to go alight from specific bus stops.

We will do this by joining `var_hc`, selecting the attractiveness variables, and doing a `left_join()` with `model_data`. We also need to rename the included variables by adding a prefix `DEST_` using `rename_with()`.

```{r}
attractive <- var_hc %>%
  st_drop_geometry() %>%
  select(c(
    HEX_ID,
    BUS_STOP_COUNT,
    ENTERTN_COUNT,
    F_AND_B_COUNT,
    LEISURE_COUNT,
    RETAIL_COUNT,
    TRAIN_EXITS_COUNT,
    HDB_DWELLING_COUNT)) %>%
  rename_with(~paste("DEST_", .x, sep = ""))

model_data <- left_join(model_data, attractive)
rm(attractive)

kable(head(model_data))
```
:::

::: {.callout-tip collapse="true"}
### Save point

Let's save `model_data` as it contains the data we need to model the flows.

```{r}
write_rds(model_data, "data/rds/model_data202310.rds")
```
:::

::: {.callout-warning collapse="true"}
### Data clear point

We do not need `od_hex` and `var_hc` anymore as we have everything we need in `model_data`.

```{r}
#| eval: true
rm(od_hex)
rm(var_hc)
```
:::
