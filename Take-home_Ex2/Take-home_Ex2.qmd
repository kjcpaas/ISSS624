---
title: "Take Home Exercise 2: A Case Study of Singapore Public Bus Commuter Flows"
author: "Kristine Joy Paas"
date: "6 Dec 2023"
date-modified: "last-modified"
format:
  html:
    toc: true
    toc-depth: 5
execute: 
  echo: true
  eval: true
  warning: false
---

# Overview

The aim of this exercise to study the bus commuter flow patterns in Singapore to gain insights that support decision-making.

We will be examining the **weekend morning peak hours** (11 AM - 2 PM) to figure out where people go during weekends and holidays.

We will also be the modelling the spatial interaction between the different locations in Singapore, related to the bus commuter patterns.

Check <https://isss624-ay2023-24nov.netlify.app/take-home_ex02> for the full requirements of this exercise.

## The Analysis

The analysis has two parts: (1) analyzing the spatial interactions between pairs of zone, (2) modelling the interaction.

We will create a honeycomb grid with hexagons with a distance of **375m** from the center to the midpoint of the edge as the [traffic analysis zone (TAZ)](https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf). These hexagons will serve as the **zones** for our analysis.

::: panel-tabset
### Spatial Interaction Analysis

We will visualize the interactions by plotting the flow lines corresponding to the number of trips between each pair of zones.

We need the following to start this analysis:

-   geometry with the traffic analysis zones

-   data about the number of trips between different pairs of zones

### Spatial interaction Modelling

We will generate 4 *log*-based Poisson models:

-   origin-constrained model

-   destination-constrained model

-   unconstrained model

-   doubly-constrained model

We need the following to start this analysis:

-   geometry with the traffic analysis zones

-   propulsiveness variables, which influence the number of of trips originating from a zone

-   attractiveness variables, which influence bus commuters to make a trip a zone

-   data about the number of trips between different pairs of zones

-   distance between each pair of zone

We use the different variables to generate formula for each model, which will be explored further in their respective sections.

Once the models are generated, we will also compare the models as to which one best fits our data, using **goodness of fit** test or $R^2$ test.
:::

To perform our modelling, we need to identify the propulsiveness and attractiveness variables we will use for our model.

As our data will be based on real-world data, *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API, we can think of possible factors based on our real-world experience.

As we are interested in the factors that influence **weekend/holiday morning (11 AM - 2PM)** peak period bus commuting patterns, we will consider the following variables.

::: panel-tabset
### Attractiveness {data-link="Attractiveness"}

Attractiveness variables are factors that can motivate people to go to their destinations. In our case, these are what *motivates people to ride to their destination bus stop*.

| Variable            | Data Source                                                                                                                                 | Motivation                                               |
|------------------------|------------------------|------------------------|
| `BUS_STOP_COUNT`    | *Bus Stop Location* from [LTA DataMall](https://datamall.lta.gov.sg/content/dam/datamall/datasets/Geospatial/BusStopLocation.zip)           | Transferring to another bus to their end destination     |
| `TRAIN_EXITS_COUNT` | *Train Station* *Exit Point* from [LTA DataMall](https://datamall.lta.gov.sg/content/dam/datamall/datasets/Geospatial/TrainStationExit.zip) | Transferring to train to their end destination           |
| `HDB_COUNT`         | `hdb.csv` aspatial data provided on E-learn                                                                                                 | To meet up with friends/family                           |
| `ENTERTN_COUNT`     | `entertn.shp` geospatial data provided on E-learn                                                                                           | For recreation, spending time with friends/family        |
| `F_AND_B_COUNT`     | `F&B.shp` geospatial data provided on E-learn                                                                                               | For spending time with friends/family                    |
| `LEISURE_COUNT`     | `Liesure&Recreation.shp` geospatial data provided on E-learn                                                                                | For recreation, spending time with friends/family        |
| `RETAIL_COUNT`      | `Retails.shp` geospatial data provided on E-learn                                                                                           | For errands, shopping, spending time with friends/family |

### Propulsiveness

Propulsiveness variables are factors that influence people to ride the bus from specific zones. This is based on the **number** **of potential passengers** at the origin zones.

| Variable             | Data Source                                                                                                                          | Motivation                                                                                        |
|------------------------|------------------------|------------------------|
| `BUS_ALIGHT_COUNT`   | *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API | Passengers who alight from a bus stop within can transfer to another bus to reach                 |
| `TRAIN_ALIGHT_COUNT` | *Passenger Volume By Train Stations* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API               | Passengers who alight from a train station can transfer to a bus to reach their final destination |
| `HDB_RESIDENT_COUNT` | `hdb.csv` aspatial data provided on E-learn                                                                                          | Residents in an area are potential bus passengers as they leave their homes                       |
:::

## Data Outputs

To accomplish our analysis, we need to prepare the data with the following specifications.

For all our geospatial data, we will use the [**SVY21**](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) projection it is appropriate for the Singapore context. Also, having a consistent projection will make it straightforward to use the functions from `sfdep`.

::: panel-tabset
### Utility

::: {.callout-note collapse="true" appearance="minimal"}
#### Singapore Boundary geometry (*mpsz)*

Sourced from `MPSZ-2019` geospatial data from E-learn, this will provide the Singapore boundary geometry for visualization purposes.

We will be using `tmap_mode("plot")` instead of `tmap_mode("view")` to make the code run more efficiently with less memory requirements.

**Prerequisites:** None

**Output data:** `mpsz` (geospatial)
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Honeycomb grid corresponding to bus stop locations (*honeycomb)*

Sourced from the `shp` [*Bus Stop Locations*](https://datamall.lta.gov.sg/content/datamall/en/static-data.html#:~:text=drop%20off%20passengers.-,203%20kB,-Last%20Update%3A%C2%A0Jul) dataset from LTA DataMall. This consist of hexagons with a distance of **375m** from the center to the midpoint of the edge as the [traffic analysis zone (TAZ)](https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf).

We only consider the bus stops within Singapore so we have to ensure that the bus stops included here are within the \[Singapore Boundary geometry (mpsz)\].

**Prerequisites:** \[Singapore Boundary geometry (mpsz)\]

**Output data:** `honeycomb` (geospatial)

**Columns:**

-   `HEX_ID`: Unique ID used to associate the zone with other data frames
-   Geometry of the hexagons corresponding to the traffic analysis zone
:::

### Spatial Interaction Analysis

::: {.callout-note collapse="true" appearance="minimal"}
#### Number of trips between 2 zones (*od_hex*) {#number-of-trips-between-2-zones-hexagon}

This contains the number of trips on **weekend/holiday morning peak periods** (11 AM - 2 PM). Data is sourced from *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API

This data will be used generating the flow lines for visualization, and for Spatial Interaction Modelling.

**Prerequisites:** \[Honeycomb grid corresponding to bus stop locations (honeycomb)\]

**Output data:** `od_hex` (aspatial)

**Columns**:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `TRIPS`: Number of bus trips between the origin and destination zones
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Flow Lines (*flowlines*)

This contains the flow lines derived from the pairs of zones in \[Number of trips between 2 zones (od_hex)\]. It will be used to visualize the flow patterns.

**Prerequisites:** \[Number of trips between 2 zones (od_hex)\]

**Output data:** `flowlines`

**Columns**:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `TRIPS`: Number of bus trips between the origin and destination zones

-   Geometry of the line between the origin and destination zones
:::

### Spatial Interaction Modelling

::: {.callout-note collapse="true" appearance="minimal"}
#### Zone distance table (*dist_tbl*)

This table contains the distances between all the pair of zones. This corresponds to the **cost** component of our model

**Prerequisites:** \[Honeycomb grid corresponding to bus stop locations (honeycomb)\]

**Output data:** `dist_tbl` (aspatial)

**Columns**:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `DISTANCE`: Distance between the (centroids of) origin and destination zones
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Attractiveness Variables Table (*attractiveness*)

This table contains the values of the [Attractiveness] variables. Data sources are defined in the [Attractiveness] section.

**Prerequisites:** \[Honeycomb grid corresponding to bus stop locations (honeycomb)\], prepared data from identified data sources

**Output data:** `attractiveness` (geospatial)

**Columns**:

-   `HEX_ID`: ID corresponding to the zone
-   `BUS_STOP_COUNT`: Number of bus stops in a zone
-   `TRAIN_EXITS_COUNT`: Number of train station exits in a zone
-   `HDB_COUNT`: Number of HDB blocks in a zone
-   `ENTERTN_COUNT`: Number of entertainment locations in a zone
-   `F_AND_B_COUNT`: Number of F&B outlets in a zone
-   `LEISURE_COUNT`: Number of leisure and recreation in a zone
-   `RETAIL_COUNT`: Number of retail locations in a zone
-   Geometry of the hexagons corresponding to the traffic analysis zone
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Propulsiveness Variables Table (*propulsiveness*)

This table contains the values of the [Propulsiveness] variables. Data sources are defined in the [Propulsiveness] section.

**Prerequisites:** \[Honeycomb grid corresponding to bus stop locations (honeycomb)\], prepared data from identified data sources

**Output data:** `propulsiveness` (geospatial)

**Columns**:

-   `HEX_ID`: ID corresponding to the zone

-   `BUS_ALIGHT_COUNT`: Number of bus passengers alighting from a zone

-   `TRAIN_ALIGHT_COUNT`: Number of train passengers alighting from a zone

-   `HDB_RESIDENT_COUNT`: Number of residents in a zone

-   Geometry of the hexagons corresponding to the traffic analysis zone
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Model Data (*model_data*)

Contains all the data we need to model the interaction.

**Prerequisites:**

-   \[Zone distance table (dist_tbl)\]

-   \[Number of trips between 2 zones (od_hex)\]

-   \[Attractiveness Variables Table (attractiveness)\]

-   \[Propulsiveness Variables Table (propulsiveness)\]

**Output data:** `model_data` (aspatial)

**Columns**:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `DISTANCE`: Distance between the (centroids of) origin and destination zones

-   `TRIPS`: Number of bus trips between the origin and destination zones

-   `DEST_*_COUNT`: Values from \[Attractiveness Variables Table (attractiveness)\]

-   `ORIG_*_COUNT`: Values from \[Propulsiveness Variables Table (propulsiveness)\]
:::
:::

## Managing our data

As this process is expected to have a lot of intermediate steps, **Save**, **Load**, and **Data clear** points are available to make our data wrangling more efficient.

::: callout-tip
### Save point

This is where data is written as `rds` files using `write_rds()` for important data sets that will be used in later analysis. Examples are:

-   Data we need to prepare for analysis
-   Critical outputs of expensive calculations
-   Cleaned up data for lightweight processing
:::

::: callout-note
### Load point

This is where data is loaded from `rds` files using `read_rds()`. They were previously generated by the save point.

**TIP**: Skip to the load points to progress without running the code above it
:::

::: callout-warning
### Data clear point

This is where data that will not be used anymore are cleared. The data in RStudio environment will pile up and will make it more difficult to check the relevant data in each part.

We can set `#| eval: false` in code chunks if we want skip the clearing. For example, the code below won't be run.

```{r}
#| eval: false
message <- "This code chunk executed"
```
:::

# Setup

::: panel-tabset
## Datasets

Using the data sources identified in [Data Outputs], we will download the datasets and add them into our `data/` directory.

We will also prepare the `data/rds/` directory to save the data we from our [Load point]. After the setup we are left with the directory structure below.

::: {.callout-note collapse="true" appearance="simple"}
## Directory structure

``` bash
Take-home_Ex2/data
├── aspatial
│   ├── hdb.csv
│   ├── origin_destination_bus_202310.csv
│   └── origin_destination_train_202310.csv
├── geospatial
│   ├── BusStop.cpg
│   ├── BusStop.dbf
│   ├── BusStop.lyr
│   ├── BusStop.prj
│   ├── BusStop.sbn
│   ├── BusStop.sbx
│   ├── BusStop.shp
│   ├── BusStop.shp.xml
│   ├── BusStop.shx
│   ├── F&B.cpg
│   ├── F&B.dbf
│   ├── F&B.prj
│   ├── F&B.qix
│   ├── F&B.qmd
│   ├── F&B.shp
│   ├── F&B.shx
│   ├── Liesure&Recreation.cpg
│   ├── Liesure&Recreation.dbf
│   ├── Liesure&Recreation.prj
│   ├── Liesure&Recreation.qmd
│   ├── Liesure&Recreation.shp
│   ├── Liesure&Recreation.shx
│   ├── MPSZ-2019.cpg
│   ├── MPSZ-2019.dbf
│   ├── MPSZ-2019.prj
│   ├── MPSZ-2019.qmd
│   ├── MPSZ-2019.shp
│   ├── MPSZ-2019.shx
│   ├── RapidTransitSystemStation.cpg
│   ├── RapidTransitSystemStation.dbf
│   ├── RapidTransitSystemStation.lyr
│   ├── RapidTransitSystemStation.prj
│   ├── RapidTransitSystemStation.sbn
│   ├── RapidTransitSystemStation.sbx
│   ├── RapidTransitSystemStation.shp
│   ├── RapidTransitSystemStation.shp.xml
│   ├── RapidTransitSystemStation.shx
│   ├── Retails.cpg
│   ├── Retails.dbf
│   ├── Retails.prj
│   ├── Retails.qix
│   ├── Retails.qmd
│   ├── Retails.shp
│   ├── Retails.shx
│   ├── entertn.cpg
│   ├── entertn.dbf
│   ├── entertn.prj
│   ├── entertn.qix
│   ├── entertn.qmd
│   ├── entertn.shp
│   └── entertn.shx
└── rds
```
:::

## R Packages

We will use the following R packages to run the code needed for data analysis.

-   [**tmap**](https://cran.r-project.org/web/packages/tmap/index.html): for thematic mapping

-   [**sf**](https://cran.r-project.org/web/packages/sf/index.html): for geospatial data handling

-   [**tidyverse**](https://cran.r-project.org/web/packages/tidyverse/index.html): for non-spatial data handling

-   [**knitr**](https://cran.r-project.org/web/packages/knitr/): for prettifying presentation

-   [**stplanr**](https://cran.r-project.org/web/packages/stplanr/index.html): for generating flow lines

## Environment Settings

These are the default setting we will use, and initial setup required for the environment.

-   `tmap_mode` to **plot**: for plotting simple maps

-   `tmap_style` to **natural**: for my preferred mapping style

-   set **seed** for reproducibility of results
:::

Using the setup tasks identified above, we will now run the setup code.

::: {.callout-note appearance="simple"}
We will label this code chunk with `label: setup` so it will always be run even if we reset our environment and start in the middle of the page
:::

```{r}
#| label: setup
pacman::p_load(sf, sp, tmap, tidyverse, knitr, stplanr)
#pacman::p_load(sf, sp, tmap, tidyverse, knitr, sfdep, stplanr, reshape2)
tmap_mode("plot")
tmap_style("natural")
set.seed(1234)
```

# Data Wrangling

Using the [Data Outputs] previously identified, we generate the dependency map below.

![](images/data_dependency_map.png)

## Utility

We will first start by preparing the data needed for utility, \[Singapore Boundary geometry (mpsz)\] and \[Honeycomb grid corresponding to bus stop locations (honeycomb)\].

### Importing the datasets

We will import the datasets needed to prepare the utility data.

::: panel-tabset
#### Singapore boundary map

We will import the **Master Plan 2019 Subzone Boundary (Web)** data set that has been used in class. We will only keep the `SUBZONE_N` column and the geometry as we will only use this as the **base for our visualizations**.

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                layer = "MPSZ-2019") %>%
  select(SUBZONE_N)
```

::: {.callout-caution collapse="true" appearance="simple"}
##### Correcting the projection

This data frame using the global GPS standard, [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We need to convert this to [**SVY21**](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) projection that we will use for all our data in our analysis.

```{r}
mpsz <- mpsz %>% st_transform(crs=3414)
```
:::

::: {.callout-important collapse="true" appearance="simple"}
##### Visual inspection

We will do a quick visual inspection to check if the map has been imported as expected.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```

::: {.callout-tip collapse="true"}
##### Save point

Let's save this geometry as this is one of our Utility data outputs, \[Singapore Boundary geometry (mpsz)\].

```{r}
write_rds(mpsz, "data/rds/mpsz.rds")
```
:::
:::

#### BusStop (shp)

Next, we need to import the bus stop data as we will generate the honeycomb grid based on locations with bus stops.

```{r}
busstops <- st_read(dsn = "data/geospatial",
                    layer = "BusStop")
```

::: {.callout-caution collapse="true" appearance="simple"}
##### Correcting the projection

We want to use [SVY21](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) as the projection for this study as it is the projection used for local Singaporean context.

After the import, it shows that the **Projected CRS**is **SVY21**. However, checking the CRS with `st_crs()` tells a different story.

```{r}
st_crs(busstops)
```

As we can see EPSG value is **9001**, which correspond to [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We have to fix the projection by transforming to EPSG value of **3414**, which corresponds to **SVY21**.

```{r}
busstops <- st_transform(busstops, crs = 3414)
```
:::

::: {.callout-important collapse="true" appearance="simple"}
##### Visual inspection

We will do a quick visual inspection to check if the map has been imported as expected.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tmap_style("natural")
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of bus stops in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.005, title = "Bus Stops") +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```

The map shows that there are bus stops in our data set that are outside Singapore bounds (green area). We need to remove them as we are only interested in bus stops within Singapore.

::: {.callout-important appearance="simple" collapse="true"}
##### Removing the bus stops outside Singapore

We can remove the points outside Singapore from our `busstops` data by using `st_intersection()`.

We will use this as `busstops` contains points, the intersection of the 2 geometries will generate points corresponding to the bus stops within Singapore.

We will also just retain the `BUS_STOP_N` to remove the columns we do not need.

```{r}
busstops <- busstops %>% st_intersection(mpsz) %>% select(BUS_STOP_N, )
```

Visualizing again, all the bus stops are now within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tmap_style("natural")
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of bus stops in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.005, title = "Bus Stops") +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```
:::
:::
:::

### Generating the honeycomb grid

Finally, we can generate the honeycomb grid using `st_make_grid()`, providing *cellsize* of **750m**.

::: {.callout-tip collapse="true" appearance="simple"}
#### Calculating cellsize

[Apothem](https://www.merriam-webster.com/dictionary/apothem) is defined as *the perpendicular from the center of a regular polygon to one of the sides**.***

The specification is this study requires hexagons to be **375 m** from the center of the hexagon to the center of one of it's edge.

![](images/apothem.png){fig-align="center"}

As such, this corresponds to the length of 2 opposite apothems, which is **750 m**.

The edge length is **not** the same as apothem. It is **433.013 m**m.

$$
375m/cos(30) = 433.013m
$$
:::

```{r}
honeycomb <- busstops %>% st_make_grid(cellsize = 750,
                                       what="polygons",
                                       square = FALSE) %>%
  st_sf() %>%
  filter(lengths(st_intersects(geometry, busstops)) > 0)
```

::: {.callout-tip collapse="true" appearance="simple"}
#### Code Explanation

st_make_grid()

:   Creates a grid that covers the entire bus stop geometry, including areas without bus stop.

st_sf()

:   Converts to simple feature data set

st_intersects()

:   Checks if the hexagons have bus stops

filter()

:   Removes hexagons without bus stops
:::

Let's plot the map to visually inspect if the hexagons cover all the bus stop locations.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Honeycomb grid corresponding to Singapore bus stops",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.001, title = "Bus Stops") +
  tm_grid(alpha = 0.2)
```

### Assigning id to each hexagon

Now that we have hexagons properly generated, we will assign id for each hexagon to be used as a unique identifier. We will store this id under the `HEX_ID` column, and can be used in joining data frames.

```{r}
honeycomb$HEX_ID <- sprintf("H%04d", seq_len(nrow(honeycomb))) %>% as.factor()
kable(head(honeycomb))
```

::: {.callout-tip collapse="true"}
### Save point

Let's save `honeycomb` as it contains the main geometry we will use in analysis.

```{r}
write_rds(honeycomb, "data/rds/honeycomb.rds")
```
:::

## Spatial Interaction Analysis

### Importing the datasets

We will import the datasets needed to prepare the data outputs, \[Number of trips between 2 zones (od_hex)\] and \[Flow Lines (flowlines)\].

Aside from the output of [Utility], we also need to import the *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API for the month of **October 2023**.

The data set is an aspatial data in `csv` format so we will use `read_csv()` to import the data.

::: {.callout-note appearance="simple"}
We will use the October 2023 passenger data in this document. If you want to use dataset for another month, replace `202310` to the corresponding `YYYYMM` format.
:::

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
kable(head(odbus))
```

### Generating the O-D trip data by hexagon level

#### Filtering the relevant data

We only need the data for the **weekend morning peak period**, which is from 11 AM - 2 PM on weekends and holidays. As such, we will filter the data for the relevant hours.

We will also rename the `ORIGIN_PT_CODE` and `DESTINATION_PT_CODE` to be consistent with the naming with `busstops` as these columns can be associated to `busstops`'s `BUS_STOP_N`

::: {.callout-tip collapse="true" appearance="simple"}
##### How to filter data by *TIME_PER_HOUR*

The `TIME_PER_HOUR` in data set covers the data from the start to the end of the hour in **24-hour format**, i.e. when `TIME_PER_HOUR = 13`, this means bus taps from `1:00 PM` ton`1:59:59PM`.

Hence, if we want to get 11AM to 2PM data, we will filter by:

```         
TIME_PER_HOUR >= 11 & TIME_PER_HOUR < 14
```
:::

```{r}
od_trips <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter( TIME_PER_HOUR >= 11 &
            TIME_PER_HOUR < 14
          ) %>%
  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  rename(
    ORIG_BUS_STOP_N = ORIGIN_PT_CODE,
    DEST_BUS_STOP_N = DESTINATION_PT_CODE
  )
kable(head(od_trips))
```

::: {.callout-warning collapse="true"}
##### Data clear point

We do not need `odbus` anymore as we already extracted the data relevant to our analysis.

```{r}
#| eval: true
rm(odbus)
```
:::

#### Generating lookup table for bus stop to associated hexagon

To connect the trip data to the their corresponding hexagon, we need to create a lookup table. This will serve as a glue in associating the aspatial `od_trips` data frame to the `honeycomb` data frame.

This can be done via `st_intersection()`.

```{r}
bs_hex <- st_intersection(busstops, honeycomb) %>%
  st_drop_geometry() %>%
  select(c(BUS_STOP_N, HEX_ID))
kable(head(bs_hex))
```

#### Joining *od_trips* and *bs_hex*

Next, we need to associate each origin bus stop and destination bus stop to their corresponding hexagons.

We can use that by doing `inner_join()` twice, once for the origin and another for the destination.

::: {.callout-tip collapse="true"}
##### Why *inner_join()* instead of *left_join()*?

We will use `inner_join` as there are `BUS_STOP_N` values in `od_trips` data that are not in `bs_hex`.

```{r}
c(
  od_trips$ORIG_BUS_STOP_N[!(od_trips$ORIG_BUS_STOP_N %in% bs_hex$BUS_STOP_N)],
  od_trips$DEST_BUS_STOP_N[!(od_trips$DEST_BUS_STOP_N %in% bs_hex$BUS_STOP_N)]
) %>% unique() %>% length()
```

There are **59** bus stops in `od_trips` that are not in `bs_hex`. **5** of these can be attributed the bus stops we removed due to them being out in Singapore. Others may be due to the *BusStops* data set not having complete information.

The proper way to handle this is to validate the existence of each of these bus stops and look at public sources (e.g. Google Maps, LTA data) and add coordinate data. However, as we do not have much to do this task, we have to **remove** these bus stops from our analysis as **we do not have geospatial data** to associate to the hexagons from the data sets available to us.

Therefore, we will use `inner_join` to keep only the observations in `trips` with the matching bus stops in `bs_hex`.
:::

```{r}
od_trips_w_hex <- od_trips %>%
  inner_join(bs_hex,
             by = c("ORIG_BUS_STOP_N" = "BUS_STOP_N")) %>%
  rename(ORIG_HEX_ID = HEX_ID) %>%
  inner_join(bs_hex,
             by = c("DEST_BUS_STOP_N" = "BUS_STOP_N")) %>%
  rename(DEST_HEX_ID = HEX_ID)

kable(head(od_trips_w_hex))
```

#### Aggregating data by hexagon

Next, we will perform aggregations by `ORIG_HEX_ID` and `DEST_HEX_ID` to have an aggregated sum of trips by hexagon instead of bus stops.

```{r}
od_hex <- od_trips_w_hex %>%
  group_by(ORIG_HEX_ID, DEST_HEX_ID) %>%
  summarise(TRIPS = sum(TRIPS))
kable(head(od_hex))
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `od_hex` as it contains the `TRIP` data needed to visualize flow data and do spatial interaction modelling. Take note that this **includes intra-zonal trips**.

```{r}
write_rds(od_hex, "data/rds/od_hex202310.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need `bs_hex`, `od_trips_w_hex` anymore as we already have the necessary data for doing hexagon-based analysis in `od_hex`.

```{r}
#| eval: true
rm(bs_hex)
rm(od_trips_w_hex)
```

We will still keep `busstops` and `od_trips` as we need these for calculating attractiveness and propulsiveness variables.
:::

### Generating the flow lines

First, we will generate the flow lines using `od2line()`. `honeycomb` will be supplied as the `zone` as it contains the hexagons we are using as the **traffic analysis zones**.

```{r}
flowlines <- od_hex %>% od2line(
  honeycomb,
  zone_code = "HEX_ID")
```

#### Initial inspection of the flow lines

Next, we will do an initial inspection of the flow lines to check if they have been generated correctly.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  
  tm_shape(flowlines) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7),
           title.lwd = "# of bus trips",
           alpha = 0.8) +
  
  tm_layout(main.title = "Bus Passenger flow for Weekends/Holidays 11 AM - 2PM (October 2023)",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2)
```

::: {.callout-tip appearance="simple"}
#### Insights

The flow lines are sparse at the West side of Singapore, the **Jurong** and **Choa Chu Kang** areas. This is consistent with the observations that we have in the [Take-home Exercise 1](Take-home_Ex1/Take-home_Ex1) that these areas are least busy in terms of bus rides.

We can also notice that the thickest flow lines is between **Woodlands Chaeckpoint** and **Kranji Station**. There are not residential areas so our hypothesis that connecting transport points influence the bus passenger flow.
:::

::: {.callout-tip collapse="true"}
#### Save point

Let's save `flowlines` as it contains the data for spatial interaction that we will use later on.

```{r}
write_rds(flowlines, "data/rds/flowlines202310.rds")
```
:::

## Spatial Interaction Modelling

Next, we will prepare the data needed for spatial interaction modelling. Some of these are straightforward to get, especially those of attractiveness variables. Additional steps are needed for more complex data sets, like those needed for propulsiveness variables. We will derive those in a separate section.

### Attractiveness variables

We will first initiate `attractiveness` from `honeycomb`.

```{r}
attractiveness <- honeycomb
```

For all the variables, we only need to count the number of each location types for each hexagon. We will use a combination of `lengths()` and `st_intersects()` to derive this value.

::: panel-tabset
#### Bus Stops

```{r}
attractiveness$BUS_STOP_COUNT <- lengths(
  st_intersects(attractiveness, busstops))
```

#### Entertainment

```{r}
entertn <- st_read(dsn = "data/geospatial", layer = "entertn")
```

::: {.callout-important collapse="true" appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Entertainment Spots in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(entertn) +
  tm_dots(col = "red", size = 0.005, title = "Entertainment Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$ENTERTN_COUNT <- lengths(st_intersects(attractiveness, entertn))
```

#### F&B

```{r}
f_and_b <- st_read(dsn = "data/geospatial", layer = "F&B")
```

::: {.callout-important collapse="true" appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of F&B Establishments in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(f_and_b) +
  tm_dots(col = "red", size = 0.005, title = "F&B Establishments Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$F_AND_B_COUNT <- lengths(st_intersects(attractiveness, f_and_b))
```

#### Leisure & Recreation

```{r}
leis_rec <- st_read(dsn = "data/geospatial", layer = "Liesure&Recreation")
```

::: {.callout-important appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Leisure & Recreation Spots in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(leis_rec) +
  tm_dots(col = "red", size = 0.005, title = "Leisure & Recreation Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$LEISURE_COUNT <- lengths(st_intersects(attractiveness, leis_rec))
```

#### Retail

```{r}
retail <- st_read(dsn = "data/geospatial", layer = "Retails")
```

::: {.callout-important collapse="true" appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Retail Outlets in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(retail) +
  tm_dots(col = "red", size = 0.005, title = "Retail Outlets") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$RETAIL_COUNT <- lengths(st_intersects(attractiveness, retail))
```

#### Train Station Exits

```{r}
train_exits <- st_read(dsn = "data/geospatial", layer = "Train_Station_Exit_Layer")
```

::: {.callout-caution collapse="true" appearance="simple"}
##### Correcting the projection

We want to use [SVY21](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) as the projection for this study as it is the projection used for local Singaporean context.

After the import, it shows that the **Projected CRS** is **SVY21**. However, checking the CRS with `st_crs()` tells a different story.

```{r}
st_crs(train_exits)
```

As we can see EPSG value is **9001**, which correspond to [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We have to fix the projection by transforming to EPSG value of **3414**, which corresponds to **SVY21**.

```{r}
train_exits <- st_transform(train_exits, crs = 3414)
```
:::

::: {.callout-important appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Train Station Exits in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(train_exits) +
  tm_dots(col = "red", size = 0.005, title = "Train Station Exits") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$TRAIN_EXITS_COUNT <- lengths(st_intersects(attractiveness, train_exits))
```
:::

Let's check if the attractiveness variables have been added correctly.

```{r}
kable(head(attractiveness))
```

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need the data used to read the `shp` contents anymore as we have already derived the attractiveness variables from them.

```{r}
#| eval: true
rm(busstops)
rm(entertn)
rm(f_and_b)
rm(leis_rec)
rm(retail)

```
:::

### Deriving Train Passenger Data

One of our propulsiveness variables is the **number of passengers alighting from a train stations** as they are potential bus passengers, especially if they need to transfer to a bus to reach their final destination.

For this, we will import the *Passenger Volume By Train Stations* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API, which contains the number of tap outs from a station every hour. It has a similar structure to *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API, which we have been using in class so I will not dive deep in to the details on how to get passenger data from them as we are using the same techniques as the bus data.

#### Importing data sets

::: panel-tabset
##### Passenger Data

We will import the `csv` from *Passenger Volume By Train Stations* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API, using `read_csv()`.

```{r}
train_tap <- read_csv("data/aspatial/transport_node_train_202310.csv")
kable(head(train_tap))
```

We only need data for **weekend/holidays 11AM - 2PM,** and the columns `PT_CODE` and `TAP_OUT_VOLUME` as we are only interested in passengers leaving the train station.

We will extract this the same way we did in [Filtering the relevant data].

```{r}
train_tap_out <- train_tap %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter( TIME_PER_HOUR >= 11 &
            TIME_PER_HOUR < 14
          ) %>%
  group_by(PT_CODE) %>%
  summarise(TAPS = sum(TOTAL_TAP_OUT_VOLUME)) %>%
  rename(TRAIN_ST_CODE = PT_CODE)
kable(head(train_tap_out))
```

::: {.callout-warning collapse="true"}
###### Data clear point

We do not need `train_tap` anymore as we already extracted the tap out data we need.

```{r}
#| eval: true
rm(train_tap)
```
:::

##### Station Code and Names

The passenger data only has the **train station code**, but not the name. However, `train_exits` only have the **station names**, not the station code.

::: {.callout-note collapse="true" appearance="simple"}
###### Recap of *train exits*

```{r}
kable(head(train_exits))
```
:::
Hence, we need way to connect the 2 datasets so we will use *Train Station Codes and Chinese Names* from [LTA DataMall](https://datamall.lta.gov.sg/content/dam/datamall/datasets/PublicTransportRelated/Train%20Station%20Codes%20and%20Chinese%20Names.zip).

```{r}
station_codes_names <- read_csv("data/aspatial/Train_Station_Codes_and_Chinese_Names.csv")
kable(head(station_codes_names))
```

We only need the station code and English names so we can remove the columns that are not needed.

```{r}
station_codes_names <- station_codes_names %>%
  select(stn_code, mrt_station_english)
```
:::

#### Adjusting data columns

To connect `train_exits`, `station_code_names`, and `train_tap_out`, we need to make adjustments to the columns.

::: panel-tabset
##### *station_code_names*

```{r}
kable(head(station_codes_names))
```

We need to capitalize the station names as the names are capitalized in `train_exits`. We can use `toupper()` to accomplish this.

```{r}
station_codes_names <- station_codes_names %>%
  mutate(stn_name = toupper(mrt_station_english))
kable(head(station_codes_names))
```

##### *train_tap_out*

```{r}
kable(head(train_tap_out[6:10,]))
```

There are multiple station codes in `TRAIN_ST_CODE` column, while in `station_codes_names`, the `stn_code` column only has 1 station code.

We have to separate these station codes into their own rows by using `separate_rows()`.

```{r}
train_tap_out <- train_tap_out %>%
  separate_rows(TRAIN_ST_CODE, sep="/")
kable(head(train_tap_out[6:10,]))
```

::: {.callout-tip appearance="simple"}
`station_codes_names` and `train_tap_out` now have the number of rows so they can be mapped one-to-one.

```{r}
nrow(station_codes_names) == nrow(train_tap_out)
```
:::

##### *train_exits*

```{r}
kable(head(train_exits))
```

Station names in `train_exits` have `MRT STATION` or `LRT STATION` while `station_code_names` does not have.

We have to remove this part of the name so we can join the tables properly. We can use `sub()` to remove this part of the station name.

```{r}
train_exits <- train_exits %>%
  mutate(stn_name_short = gsub(" [ML]RT STATION$" , "", stn_name))
kable(head(train_exits))
```
:::

#### Adding tap out information to exits

::: panel-tabset
##### Joining *station_code_names* and *train_tap_out*

We will join by the station code. Also, as some train stations have multiple station codes, we will remove the duplicates on the station name. This can be accomplished by selecting `stn_name` and `TAPS` and applying `unique()`. It is safe to not include the station code here anymore as `trains_exits` does not have the station code.

```{r}
train_tap_out_with_names <- station_codes_names %>%
  left_join(train_tap_out,
            by = join_by(stn_code == TRAIN_ST_CODE)) %>%
  select(stn_name, TAPS) %>%
  unique()
kable(head(train_tap_out_with_names))
```

##### Adding tap out to exits

Next, we join `train_tap_out_with_names` with `train_exits` to finally add the tap information to exits.

```{r}
tap_out_exit <- train_exits %>%
  left_join(train_tap_out_with_names,
            by = join_by(stn_name_short == stn_name)) %>%
  rename(STN_NAME = stn_name) %>%
  rename(EXIT_CODE = exit_code) %>%
  select(STN_NAME, EXIT_CODE, TAPS)
```
:::

```{r}
kable(head(tap_out_exit))
```

We now have the number of tap outs from station, that we can use as propulsive variable on the exits. We will **not distribute** these taps to the number of exits as we cannot be accurate on the volume of people taking specific exits. We can consider the people tapping out from a station **as potential passengers** of bus stop from the nearby exits.

#### Aggregating TAPS by Hexagon level

Finally, we can aggregate the taps on a hexagon level. We will do an `st_join()` of `honeycomb` and `tap_out_exit` as they are both of class `sf`.

```{r}
tap_out_hex <- honeycomb %>%
  st_join(tap_out_exit,
          left = FALSE) %>%
  group_by(HEX_ID) %>%
  summarise(TAPS = sum(TAPS))
kable(head(tap_out_hex))
```

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need the intermediate data used to derive `tap_out_hex` so we can remove them.

```{r}
#| eval: true
rm(train_exits)
rm(train_tap_out)
rm(train_tap_out_with_names)
rm(tap_out_exit)
rm(station_codes_names)
```
:::
