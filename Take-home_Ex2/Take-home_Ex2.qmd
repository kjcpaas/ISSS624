---
title: "Take Home Exercise 2: A Case Study of Singapore Public Bus Commuter Flows"
author: "Kristine Joy Paas"
date: "6 Dec 2023"
date-modified: "last-modified"
format:
  html:
    toc: true
    toc-depth: 5
execute: 
  echo: true
  eval: true
  warning: false
---

# Overview

The aim of this exercise to study the bus commuter flow patterns in Singapore to gain insights that support decision-making.

We will be examining the **weekend morning peak hours** (11 AM - 2 PM) to figure out where people go during weekends and holidays.

We will also be the modelling the spatial interaction between the different locations in Singapore, related to the bus commuter patterns.

Check <https://isss624-ay2023-24nov.netlify.app/take-home_ex02> for the full requirements of this exercise.

## The Analysis

The analysis has two parts: (1) analyzing the spatial interactions between pairs of zone, (2) modelling the interaction.

We will create a honeycomb grid with hexagons with a distance of **375m** from the center to the midpoint of the edge as the [traffic analysis zone (TAZ)](https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf). These hexagons will serve as the **zones** for our analysis.

::: panel-tabset
### Spatial Interaction Analysis

We will visualize the interactions by plotting the flow lines corresponding to the number of trips between each pair of zones.

We need the following to start this analysis:

-   geometry with the traffic analysis zones

-   data about the number of trips between different pairs of zones

### Spatial interaction Modelling

We will generate 4 *log*-based Poisson models:

-   origin constrained model

-   destination constrained model

-   unconstrained model

-   doubly constrained model

We need the following to start this analysis:

-   geometry with the traffic analysis zones

-   propulsiveness variables, which influence the number of of trips originating from a zone

-   attractiveness variables, which influence bus commuters to make a trip a zone

-   data about the number of trips between different pairs of zones

-   distance between each pair of zone

We use the different variables to generate formula for each model, which will be explored further in their respective sections.

Once the models are generated, we will also compare the models as to which one best fits our data, using **goodness of fit** test or $R^2$ test.
:::

To perform our modelling, we need to identify the propulsiveness and attractiveness variables we will use for our model.

As our data will be based on real-world data, *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API, we can think of possible factors based on our real-world experience.

As we are interested in the factors that influence **weekend/holiday morning (11 AM - 2PM)** peak period bus commuting patterns, we will consider the following variables.

::: panel-tabset
### Attractiveness {data-link="Attractiveness"}

Attractiveness variables are factors that can motivate people to go to their destinations. In our case, these are what *motivates people to ride to their destination bus stop*.

| Variable            | Data Source                                                                                                                                 | Motivation                                               |
|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| `BUS_STOP_COUNT`    | *Bus Stop Location* from [LTA DataMall](https://datamall.lta.gov.sg/content/dam/datamall/datasets/Geospatial/BusStopLocation.zip)           | Transferring to another bus to their end destination     |
| `TRAIN_EXITS_COUNT` | *Train Station* *Exit Point* from [LTA DataMall](https://datamall.lta.gov.sg/content/dam/datamall/datasets/Geospatial/TrainStationExit.zip) | Transferring to train to their end destination           |
| `HDB_COUNT`         | `hdb.csv` aspatial data provided on E-learn                                                                                                 | To meet up with friends/family                           |
| `ENTERTN_COUNT`     | `entertn.shp` geospatial data provided on E-learn                                                                                           | For recreation, spending time with friends/family        |
| `F_AND_B_COUNT`     | `F&B.shp` geospatial data provided on E-learn                                                                                               | For spending time with friends/family                    |
| `LEISURE_COUNT`     | `Liesure&Recreation.shp` geospatial data provided on E-learn                                                                                | For recreation, spending time with friends/family        |
| `RETAIL_COUNT`      | `Retails.shp` geospatial data provided on E-learn                                                                                           | For errands, shopping, spending time with friends/family |

### Propulsiveness

Propulsiveness variables are factors that influence people to ride the bus from specific zones. This is based on the **number** **of potential passengers** at the origin zones.

| Variable             | Data Source                                                                                                                          | Motivation                                                                                        |
|----------------------|--------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|
| `BUS_ALIGHT_COUNT`   | *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API | Passengers who alight from a bus stop within can transfer to another bus to reach                 |
| `TRAIN_ALIGHT_COUNT` | *Passenger Volume By Train Stations* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API               | Passengers who alight from a train station can transfer to a bus to reach their final destination |
| `HDB_RESIDENT_COUNT` | `hdb.csv` aspatial data provided on E-learn                                                                                          | Residents in an area are potential bus passengers as they leave their homes                       |
:::

## Data Outputs

To accomplish our analysis, we need to prepare the data with the following specifications.

For all our geospatial data, we will use the [**SVY21**](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) projection it is appropriate for the Singapore context. Also, having a consistent projection will make it straightforward to use the functions from `sfdep`.

::: panel-tabset
### Utility

::: {.callout-note collapse="true" appearance="minimal"}
#### Singapore Boundary geometry (*mpsz)*

Sourced from `MPSZ-2019` geospatial data from E-learn, this will provide the Singapore boundary geometry for visualization purposes.

We will be using `tmap_mode("plot")` instead of `tmap_mode("view")` to make the code run more efficiently with less memory requirements.

**Prerequisites:** None

**Output data:** `mpsz` (geospatial)
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Honeycomb grid corresponding to bus stop locations (*honeycomb)*

Sourced from the `shp` [*Bus Stop Locations*](https://datamall.lta.gov.sg/content/datamall/en/static-data.html#:~:text=drop%20off%20passengers.-,203%20kB,-Last%20Update%3A%C2%A0Jul) dataset from LTA DataMall. This consist of hexagons with a distance of **375m** from the center to the midpoint of the edge as the [traffic analysis zone (TAZ)](https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf).

We only consider the bus stops within Singapore so we have to ensure that the bus stops included here are within the \[Singapore Boundary geometry (mpsz)\].

**Prerequisites:** \[Singapore Boundary geometry (mpsz)\]

**Output data:** `honeycomb` (geospatial)

**Columns:**

-   `HEX_ID`: Unique ID used to associate the zone with other data frames
-   Geometry of the hexagons corresponding to the traffic analysis zone
:::

### Spatial Interaction Analysis

::: {.callout-note collapse="true" appearance="minimal"}
#### Number of trips between 2 zones (*od_hex*) {#number-of-trips-between-2-zones-hexagon}

This contains the number of trips on **weekend/holiday morning peak periods** (11 AM - 2 PM). Data is sourced from *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API

This data will be used generating the flow lines for visualization, and for Spatial Interaction Modelling.

**Prerequisites:** \[Honeycomb grid corresponding to bus stop locations (honeycomb)\]

**Output data:** `od_hex` (geospatial)

**Columns**:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `TRIPS`: Number of bus trips between the origin and destination zones
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Flow Lines (*flowlines*)

This contains the flow lines derived from the pairs of zones in \[Number of trips between 2 zones (od_hex)\]. It will be used to visualize the flow patterns.

**Prerequisites:** \[Number of trips between 2 zones (od_hex)\]

**Output data:** `flowlines`

**Columns**:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `TRIPS`: Number of bus trips between the origin and destination zones

-   Geometry of the line between the origin and destination zones
:::

### Spatial Interaction Modelling

::: {.callout-note collapse="true" appearance="minimal"}
#### Zone distance table (*dist_tbl*)

This table contains the distances between all the pair of zones. This corresponds to the **distance decay** component of our model

**Prerequisites:** \[Honeycomb grid corresponding to bus stop locations (honeycomb)\]

**Output data:** `dist_tbl` (aspatial)

**Columns**:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `DISTANCE`: Distance between the (centroids of) origin and destination zones
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Attractiveness Variables Table (*attractiveness*)

This table contains the values of the [Attractiveness] variables. Data sources are defined in the [Attractiveness] section.

**Prerequisites:** \[Honeycomb grid corresponding to bus stop locations (honeycomb)\], prepared data from identified data sources

**Output data:** `attractiveness` (geospatial)

**Columns**:

-   `HEX_ID`: ID corresponding to the zone
-   `BUS_STOP_COUNT`: Number of bus stops in a zone
-   `TRAIN_EXITS_COUNT`: Number of train station exits in a zone
-   `HDB_COUNT`: Number of HDB blocks in a zone
-   `ENTERTN_COUNT`: Number of entertainment locations in a zone
-   `F_AND_B_COUNT`: Number of F&B outlets in a zone
-   `LEISURE_COUNT`: Number of leisure and recreation in a zone
-   `RETAIL_COUNT`: Number of retail locations in a zone
-   Geometry of the hexagons corresponding to the traffic analysis zone
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Propulsiveness Variables Table (*propulsiveness*)

This table contains the values of the [Propulsiveness] variables. Data sources are defined in the [Propulsiveness] section.

**Prerequisites:** \[Honeycomb grid corresponding to bus stop locations (honeycomb)\], prepared data from identified data sources

**Output data:** `propulsiveness` (geospatial)

**Columns**:

-   `HEX_ID`: ID corresponding to the zone

-   `BUS_ALIGHT_COUNT`: Number of bus passengers alighting from a zone

-   `TRAIN_ALIGHT_COUNT`: Number of train passengers alighting from a zone

-   `HDB_RESIDENT_COUNT`: Number of residents in a zone

-   Geometry of the hexagons corresponding to the traffic analysis zone
:::

::: {.callout-note collapse="true" appearance="minimal"}
#### Model Data (*SIM_data*)

Contains all the data we need to model the interaction.

**Prerequisites:**

-   \[Zone distance table (dist_tbl)\]

-   \[Number of trips between 2 zones (od_hex)\]

-   \[Attractiveness Variables Table (attractiveness)\]

-   \[Propulsiveness Variables Table (propulsiveness)\]

-   \[Flow Lines (flowlines)\]

**Output data:** `SIM_data` (aspatial)

**Columns**:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `DISTANCE`: Distance between the (centroids of) origin and destination zones

-   `TRIPS`: Number of bus trips between the origin and destination zones

-   `DEST_*_COUNT`: Values from \[Attractiveness Variables Table (attractiveness)\]

-   `ORIG_*_COUNT`: Values from \[Propulsiveness Variables Table (propulsiveness)\]

-   Geomtery corresponding to the flowlines
:::
:::

## Managing our data

As this process is expected to have a lot of intermediate steps, **Save**, **Load**, and **Data clear** points are available to make our data wrangling more efficient.

::: callout-tip
### Save point

This is where data is written as `rds` files using `write_rds()` for important data sets that will be used in later analysis. Examples are:

-   Data we need to prepare for analysis
-   Critical outputs of expensive calculations
-   Cleaned up data for lightweight processing
:::

::: callout-note
### Load point

This is where data is loaded from `rds` files using `read_rds()`. They were previously generated by the save point.

**TIP**: Skip to the load points to progress without running the code above it
:::

::: callout-warning
### Data clear point

This is where data that will not be used anymore are cleared. The data in RStudio environment will pile up and will make it more difficult to check the relevant data in each part.

We can set `#| eval: false` in code chunks if we want skip the clearing. For example, the code below won't be run.

```{r}
#| eval: false
message <- "This code chunk executed"
```
:::

# Setup

::: panel-tabset
## Datasets

Using the data sources identified in [Data Outputs], we will download the datasets and add them into our `data/` directory.

We will also prepare the `data/rds/` directory to save the data we from our [Load point]. After the setup we are left with the directory structure below.

::: {.callout-note collapse="true" appearance="simple"}
## Directory structure

``` bash
Take-home_Ex2/data
├── aspatial
│   ├── hdb.csv
│   ├── origin_destination_bus_202310.csv
│   └── origin_destination_train_202310.csv
├── geospatial
│   ├── BusStop.cpg
│   ├── BusStop.dbf
│   ├── BusStop.lyr
│   ├── BusStop.prj
│   ├── BusStop.sbn
│   ├── BusStop.sbx
│   ├── BusStop.shp
│   ├── BusStop.shp.xml
│   ├── BusStop.shx
│   ├── F&B.cpg
│   ├── F&B.dbf
│   ├── F&B.prj
│   ├── F&B.qix
│   ├── F&B.qmd
│   ├── F&B.shp
│   ├── F&B.shx
│   ├── Liesure&Recreation.cpg
│   ├── Liesure&Recreation.dbf
│   ├── Liesure&Recreation.prj
│   ├── Liesure&Recreation.qmd
│   ├── Liesure&Recreation.shp
│   ├── Liesure&Recreation.shx
│   ├── MPSZ-2019.cpg
│   ├── MPSZ-2019.dbf
│   ├── MPSZ-2019.prj
│   ├── MPSZ-2019.qmd
│   ├── MPSZ-2019.shp
│   ├── MPSZ-2019.shx
│   ├── RapidTransitSystemStation.cpg
│   ├── RapidTransitSystemStation.dbf
│   ├── RapidTransitSystemStation.lyr
│   ├── RapidTransitSystemStation.prj
│   ├── RapidTransitSystemStation.sbn
│   ├── RapidTransitSystemStation.sbx
│   ├── RapidTransitSystemStation.shp
│   ├── RapidTransitSystemStation.shp.xml
│   ├── RapidTransitSystemStation.shx
│   ├── Retails.cpg
│   ├── Retails.dbf
│   ├── Retails.prj
│   ├── Retails.qix
│   ├── Retails.qmd
│   ├── Retails.shp
│   ├── Retails.shx
│   ├── entertn.cpg
│   ├── entertn.dbf
│   ├── entertn.prj
│   ├── entertn.qix
│   ├── entertn.qmd
│   ├── entertn.shp
│   └── entertn.shx
└── rds
```
:::

## R Packages

We will use the following R packages to run the code needed for data analysis.

-   [**tmap**](https://cran.r-project.org/web/packages/tmap/index.html): for thematic mapping

-   [**sf**](https://cran.r-project.org/web/packages/sf/index.html): for geospatial data handling

-   [**tidyverse**](https://cran.r-project.org/web/packages/tidyverse/index.html): for non-spatial data handling

-   [**knitr**](https://cran.r-project.org/web/packages/knitr/): for prettifying presentation

-   [**stplanr**](https://cran.r-project.org/web/packages/stplanr/index.html): for generating flow lines

-   [**reshape2**](https://cran.r-project.org/web/packages/reshape2/index.html): for generating pivot tables from matrix

-   [**performance**](https://cran.r-project.org/web/packages/performance/index.html): for model comparisons

## Environment Settings

These are the default setting we will use, and initial setup required for the environment.

-   `tmap_mode` to **plot**: for plotting simple maps

-   `tmap_style` to **natural**: for my preferred mapping style

-   set **seed** for reproducibility of results
:::

Using the setup tasks identified above, we will now run the setup code.

::: {.callout-note appearance="simple"}
We will label this code chunk with `label: setup` so it will always be run even if we reset our environment and start in the middle of the page
:::

```{r}
#| label: setup
pacman::p_load(sf, sp, tmap, tidyverse, knitr, stplanr, reshape2, performance)
#pacman::p_load(sf, sp, tmap, tidyverse, knitr, sfdep, stplanr, reshape2)
tmap_mode("plot")
tmap_style("natural")
set.seed(1234)
```

# Data Wrangling

Using the [Data Outputs] previously identified, we generate the dependency map below.

![](images/data_dependency_map.png)

We will use this as a guide to do our complex data wrangling tasks.

## Utility

We will first start by preparing the data needed for utility, \[Singapore Boundary geometry (mpsz)\] and \[Honeycomb grid corresponding to bus stop locations (honeycomb)\].

### Importing the datasets

We will import the datasets needed to prepare the utility data.

::: panel-tabset
#### Singapore boundary map

We will import the **Master Plan 2019 Subzone Boundary (Web)** data set that has been used in class. We will only keep the `SUBZONE_N` column and the geometry as we will only use this as the **base for our visualizations**.

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                layer = "MPSZ-2019") %>%
  select(SUBZONE_N)
```

::: {.callout-caution collapse="true" appearance="simple"}
##### Correcting the projection

This data frame using the global GPS standard, [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We need to convert this to [**SVY21**](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) projection that we will use for all our data in our analysis.

```{r}
mpsz <- mpsz %>% st_transform(crs=3414)
```
:::

::: {.callout-important collapse="true" appearance="simple"}
##### Visual inspection

We will do a quick visual inspection to check if the map has been imported as expected.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```
:::

#### BusStop (shp)

Next, we need to import the bus stop data as we will generate the honeycomb grid based on locations with bus stops.

```{r}
busstops <- st_read(dsn = "data/geospatial",
                    layer = "BusStop")
```

::: {.callout-caution collapse="true" appearance="simple"}
##### Correcting the projection

We want to use [SVY21](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) as the projection for this study as it is the projection used for local Singaporean context.

After the import, it shows that the **Projected CRS**is **SVY21**. However, checking the CRS with `st_crs()` tells a different story.

```{r}
st_crs(busstops)
```

As we can see EPSG value is **9001**, which correspond to [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We have to fix the projection by transforming to EPSG value of **3414**, which corresponds to **SVY21**.

```{r}
busstops <- st_transform(busstops, crs = 3414)
```
:::

::: {.callout-important collapse="true" appearance="simple"}
##### Visual inspection

We will do a quick visual inspection to check if the map has been imported as expected.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tmap_style("natural")
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of bus stops in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.005, title = "Bus Stops") +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```

The map shows that there are bus stops in our data set that are outside Singapore bounds (green area). We need to remove them as we are only interested in bus stops within Singapore.

::: {.callout-important appearance="simple" collapse="true"}
##### Removing the bus stops outside Singapore

We can remove the points outside Singapore from our `busstops` data by using `st_intersection()`.

We will use this as `busstops` contains points, the intersection of the 2 geometries will generate points corresponding to the bus stops within Singapore.

We will also just retain the `BUS_STOP_N` to remove the columns we do not need.

```{r}
busstops <- busstops %>% st_intersection(mpsz) %>% select(BUS_STOP_N, )
```

Visualizing again, all the bus stops are now within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tmap_style("natural")
tm_shape(mpsz) +
  tm_polygons("lightgreen", title = "Singapore Boundary") +
  tm_layout(main.title = "Map of bus stops in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.005, title = "Bus Stops") +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```
:::
:::
:::

::: {.callout-tip collapse="true"}
##### Save point

Let's save `mpsz` geometry as this is one of our Utility data outputs, \[Singapore Boundary geometry (mpsz)\].

We will also save `busstops` for later use.

```{r}
write_rds(mpsz, "data/rds/mpsz.rds")
write_rds(busstops, "data/rds/busstops.rds")
```
:::

### Generating the honeycomb grid

Finally, we can generate the honeycomb grid using `st_make_grid()`, providing *cellsize* of **750m**.

::: {.callout-tip collapse="true" appearance="simple"}
#### Calculating cellsize

[Apothem](https://www.merriam-webster.com/dictionary/apothem) is defined as *the perpendicular from the center of a regular polygon to one of the sides**.***

The specification is this study requires hexagons to be **375 m** from the center of the hexagon to the center of one of it's edge.

![](images/apothem.png){fig-align="center"}

As such, this corresponds to the length of 2 opposite apothems, which is **750 m**.

The edge length is **not** the same as apothem. It is **433.013 m**m.

$$
375m/cos(30) = 433.013m
$$
:::

```{r}
honeycomb <- busstops %>% st_make_grid(cellsize = 750,
                                       what="polygons",
                                       square = FALSE) %>%
  st_sf() %>%
  filter(lengths(st_intersects(geometry, busstops)) > 0)
```

::: {.callout-tip collapse="true" appearance="simple"}
#### Code Explanation

st_make_grid()

:   Creates a grid that covers the entire bus stop geometry, including areas without bus stop.

st_sf()

:   Converts to simple feature data set

st_intersects()

:   Checks if the hexagons have bus stops

filter()

:   Removes hexagons without bus stops
:::

Let's plot the map to visually inspect if the hexagons cover all the bus stop locations.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Honeycomb grid corresponding to Singapore bus stops",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(busstops) +
  tm_dots(col = "red", size = 0.001, title = "Bus Stops") +
  tm_grid(alpha = 0.2)
```

### Assigning id to each hexagon

Now that we have hexagons properly generated, we will assign id for each hexagon to be used as a unique identifier. We will store this id under the `HEX_ID` column, and can be used in joining data frames.

```{r}
honeycomb$HEX_ID <- sprintf("H%04d", seq_len(nrow(honeycomb)))
kable(head(honeycomb))
```

::: {.callout-tip collapse="true"}
### Save point

Let's save `honeycomb` as it contains the main geometry we will use in analysis.

```{r}
write_rds(honeycomb, "data/rds/honeycomb.rds")
```
:::

## Spatial Interaction Analysis

::: {.callout-note collapse="true"}
### Load point

We can start from this point by loading the relevant datasets.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
honeycomb <- read_rds("data/rds/honeycomb.rds")
busstops <- read_rds("data/rds/busstops.rds")
```
:::

### Importing the datasets

We will import the datasets needed to prepare the data outputs, \[Number of trips between 2 zones (od_hex)\] and \[Flow Lines (flowlines)\].

Aside from the output of [Utility], we also need to import the *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API for the month of **October 2023**.

The data set is an aspatial data in `csv` format so we will use `read_csv()` to import the data.

::: {.callout-note appearance="simple"}
We will use the October 2023 passenger data in this document. If you want to use dataset for another month, replace `202310` to the corresponding `YYYYMM` format.
:::

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
kable(head(odbus))
```

### Generating the O-D trip data by hexagon level

#### Filtering the relevant data

We only need the data for the **weekend morning peak period**, which is from 11 AM - 2 PM on weekends and holidays. As such, we will filter the data for the relevant hours.

We will also rename the `ORIGIN_PT_CODE` and `DESTINATION_PT_CODE` to be consistent with the naming with `busstops` as these columns can be associated to `busstops`'s `BUS_STOP_N`

::: {.callout-tip collapse="true" appearance="simple"}
##### How to filter data by *TIME_PER_HOUR*

The `TIME_PER_HOUR` in data set covers the data from the start to the end of the hour in **24-hour format**, i.e. when `TIME_PER_HOUR = 13`, this means bus taps from `1:00 PM` ton`1:59:59PM`.

Hence, if we want to get 11AM to 2PM data, we will filter by:

```         
TIME_PER_HOUR >= 11 & TIME_PER_HOUR < 14
```
:::

```{r}
od_trips <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter( TIME_PER_HOUR >= 11 &
            TIME_PER_HOUR < 14
          ) %>%
  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  rename(
    ORIG_BUS_STOP_N = ORIGIN_PT_CODE,
    DEST_BUS_STOP_N = DESTINATION_PT_CODE
  )
kable(head(od_trips))
```

::: {.callout-warning collapse="true"}
##### Data clear point

We do not need `odbus` anymore as we already extracted the data relevant to our analysis.

```{r}
#| eval: true
rm(odbus)
```
:::

#### Generating lookup table for bus stop to associated hexagon

To connect the trip data to the their corresponding hexagon, we need to create a lookup table. This will serve as a glue in associating the aspatial `od_trips` data frame to the `honeycomb` data frame.

This can be done via `st_intersection()`.

```{r}
bs_hex <- st_intersection(busstops, honeycomb) %>%
  st_drop_geometry() %>%
  select(c(BUS_STOP_N, HEX_ID))
kable(head(bs_hex))
```

#### Joining *od_trips* and *bs_hex*

Next, we need to associate each origin bus stop and destination bus stop to their corresponding hexagons.

We can use that by doing `inner_join()` twice, once for the origin and another for the destination.

::: {.callout-tip collapse="true"}
##### Why *inner_join()* instead of *left_join()*?

We will use `inner_join` as there are `BUS_STOP_N` values in `od_trips` data that are not in `bs_hex`.

```{r}
c(
  od_trips$ORIG_BUS_STOP_N[!(od_trips$ORIG_BUS_STOP_N %in% bs_hex$BUS_STOP_N)],
  od_trips$DEST_BUS_STOP_N[!(od_trips$DEST_BUS_STOP_N %in% bs_hex$BUS_STOP_N)]
) %>% unique() %>% length()
```

There are **59** bus stops in `od_trips` that are not in `bs_hex`. **5** of these can be attributed the bus stops we removed due to them being out in Singapore. Others may be due to the *BusStops* data set not having complete information.

The proper way to handle this is to validate the existence of each of these bus stops and look at public sources (e.g. Google Maps, LTA data) and add coordinate data. However, as we do not have much to do this task, we have to **remove** these bus stops from our analysis as **we do not have geospatial data** to associate to the hexagons from the data sets available to us.

Therefore, we will use `inner_join` to keep only the observations in `trips` with the matching bus stops in `bs_hex`.
:::

```{r}
od_trips_w_hex <- od_trips %>%
  inner_join(bs_hex,
             by = c("ORIG_BUS_STOP_N" = "BUS_STOP_N")) %>%
  rename(ORIG_HEX_ID = HEX_ID) %>%
  inner_join(bs_hex,
             by = c("DEST_BUS_STOP_N" = "BUS_STOP_N")) %>%
  rename(DEST_HEX_ID = HEX_ID)

kable(head(od_trips_w_hex))
```

#### Aggregating data by hexagon

Next, we will perform aggregations by `ORIG_HEX_ID` and `DEST_HEX_ID` to have an aggregated sum of trips by hexagon instead of bus stops.

```{r}
od_hex <- od_trips_w_hex %>%
  group_by(ORIG_HEX_ID, DEST_HEX_ID) %>%
  summarise(TRIPS = sum(TRIPS))
kable(head(od_hex))
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `od_hex` as it contains the `TRIP` data needed to visualize flow data and do spatial interaction modelling. Take note that this **includes intra-zonal trips**.

We will also write save `od_trips` as we need this later for calculating propulsiveness variables.

```{r}
write_rds(bs_hex, "data/rds/bs_hex.rds")
write_rds(od_hex, "data/rds/od_hex202310.rds")
write_rds(od_trips, "data/rds/od_trips202310.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need `bs_hex`, `od_trips_w_hex` anymore as we already have the necessary data for doing hexagon-based analysis in `od_hex`.

We will also remove `od_trips` for now as we do not need them until the later sections.

```{r}
#| eval: true
rm(bs_hex)
rm(od_trips)
rm(od_trips_w_hex)
```
:::

### Generating the flow lines

First, we will generate the flow lines using `od2line()`. `honeycomb` will be supplied as the `zone` as it contains the hexagons we are using as the **traffic analysis zones**.

```{r}
flowlines <- od_hex %>% od2line(
  honeycomb,
  zone_code = "HEX_ID")
```

#### Initial inspection of the flow lines

Next, we will do an initial inspection of the flow lines to check if they have been generated correctly.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  
  tm_shape(flowlines) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7),
           title.lwd = "# of bus trips",
           alpha = 0.8) +
  
  tm_layout(main.title = "Bus Passenger flow for Weekends/Holidays 11 AM - 2PM (October 2023)",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2)
```

::: {.callout-tip appearance="simple"}
#### Insights

The flow lines are sparse at the West side of Singapore, the **Jurong** and **Choa Chu Kang** areas. This is consistent with the observations that we have in the [Take-home Exercise 1](Take-home_Ex1/Take-home_Ex1) that these areas are least busy in terms of bus rides.

We can also notice that the thickest flow lines is between **Woodlands Checkpoint** and **Kranji Station**. There are not residential areas so our hypothesis that connecting transport points influence the bus passenger flow.

Lastly, points where many lines intersect must be transportation hubs as many trips originate or end in those zones.
:::

::: {.callout-tip collapse="true"}
#### Save point

Let's save `flowlines` as it contains the data for spatial interaction that we will use later on.

```{r}
write_rds(flowlines, "data/rds/flowlines202310.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need `flowlines` and `od_hex` until later sections so we can remove them from the environment for now.

```{r}
#| eval: true
rm(flowlines)
rm(od_hex)
```
:::

## Spatial Interaction Modelling

::: {.callout-note collapse="true"}
### Load point

We can start from this point by loading the relevant datasets.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
honeycomb <- read_rds("data/rds/honeycomb.rds")
busstops <- read_rds("data/rds/busstops.rds")
```
:::

Next, we will prepare the data needed for spatial interaction modelling. Some of these are straightforward to get, especially those of attractiveness variables. Additional steps are needed for more complex data sets, like those needed for propulsiveness variables. We will derive those in a separate section.

### Attractiveness variables

We will first initiate `attractiveness` from `honeycomb`.

```{r}
attractiveness <- honeycomb
```

For all the variables, we only need to count the number of each location types for each hexagon. We will use a combination of `lengths()` and `st_intersects()` to derive this value.

::: panel-tabset
#### Bus Stops

```{r}
attractiveness$BUS_STOP_COUNT <- lengths(
  st_intersects(attractiveness, busstops))
```

#### Entertainment

```{r}
entertn <- st_read(dsn = "data/geospatial", layer = "entertn")
```

::: {.callout-important collapse="true" appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Entertainment Spots in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(entertn) +
  tm_dots(col = "red", size = 0.005, title = "Entertainment Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$ENTERTN_COUNT <- lengths(st_intersects(attractiveness, entertn))
```

#### F&B

```{r}
f_and_b <- st_read(dsn = "data/geospatial", layer = "F&B")
```

::: {.callout-important collapse="true" appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of F&B Establishments in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(f_and_b) +
  tm_dots(col = "red", size = 0.005, title = "F&B Establishments Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$F_AND_B_COUNT <- lengths(st_intersects(attractiveness, f_and_b))
```

#### Leisure & Recreation

```{r}
leis_rec <- st_read(dsn = "data/geospatial", layer = "Liesure&Recreation")
```

::: {.callout-important appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Leisure & Recreation Spots in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(leis_rec) +
  tm_dots(col = "red", size = 0.005, title = "Leisure & Recreation Spots") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$LEISURE_COUNT <- lengths(st_intersects(attractiveness, leis_rec))
```

#### Retail

```{r}
retail <- st_read(dsn = "data/geospatial", layer = "Retails")
```

::: {.callout-important collapse="true" appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Retail Outlets in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(retail) +
  tm_dots(col = "red", size = 0.005, title = "Retail Outlets") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$RETAIL_COUNT <- lengths(st_intersects(attractiveness, retail))
```

#### Train Station Exits

```{r}
train_exits <- st_read(dsn = "data/geospatial", layer = "Train_Station_Exit_Layer")
```

::: {.callout-caution collapse="true" appearance="simple"}
##### Correcting the projection

We want to use [SVY21](https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem) as the projection for this study as it is the projection used for local Singaporean context.

After the import, it shows that the **Projected CRS** is **SVY21**. However, checking the CRS with `st_crs()` tells a different story.

```{r}
st_crs(train_exits)
```

As we can see EPSG value is **9001**, which correspond to [**WGS84**](https://gisgeography.com/wgs84-world-geodetic-system/). We have to fix the projection by transforming to EPSG value of **3414**, which corresponds to **SVY21**.

```{r}
train_exits <- st_transform(train_exits, crs = 3414)
```
:::

::: {.callout-important appearance="simple"}
##### Visual Inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of Train Station Exits in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(train_exits) +
  tm_dots(col = "red", size = 0.005, title = "Train Station Exits") +
  tm_grid(alpha = 0.2)
```
:::

```{r}
attractiveness$TRAIN_EXITS_COUNT <- lengths(st_intersects(attractiveness, train_exits))
```
:::

Let's check if the attractiveness variables have been added correctly.

```{r}
kable(head(attractiveness))
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `attractiveness` even though it is still missing `HDB_COUNT` as additional processing is needed to derive that. We will also save `train_exits` as it contains data needed for deriving propulsiveness variables.

```{r}
write_rds(attractiveness, "data/rds/attractiveness_no_hdb.rds")
write_rds(train_exits, "data/rds/train_exits.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need the data used to read the `shp` contents anymore as we have already derived the attractiveness variables from them.

```{r}
#| eval: true
rm(busstops)
rm(entertn)
rm(f_and_b)
rm(leis_rec)
rm(retail)

```
:::

### Deriving Passengers Alighting from Bus Stop

::: {.callout-note collapse="true"}
#### Load point

We can run from this point by loading these data.

```{r}
bs_hex <- read_rds("data/rds/bs_hex.rds")
od_trips <- read_rds("data/rds/od_trips202310.rds")
```

-   `bs_hex`: for connecting `od_trips` with honeycomb grid.
-   `od_trips`: to get trips to destination bus stops

We are not using `od_hex` as some destination trips were lost from \[Joining od_trips and bs_hex\] if the origin bus stop has no known geometry.
:::

Using the similar techniques used in [Take-home Exercise 1](Take-home_Ex1/Take-home_Ex1.html#extracting-hourly-of-bus-trips-originating-from-hexagons), we will aggregate the trips using `inner_join()`, `group_by`, and `summarise`.

```{r}
dest_bus_hex <- od_trips %>%
  inner_join(bs_hex,
             by = join_by(DEST_BUS_STOP_N == BUS_STOP_N)) %>%
  group_by(HEX_ID) %>%
  summarise(TRIPS = sum(TRIPS))
kable(head(dest_bus_hex))
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `dest_bus_hex` as it contains the data for propulsiveness variable.

```{r}
write_rds(dest_bus_hex, "data/rds/dest_bus_hex202310.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need `bs_hex` and `od_trips` anymore so we can remove them from our environment.

```{r}
#| eval: true
rm(bs_hex)
rm(od_trips)
```
:::

### Deriving Train Passenger Data

::: {.callout-note collapse="true"}
#### Load point

We can run from this point by loading these data.

```{r}
honeycomb <- read_rds("data/rds/honeycomb.rds")
train_exits <- read_rds("data/rds/train_exits.rds")
```
:::

One of our propulsiveness variables is the **number of passengers alighting from a train stations** as they are potential bus passengers, especially if they need to transfer to a bus to reach their final destination.

For this, we will import the *Passenger Volume By Origin Destination Train Stations* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API, which contains the number of tap outs from a station every hour. It has a similar structure to *Passenger Volume By Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API, which we have been using in class so I will not dive deep in to the details on how to get passenger data from them as we are using the same techniques as the bus data.

#### Importing data sets

::: panel-tabset
##### Passenger Data

We will import the `csv` from *Passenger Volume By Train Stations* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) via API, using `read_csv()`.

```{r}
od_train <- read_csv("data/aspatial/origin_destination_train_202310.csv")
kable(head(od_train))
```

We only need data for **weekend/holidays 11AM - 2PM,** and the columns `DESTINATION_PT_CODE` and `TOTAL_TRIPS` as we are only interested in passengers leaving the train station.

We will extract this the same way we did in [Filtering the relevant data].

```{r}
od_train_trips <- od_train %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter( TIME_PER_HOUR >= 11 &
            TIME_PER_HOUR < 14
          ) %>%
  group_by(DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  rename(TRAIN_ST_CODE = DESTINATION_PT_CODE)
kable(head(od_train_trips))
```

::: {.callout-warning collapse="true"}
###### Data clear point

We do not need `od_train` anymore as we already extracted the tap out data we need.

```{r}
#| eval: true
rm(od_train)
```
:::

##### Station Code and Names

The passenger data only has the **train station code**, but not the name. However, `train_exits` only have the **station names**, not the station code.

::: {.callout-note collapse="true" appearance="simple"}
###### Recap of *train exits*

```{r}
kable(head(train_exits))
```
:::

Hence, we need way to connect the 2 datasets so we will use *Train Station Codes and Chinese Names* from [LTA DataMall](https://datamall.lta.gov.sg/content/dam/datamall/datasets/PublicTransportRelated/Train%20Station%20Codes%20and%20Chinese%20Names.zip).

```{r}
station_codes_names <- read_csv("data/aspatial/Train_Station_Codes_and_Chinese_Names.csv")
kable(head(station_codes_names))
```

We only need the station code and English names so we can remove the columns that are not needed.

```{r}
station_codes_names <- station_codes_names %>%
  select(stn_code, mrt_station_english)
```
:::

#### Adjusting data columns

To connect `train_exits`, `station_code_names`, and `train_tap_out`, we need to make adjustments to the columns.

::: panel-tabset
##### *station_code_names*

```{r}
kable(head(station_codes_names))
```

We need to capitalize the station names as the names are capitalized in `train_exits`. We can use `toupper()` to accomplish this.

```{r}
station_codes_names <- station_codes_names %>%
  mutate(stn_name = toupper(mrt_station_english))
kable(head(station_codes_names))
```

##### *od_train_trips*

```{r}
kable(head(od_train_trips[6:10,]))
```

There are multiple station codes in `TRAIN_ST_CODE` column, while in `station_codes_names`, the `stn_code` column only has 1 station code.

We have to separate these station codes into their own rows by using `separate_rows()`.

```{r}
od_train_trips <- od_train_trips %>%
  separate_rows(TRAIN_ST_CODE, sep="/")
kable(head(od_train_trips[6:10,]))
```

::: {.callout-tip appearance="simple"}
`station_codes_names` and `od_train_trips` now have the number of rows so they can be mapped one-to-one.

```{r}
nrow(station_codes_names) == nrow(od_train_trips)
```
:::

##### *train_exits*

```{r}
kable(head(train_exits))
```

Station names in `train_exits` have `MRT STATION` or `LRT STATION` while `station_code_names` does not have.

We have to remove this part of the name so we can join the tables properly. We can use `sub()` to remove this part of the station name.

```{r}
train_exits <- train_exits %>%
  mutate(stn_name_short = gsub(" [ML]RT STATION$" , "", stn_name))
kable(head(train_exits))
```
:::

#### Adding tap out information to exits

::: panel-tabset
##### Joining *station_code_names* and *od_train_trips*

We will join by the station code. Also, as some train stations have multiple station codes, we will remove the duplicates on the station name. This can be accomplished by selecting `stn_name` and `TRIPS` and applying `unique()`. It is safe to not include the station code here anymore as `trains_exits` does not have the station code.

```{r}
od_train_trips_with_name <- station_codes_names %>%
  left_join(od_train_trips,
            by = join_by(stn_code == TRAIN_ST_CODE)) %>%
  select(stn_name, TRIPS) %>%
  unique()
kable(head(od_train_trips_with_name))
```

##### Adding tap out to exits

Next, we join `train_tap_out_with_names` with `train_exits` to finally add the tap information to exits.

```{r}
od_train_exits <- train_exits %>%
  left_join(od_train_trips_with_name,
            by = join_by(stn_name_short == stn_name)) %>%
  rename(STN_NAME = stn_name) %>%
  rename(EXIT_CODE = exit_code) %>%
  select(STN_NAME, EXIT_CODE, TRIPS)
```
:::

```{r}
kable(head(od_train_exits))
```

We now have the number of tap outs from station, that we can use as propulsive variable on the exits.

::: {.callout-note appearance="simple"}
We will **not distribute** these trips to the number of exits as we cannot be accurate on the volume of people taking specific exits. We can consider the people tapping out from a station **as potential passengers** of bus stop from the nearby exits.
:::

#### Aggregating TRIPS by Hexagon level

Finally, we can aggregate the trips on a hexagon level. We will do an `st_join()` of `honeycomb` and `tap_out_exit` as they are both of class `sf`.

```{r}
od_train_hex <- honeycomb %>%
  st_join(od_train_exits,
          left = FALSE) %>%
  group_by(HEX_ID) %>%
  summarise(TRIPS = sum(TRIPS))
kable(head(od_train_hex))
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `od_train_hex` as it contains the data for propulsiveness variable.

```{r}
write_rds(od_train_hex, "data/rds/od_train_hex202310.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need the intermediate data used to derive `od_train_hex` so we can remove them.

```{r}
#| eval: true
rm(train_exits)
rm(od_train_exits)
rm(od_train_trips)
rm(od_train_trips_with_name)
rm(station_codes_names)
```
:::

### Deriving HDB population

::: {.callout-note collapse="true"}
#### Load point

We can run from this point by loading these data.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
honeycomb <- read_rds("data/rds/honeycomb.rds")
attractiveness <- read_rds("data/rds/attractiveness_no_hdb.rds")
```
:::

Next, we will derive the population data for each zone. We will use aspatial dataset provided, `hdb.csv`.

We will initialize data to store `hdb_vars` from `honeycomb`.

```{r}
hdb_vars <- honeycomb
```

#### Importing the data

We will import the aspatial `hdb.csv`.

```{r}
hdb_csv <- read_csv("data/aspatial/hdb.csv")
kable(head(hdb_csv))
```

::: {.callout-tip appearance="minimal"}
Despite being an aspatial dataset, there are columns where we can derive geospatial data from, `lng` and `lat`.
:::

We will first convert this to a `sf` data type, which uses **WGS 84** and transform it to **SVY21**.

```{r}
hdb_sf <- hdb_csv %>% st_as_sf(coords = c("lng", "lat"),
                               crs = 4326) %>%
  st_transform(crs = 3414)
```

::: {.callout-important collapse="true" appearance="simple"}
#### Visual inspection

As we haven't used this dataset before, we will do a quick visual inspection to check if the points are within Singapore.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  tm_layout(main.title = "Map of HDB Blocks in Singapore",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_shape(hdb_sf) +
  tm_dots(col = "red", size = 0.001, title = "HDB Blocks") +
  tm_grid(alpha = 0.2)
```
:::

#### Adding *HDB_COUNT*

This variable will contain the number of **HDB blocks** in a zone. We will use the same methods to count the number locations in the zone, by using `lengths()` and `st_intersects()`.

We will use this as attractiveness variable, and will include all HDB block types (commercial, hawker, residential) as all of them are attractive destinations for eating out, meeting family/friends, and errands.

```{r}
hdb_vars$HDB_COUNT <- lengths(st_intersects(hdb_vars, hdb_sf))
```

We will also add this back to `attractiveness` now that we have finally derived the value. We have to remove the geometry for `hdb_vars` to enable the join.

```{r}
attractiveness <- left_join(attractiveness,
                            st_drop_geometry(hdb_vars))
kable(head(attractiveness))
```

#### Removing unnecessary data

To derive the population, we will only retain the rows and columns relevant to our calculations.

We will only retain the **residential**, the **total_dwelling_units** column, and lastly, the geometry.

```{r}
hdb_filtered_sf <- hdb_sf %>%
  filter(residential == "Y") %>%
  select(total_dwelling_units)
```

#### Adding *HDB_DWELLING_COUNT*

While `HDB_COUNT` can be a population proxy, we need to consider that HDB blocks have different sizes. For example, taller and wider blocks may have more units compared to shorter blocks, and therefore higher population.

As such, we will use `total_dwelling_units` multiplied by **3.09** to improve our population estimate.

::: {.callout-tip collapse="true" appearance="simple"}
##### Relevance of 3.09

According to the [2022 official statistics](https://www.singstat.gov.sg/find-data/search-by-theme/households/households/latest-data) from Department of Statistics, the average household size is **3.09 person**.

Although the HDBs have different unit sizes (1 to 5 bedroom), which can provide more accurate population estimate, we do not have data on how many people actually live in each so we will just use the average household size multiplied by dwellings.

We are not able to get a more accurate summary with the data available for us as there are also private residences (condos, landed properties) that are not contained in this dataset.
:::

We need to aggregate the sum of `total_dwelling_units` per hexagon, and doing a `left_join()` with `hdb_vars`.

```{r}
hdb_vars <- hdb_vars %>%
  left_join(
    st_intersection(hdb_filtered_sf, hdb_vars) %>%
      st_drop_geometry() %>%
      group_by(HEX_ID) %>%
      summarise(HDB_RESIDENT_COUNT = sum(total_dwelling_units))
  )
kable(hdb_vars[160:165,])
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `hdb_vars` as it contains the data for propulsiveness variable. We will also update `attractiveness` as we added `HDB_COUNT`.

```{r}
write_rds(hdb_vars, "data/rds/hdb_vars.rds")
write_rds(attractiveness, "data/rds/attractiveness.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We do not need the intermediate data used to derive `hdb_vars` anymore so we can remove them.

```{r}
#| eval: true
rm(hdb_csv)
rm(hdb_sf)
rm(hdb_filtered_sf)
```
:::

### Propulsiveness variables

::: {.callout-note collapse="true"}
#### Load point

We can run from this point by loading these data.

```{r}
honeycomb <- read_rds("data/rds/honeycomb.rds")
hdb_vars <- read_rds("data/rds/hdb_vars.rds")
dest_bus_hex <- read_rds("data/rds/dest_bus_hex202310.rds")
od_train_hex <- read_rds("data/rds/od_train_hex202310.rds")
```
:::

We will first initiate `propulsiveness` from `honeycomb`.

```{r}
propulsiveness <- honeycomb
```

We will then add the passenger/population values we just derived by using a combination of `st_drop_geometry` and `left_join().`

::: panel-tabset
#### HDB

```{r}
propulsiveness <- propulsiveness %>%
  left_join(st_drop_geometry(hdb_vars)) %>%
  select(HEX_ID, HDB_RESIDENT_COUNT)
```

#### Bus

```{r}
propulsiveness <- propulsiveness %>%
  left_join(st_drop_geometry(dest_bus_hex)) %>%
  rename(BUS_ALIGHT_COUNT = TRIPS)
```

#### Train

```{r}
propulsiveness <- propulsiveness %>%
  left_join(st_drop_geometry(od_train_hex)) %>%
  rename(TRAIN_ALIGHT_COUNT = TRIPS)
```
:::

At this point, there are some `NA` values. As these are independent variables, we will set a value for them instead of excluding rows due to empty values. We will set them to **0**.

```{r}
propulsiveness[is.na(propulsiveness)] <- 0
kable(head(propulsiveness))
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `propulsiveness` as it contains the data for propulsiveness variables.

```{r}
write_rds(propulsiveness, "data/rds/propulsiveness202310.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We can now remove the data that we use to derive `propulsiveness` from the environment.

```{r}
#| eval: true
rm(dest_bus_hex)
rm(hdb_vars)
rm(od_train_hex)
```
:::

### Generating distance table

::: {.callout-note collapse="true"}
#### Load point

We can run from this point by loading these data.

```{r}
honeycomb <- read_rds("data/rds/honeycomb.rds")
```
:::

Now that we have the attractive and propulsive forces, we can finally prepare the data for the **distance decay** component of the model.

#### Generating distance matrix

We will use `spDists()` to generate the matrix from our `honeycomb`, which requires a *Spatial* data frame. We also need to name the columns and rows to the corresponding `HEX_ID` of the hexagons.

```{r}
dist_mat <- spDists(as(honeycomb, "Spatial"),
                    longlat = FALSE)
colnames(dist_mat) <- paste0(honeycomb$HEX_ID)
rownames(dist_mat) <- paste0(honeycomb$HEX_ID)
kable(head(dist_mat, n=c(8, 8)))
```

::: {.callout-tip appearance="minimal"}
As expected, many of the distances are **multiples of 750** as we set our hexagon size to 750m edge-to-edge. This also means that the distance between centroids of adjacent hexagons is **750m**.
:::

#### Generating a pivot table

To generate data with the specifications we defined in [Data Outputs], we must generate a pivot table from our distance matrix, `dist_mat`.

We will use `melt()`, for this purpose and rename the columns to names we defined in our modelling data shape.

```{r}
dist_tbl <- melt(dist_mat) %>%
  rename(DISTANCE = value) %>%
  rename(ORIG_HEX_ID = Var1) %>%
  rename(DEST_HEX_ID = Var2)
kable(head(dist_tbl))
```

#### Setting intra-zonal distances

Intra-zonal distances are currently **0**. This can be a result of passengers taking a short bus ride to the next stop. We have to set these to a value other than 0.

::: {.callout-important collapse="true" appearance="simple"}
##### Why can't we just keep them as 0?

As we are going to use **log-based Poisson models**, *log* operations will be applied to all independent variables (including distance).

$log(0) = undefined$ so we have to set it to a value **greater than 0**, as distances are **positive** in this context.
:::

::: {.callout-tip collapse="true" appearance="simple"}
##### What do we use as intra-zonal distance? Answer: 200m

To consider the intra-zonal distance for this context, we need to consider why people board and alight within the same zone.

The most plausible explanation is people riding the bus to the immediate next stop. With this thought process, we can base the intra-zonal distance from some of the closest bus stops within the same route, **School of the Arts** (Stop ID: 08079) and **Peace Ctr** (Stop ID: 07011).

![](images/sota_to_peace_ctr.png){fig-align="center"}

Bus routes like [**147**](https://www.transitlink.com.sg/eservice/eguide/service_route.php?service=147)and [**166**](https://www.transitlink.com.sg/eservice/eguide/service_route.php?service=166) pass by these bus stops so it is possible for the above scenario to happen here. As these may not be closest bus stops within the same route, we will round the value down to **200m**.
:::

We will set the intra-zonal distances to **200m**.

```{r}
dist_tbl$DISTANCE[dist_tbl$ORIG_HEX_ID == dist_tbl$DEST_HEX_ID] <- 200
summary(dist_tbl$DISTANCE)
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `dist_tbl` as it contains the data for the distance decay component of the model.

```{r}
write_rds(dist_tbl, "data/rds/dist_tbl.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We can now remove the data that we use to derive `dist_tbl` from the environment.

```{r}
#| eval: true
rm(dist_mat)
```
:::

### Putting everything together

::: {.callout-note collapse="true"}
#### Load point

We will load saved data containing the components of the model data.

```{r}
honeycomb <- read_rds("data/rds/honeycomb.rds")
flowlines <- read_rds("data/rds/flowlines202310.rds")
dist_tbl <- read_rds("data/rds/dist_tbl.rds")
attractiveness <- read_rds("data/rds/attractiveness.rds")
propulsiveness <- read_rds("data/rds/propulsiveness202310.rds")
```
:::

Now that we have all the components, we will now generate the geospatial `data` that contains the following columns:

-   `ORIG_HEX_ID`: ID corresponding to the origin zone

-   `DEST_HEX_ID`: ID corresponding to the destination zone

-   `DISTANCE`: Distance between the (centroids of) origin and destination zones

-   `TRIPS`: Number of bus trips between the origin and destination zones

-   `DEST_*_COUNT`: Values from \[Attractiveness Variables Table (attractiveness)\]

-   `ORIG_*_COUNT`: Values from \[Propulsiveness Variables Table (propulsiveness)\]

-   Geometry containing the flowlines

We will join the tables to generate this data.

::: panel-tabset
#### Flowlines

```{r}
kable(head(flowlines))
```

`flowline` contains both the geometry of the flow lines and the `TRIPS` data so we will use it as the base of `SIM_data`

```{r}
SIM_data <- flowlines
```

#### Distance

`dist_tbl` covers all the pairs of hexagons from `honeycomb`. We will do a `left_join()` with `SIM_data` so we are only left with the pairs that have flows between them

```{r}
SIM_data <- SIM_data %>% left_join(dist_tbl)
```

#### Propulsive

Propulsive forces come from the origin zone so we will join `propulsiveness` with `SIM_data` on `ORIG_HEX_ID`. We will also add the `ORIG_` prefix to the columns added in by `propulsiveness`.

```{r}
SIM_data <- left_join(
  SIM_data,
  propulsiveness %>%
    st_drop_geometry() %>%
    rename_with(~paste("ORIG_", .x, sep = ""))
  )
```

#### Attractive

Attractive forces come from the destination zone so we will join `attractiveness` with `SIM_data` on `DEST_HEX_ID`. We will also add the `DEST_` prefix to the columns added in by `attractiveness`.

```{r}
SIM_data <- left_join(
  SIM_data,
  attractiveness %>%
    st_drop_geometry() %>%
    rename_with(~paste("DEST_", .x, sep = ""))
  )
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We can now remove the data that we use to derive `SIM_data` from the environment.

```{r}
#| eval: true
rm(attractiveness)
rm(propulsiveness)
rm(dist_tbl)
rm(flowlines)
```
:::

### Finishing touches

Let's take a look at our `SIM_data`.

```{r}
summary(SIM_data)
```

We will make finishing touches on `SIM_data`, so that they are compatible with modelling. We need to remove the 0's as we will apply *log* function to them, which will result to *undefined*. We will set them to **0.99** so we are aware that **.**

```{r}
replace_zeroes <- function(data, col_name) {
  data[[col_name]][data[[col_name]] == 0] <- 0.99
  data
}

SIM_data <- SIM_data %>%
  replace_zeroes("ORIG_HDB_RESIDENT_COUNT") %>%
  replace_zeroes("ORIG_BUS_ALIGHT_COUNT") %>%
  replace_zeroes("ORIG_TRAIN_ALIGHT_COUNT") %>%
  replace_zeroes("DEST_ENTERTN_COUNT") %>%
  replace_zeroes("DEST_F_AND_B_COUNT") %>%
  replace_zeroes("DEST_LEISURE_COUNT") %>%
  replace_zeroes("DEST_RETAIL_COUNT") %>%
  replace_zeroes("DEST_TRAIN_EXITS_COUNT") %>%
  replace_zeroes("DEST_HDB_COUNT")
```

Let's check the data again.

```{r}
summary(SIM_data)
```

::: {.callout-tip collapse="true"}
#### Save point

Let's save `SIM_data` as it contains the data we need for our models. Take note that this contains **intra-zonal pairs**.

```{r}
write_rds(SIM_data, "data/rds/SIM_data202310.rds")
```
:::

::: {.callout-warning collapse="true"}
#### Data clear point

We won't need the `SIM_data` for a while so we can remove it from the environment. We will also remove the helper function `replace_zeroes()` as we don't need it anymore.

```{r}
#| eval: true
rm(SIM_data)
rm(replace_zeroes)
```
:::

# Visualizing Spatial Interactions

::: {.callout-note collapse="true"}
## Load point

We can start from this point by loading the relevant datasets.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
honeycomb <- read_rds("data/rds/honeycomb.rds")
flowlines <- read_rds("data/rds/flowlines202310.rds")
SIM_data <- read_rds("data/rds/SIM_data202310.rds")
propulsiveness <- read_rds("data/rds/propulsiveness202310.rds")
attractiveness <- read_rds("data/rds/attractiveness.rds")
```
:::

## Visualizing flow lines again

We already did initial visualization of the flow lines in [Initial inspection of the flow lines]. However, there plot is very messy because of the number of lines.

We will remove intra-zonal flows to reduce the number of flow lines.

```{r}
flowlines_no_intra <- flowlines %>%
  filter(ORIG_HEX_ID != DEST_HEX_ID)
```

We need to look at the busiest zone pairs more closely so we will filter those with lower traffic.

We will use `quantile()` to find and appropriate cut-off number.

```{r}
quantile(flowlines_no_intra$TRIPS,
         probs = c(0.8, 0.9, 0.95, 0.99, 1))
```

Trying these values, showing *5%* of the flow lines revealed important details.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary", alpha = 0.5) +
  
  tm_shape(honeycomb) +
  tm_polygons(col = "white", title = "Hexagons", alpha = 1) +
  
  tm_shape(flowlines_no_intra %>% filter(TRIPS > 376)) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7),
           title.lwd = "# of bus trips",
           alpha = 0.8) +
  
  tm_layout(main.title = "Top 5% Bus Passenger flow for Weekends/Holidays 11 AM - 2PM (October 2023)",
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_compass(type="8star", size = 2, bg.color = "white", bg.alpha = 0.5) +
  tm_scale_bar(bg.color = "white", bg.alpha = 0.5) +
  tm_grid(alpha = 0.2)
```

::: {.callout-tip appearance="simple"}
### Insights

It is notable that the thickest flow lines are for relatively short distances, like the bus rides to and from **Woodlands Checkpoint** to **Kranji Station**. We can notice these thick lines on busy zones where lines converge as well.

Although not as thick, we can notice longer long lines on the map. This can indicate people more willing to travel longer distances over the weekend for recreation and meeting family and friends. This also means that a location being close by is not the only motivator for people to visit a place. Spatial interaction model can reveal more patterns to this.
:::

## Plotting *TRIPS* vs. *DISTANCE*

From the previous map, we can see that longer distances do not deter people from coming to a place. To verify that there is no correlation, let us plot the distance vs. the number vs trips.

```{r}
#| code-fold: true
#| code-summary: "**Show the code**"
ggplot(SIM_data,
       aes(x = DISTANCE, y = TRIPS)) +
  geom_point() +
  geom_hline(yintercept = 376.25, color = "red", linetype = "dashed") +
  annotate("text", x = 20000,
           y = 600, label = "95th percentile",
           hjust = -0.1, color = "red", size = 3) +
  geom_hline(yintercept = 1510, color = "purple", linetype = "dashed") +
  annotate("text", x = 20000,
           y = 1800, label = "99th percentile",
           hjust = -0.1, color = "purple", size = 3) +
  labs(title = "Number of Trips as a Function of Distance",
       x = "Distance (m)",
       y = "Number of Trips")
```

Plotting it in a *log* scale shows a more linear relationship.

```{r}
ggplot(SIM_data,
       aes(x = log(DISTANCE), y = log(TRIPS))) +
  geom_point() +
  geom_smooth(method = lm)
```

::: {.callout-tip appearance="simple"}
### Insights

The *maximum number of trips* **exponentially decrease** as the distance increases, which means that generally, the farther the distance, the less trips there are.

However, some outliers can be observed like some zone pairs with almost 20km distance between them having close to 99th percentile of `TRIP` values. In these zone pairs, there could be strong propulsive or attractive forces attracting passengers to ride the bus between those zones.
:::

In **doubly constrained model**, we will observe this relationship more closely as we will build the model **without attractive and propulsive** forces.

## Visualizing propulsive forces

We will plot the propulsive forces in their own choropleth maps so we can see if the top 5% busiest flows correspond to areas we hypothesize to have high propulsive forces, of influence the number of trips started from the origin.

::: {.callout-note appearance="simple"}
We will use tabsets so that we can compare each map by switching tabs.
:::

::: {.callout-tip collapse="true" appearance="simple"}
### Helper function

We will use the following function to plot the maps in this section.

```{r}
plot_propulsive <- function(var_name, title_comp) {
  tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary") +
  
  # Adding this layer underneath propulsiveness as we removed 0s. from the map
  # so it won't skew the legend
  tm_shape(honeycomb) +
  tm_polygons(col = "white") +
  
  tm_shape(propulsiveness %>% filter(if_any(var_name, ~. >= 1))) +
  tm_polygons(var_name, palette = "Blues", style = "quantile") +
    
  tm_shape(flowlines_no_intra %>% filter(TRIPS > 376)) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7, 10),
           title.lwd = "# of bus trips",
           n = 6,
           alpha = 0.5) +
  
  tm_layout(main.title = paste("Top 5% Bus Passenger Flows and", title_comp),
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_scale_bar(bg.color = "white", bg.alpha = 0.7, position = c("right", "top")) +
  tm_compass(type="8star", size = 2, bg.color = "white",
             bg.alpha = 0.5, position = c("right", "top")) +
  tm_grid(alpha = 0.2) +
  tm_credits("*Passenger data from weekend/holidays 11AM - 2PM\n(October 2023)",
             bg.color = "white", bg.alpha = 0.7,
             position = c("left", "bottom"))
}
```
:::

::: panel-tabset
### HDB Residents

```{r}
plot_propulsive("HDB_RESIDENT_COUNT", "HDB Population")
```

### Transfers from Train

```{r}
plot_propulsive("TRAIN_ALIGHT_COUNT", "Potential Transfers from Train")
```

### Transfers from Bus

```{r}
plot_propulsive("BUS_ALIGHT_COUNT", "Potential Transfers from Bus")
```
:::

::: {.callout-tip appearance="simple"}
### Insights

Upon visual inspection, HDB population and bus alights from zones correspond more closely with our flowlines. Residential areas have a lot of potential passengers in those areas.

There are less train station exits than bus stops but it can be observed that flowlines also converge on some zones where train stations are.

Lastly, we get bus alight data from the same data source or flowlines so they are expected to correspond more closely. We should be aware that flow line includes the **destination** so the correspondence may due on the destination, not the origin as we hypothesized.
:::

In **destination constrained model**, the effects of propulsive forces will be highlighted as we will model the interaction **without the attractive forces**.

## Visualizing attractive forces

We will plot the attractive forces in their own choropleth maps so we can see if the top 5% busiest flows correspond to areas we hypothesize have high attractive forces, influencing passengers to make trip to those zonoe..

We will use tabsets so that we can compare each map by switching tabs.

::: {.callout-tip collapse="true" appearance="simple"}
### Helper function

We will use the following function to plot the maps in this section.

```{r}
plot_attractive <- function(var_name, title_comp) {
  tm_shape(mpsz) +
  tm_polygons("green", title = "Singapore Boundary") +
  
  # Adding this layer underneath attractiveness as we removed 0s. from the map
  # so it won't skew the legend
  tm_shape(honeycomb) +
  tm_polygons(col = "white") +
  
  tm_shape(attractiveness %>% filter(if_any(var_name, ~. >= 1))) +
  tm_polygons(var_name, palette = "Purples", style = "quantile") +
    
  tm_shape(flowlines_no_intra %>% filter(TRIPS > 376)) +
  tm_lines(lwd = "TRIPS",
           style = "quantile",
           col = "red",
           scale = c(0.1, 1, 3, 5, 7, 10),
           title.lwd = "# of bus trips",
           n = 6,
           alpha = 0.5) +
  
  tm_layout(main.title = paste("Top 5% Bus Passenger Flows and", title_comp),
            main.title.position = "center",
            main.title.size = 1.0,
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE) +
  
  tm_scale_bar(bg.color = "white", bg.alpha = 0.7, position = c("right", "top")) +
  tm_compass(type="8star", size = 2, bg.color = "white",
             bg.alpha = 0.5, position = c("right", "top")) +
  tm_grid(alpha = 0.2) +
  tm_credits("*Passenger data from weekend/holidays 11AM - 2PM\n(October 2023)",
             bg.color = "white", bg.alpha = 0.7,
             position = c("left", "bottom"))
}
```
:::

::: panel-tabset
### Bus Stops

```{r}
plot_attractive("BUS_STOP_COUNT", "Number of Bus Stops")
```

### Train Stations

```{r}
plot_attractive("TRAIN_EXITS_COUNT", "Number of Train Stations")
```

### HDBs

```{r}
plot_attractive("HDB_COUNT", "Number of HDB blocks")
```

### Entertainment

```{r}
plot_attractive("ENTERTN_COUNT", "Number of Entertainment Locations")
```

### F&B

```{r}
plot_attractive("F_AND_B_COUNT", "Number of F&B Outlets")
```

### Leisure & Recreaction

```{r}
plot_attractive("LEISURE_COUNT", "Number of Leisure & Recreation Locations")
```

### Retail

```{r}
plot_attractive("RETAIL_COUNT", "Number of Retail Outlets")
```
:::

::: {.callout-tip appearance="simple"}
### Insights

There are less location types than the others, like entertainment and leisure locations.

There are also location types that are heavily concentrated in some zones, like the entertainment and F&B, which are heavily concentrated around the **Orchard area**. Conversely, there are much less HDBs in Orchard area. Even though the flowlines are not thick in this area, there are many flowlines, although thin. This means people are coming from various parts of Singapore.
:::

In **origin constrained model**, the effects of attractive forces will be highlighted as we will model the interaction **without the propulsive forces**.

::: {.callout-tip collapse="true"}
## Save point

Let's save `flowlines_no_intra` as we will use it for modelling,

```{r}
write_rds(SIM_data, "data/rds/flowlines_no_intra202310.rds")
```
:::

::: {.callout-warning collapse="true"}
## Data clear point

We will clear the data we do not need for the Spatial Interaction Modelling.

```{r}
#| eval: true
rm(flowlines)
rm(attractiveness)
rm(propulsiveness)
rm(plot_attractive)
rm(plot_propulsive)
```
:::

# Spatial Interaction Modelling

::: {.callout-note collapse="true"}
## Load point

We can start from this point by loading the relevant datasets.

```{r}
SIM_data <- read_rds("data/rds/SIM_data202310.rds")
```
:::

For our spatial interaction modelling, we will use *log-*based Poisson gravity models. There are 4 components in our models:

-   **attractive forces**: forces that influence bus passengers to alight at a bus stops

-   **propulsive forces**: forces that influence bus passengers to board from specific bus stops

-   **distance decay**: this corresponds to the cost of making the trip. In theory, the longer the distance to travel, the less appealing a trip is.

-   **trips**: this is the dependent variable and what we want to model.

As we generate the models, we will compare the **actual value** of the trips (from the data we have processed so far) with the values that the models generate.

## About the models

::: panel-tabset
### Unconstrained

This will model the `TRIPS` using all the idependent model components --- attractive forces, propulsive forces, distance decay.

In this model, we will see if all the forces we identified influence the number of trips made between zone pairs.

The general formula is:

$$
\lambda_{ij} = exp(k + \mu lnV_i + \alpha lnW_j + \beta ln d_{ij})
$$

::: {.callout-note appearance="simple"}
$\lambda_{ij}$: Independent variable, corresponding to `TRIPS` in our context

$\mu lnV_i$: Propulsive forces (unconstrained)

$\alpha lnW_j$: Attractive forces (unconstrained)

$\beta ln d_{ij}$: Distance decay
:::

### Origin constrained

This will model the `TRIPS` **without the attractive forces**.

In this model, we will see the highlighted effects of the propulsive forces.

The general formula is:

$$
\lambda_{ij} = exp(k + \mu_i + \alpha lnW_j + \beta ln d_{ij})
$$

::: {.callout-note appearance="simple"}
$\lambda_{ij}$: Independent variable, corresponding to `TRIPS` in our context

$\mu_i$: Propulsive parameter (constrained)

$\alpha lnW_j$: Attractive forces (unconstrained)

$\beta ln d_{ij}$: Distance decay
:::

### Destination constrained

This will model the `TRIPS` **without the propulsive forces**.

In this model, we will see the highlighted effects of the attractive forces.

The general formula is:

$$
\lambda_{ij} = exp(k + \mu lnV_i + \alpha_j + \beta ln d_{ij})
$$

::: {.callout-note appearance="simple"}
$\lambda_{ij}$: Independent variable, corresponding to `TRIPS` in our context

$\mu lnV_i$: Propulsive forces (unconstrained)

$\alpha_j$: Attractive parameter (constrained)

$\beta ln d_{ij}$: Distance decay
:::

### Doubly constrained

This will model the `TRIPS` **without the attractive and propulsive forces**.

In this model, we will see the effects of the distance alone to the trips.

The general formula is:

$$
\lambda_{ij} = exp(k + \mu_i + \alpha_j + \beta ln d_{ij})
$$

::: {.callout-note appearance="simple"}
$\lambda_{ij}$: Independent variable, corresponding to `TRIPS` in our context

$\mu_i$: Propulsive parameter (constrained)

$\alpha_j$: Attractive parameter (constrained)

$\beta ln d_{ij}$: Distance decay
:::
:::

## Generating the models

Using the formula we defined above, we will generate the models based on `SIM_data`. We will use `glm()` which generate linear models, specifying `family = poisson` as we are using Poisson gravity models.

First, we need to **remove intra-zonal zones pairs** from `SIM_data` as it currently includes those.

```{r}
SIM_data_no_intra <- SIM_data %>% filter(ORIG_HEX_ID != DEST_HEX_ID)
```

::: {.callout-tip collapse="true" appearance="simple"}
### Helper function: goodness of fit

We will use the following function to calculate the **goodness of fit**, or **R-squared.** This will calculate how the observed data fits our model by comparing the observed values to the values generated by our models.

```{r}
calc_r_squared <- function(model) {
  cor(model$data$TRIPS, model$fitted.values)^2
}
```
:::

::: {.callout-important appearance="simple"}
It is quite expensive to generate these models so we will save them right after generation. `eval` is set to `false` by default on these code chunks.

We will trigger these code chunks manually if we want to regenerate the files.
:::

::: panel-tabset
### Unconstrained

```{r}
#| eval: false
uncSIM <- glm(formula = TRIPS ~ 
                log(ORIG_HDB_RESIDENT_COUNT) +
                log(ORIG_BUS_ALIGHT_COUNT) +
                #log(ORIG_TRAIN_ALIGHT_COUNT) +
                log(DEST_BUS_STOP_COUNT) +
                #log(DEST_ENTERTN_COUNT) +
                #log(DEST_F_AND_B_COUNT) +
                #log(DEST_LEISURE_COUNT) +
                log(DEST_RETAIL_COUNT) +
                log(DEST_TRAIN_EXITS_COUNT) +
                log(DEST_HDB_COUNT) +
                log(DISTANCE),
              family = poisson(link = "log"),
              data = SIM_data_no_intra,
              na.action = na.exclude)
write_rds(uncSIM, "data/rds/uncSIM202310.rds")
```

```{r}
uncSIM <- read_rds("data/rds/uncSIM202310.rds")
uncSIM
```

```{r}
calc_r_squared(uncSIM)
```

### Origin constrained

```{r}
#| eval: false
orcSIM <- glm(formula = TRIPS ~ 
                ORIG_HEX_ID +
                log(DEST_BUS_STOP_COUNT) +
                #log(DEST_ENTERTN_COUNT) +
                #log(DEST_F_AND_B_COUNT) +
                #log(DEST_LEISURE_COUNT) +
                log(DEST_RETAIL_COUNT) +
                log(DEST_TRAIN_EXITS_COUNT) +
                log(DEST_HDB_COUNT) +
                log(DISTANCE),
              family = poisson(link = "log"),
              data = SIM_data_no_intra,
              na.action = na.exclude)
write_rds(orcSIM, "data/rds/orcSIM202310.rds")
```

```{r}
orcSIM <- read_rds("data/rds/orcSIM202310.rds")
```

```{r}
calc_r_squared(orcSIM)
```

### Destination constrained

```{r}
#| eval: false
decSIM <- glm(formula = TRIPS ~ 
                DEST_HEX_ID +
                log(ORIG_HDB_RESIDENT_COUNT) +
                #log(ORIG_BUS_ALIGHT_COUNT) +
                log(ORIG_TRAIN_ALIGHT_COUNT) +
                log(DISTANCE),
              family = poisson(link = "log"),
              data = SIM_data_no_intra,
              na.action = na.exclude)
write_rds(decSIM, "data/rds/decSIM202310.rds")
```

```{r}
decSIM <- read_rds("data/rds/decSIM202310.rds")
```

```{r}
calc_r_squared(decSIM)
```

### Doubly constrained

```{r}
#| eval: false
dbcSIM <- glm(formula = TRIPS ~ 
                ORIG_HEX_ID + 
                DEST_HEX_ID +
                log(DISTANCE),
              family = poisson(link = "log"),
              data = SIM_data_no_intra,
              na.action = na.exclude)
write_rds(dbcSIM, "data/rds/dbcSIM202310.rds")
```

```{r}
dbcSIM <- read_rds("data/rds/dbcSIM202310.rds")
```

```{r}
calc_r_squared(dbcSIM)
```
:::

## Model Comparisons

```{r}
model_list <- list(
  Unconstrained = uncSIM,
  Origin_Constrained = orcSIM,
  Destination_Constrained = decSIM,
  Doubly_Constrained = dbcSIM)
```

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```
